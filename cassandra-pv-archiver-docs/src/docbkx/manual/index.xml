<?xml version="1.0" encoding="utf-8" ?>
<book version="5.0" xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://docbook.org/ns/docbook http://www.docbook.org/xml/5.0/xsd/docbook.xsd">

  <info>
    <title>Cassandra PV Archiver Reference Manual</title>
    <subtitle>Version ${project.version}</subtitle>
    <copyright>
      <year>2016</year>
      <year>2017</year>
      <holder>aquenos GmbH</holder>
    </copyright>
    <author>
      <personname>
        <firstname>Sebastian</firstname>
        <surname>Marsching</surname>
      </personname>
      <affiliation>
        <orgname>aquenos GmbH</orgname>
      </affiliation>
    </author>
  </info>

  <chapter xml:id="overview">
    <title>Overview of Cassandra PV Archiver</title>
    <para>
      The Cassandra PV Archiver is a scalable archiving solution for
      storing
      time-series data inside an
      <link xlink:href="http://cassandra.apache.org/">Apache Cassandra database</link>
      .
      While the Cassandra PV Archiver has been designed to archive the
      values of
      process variables in industrial automation scenarios, it
      is not limited to
      this specific application.
      In fact, it is suitable
      to archive any kind of data that can be
      represented as a
      time-series and new data sources can easily be added
      through
      extensions (see
      <xref linkend="extend" />
      ).
      The default distribution is bundled with a modules that allows
      for easy
      archiving of process variables that can be accessed over
      the Channel
      Access protocol, which is typically used in
      <link xlink:href="http://www.aps.anl.gov/epics/">EPICS-based</link>
      control systems.
    </para>
    <para>
      This document is intended as a reference guide for
      administrators that
      want to deploy the Cassandra PV Archiver,
      developers that want to extend
      it, and user that want to manage the
      archiver’s configuration or to access
      archived data.
    </para>
    <para>
      This chapter should be of interest to all audiences.
      In addition to
      that, administrators are most likely going to be interested
      in
      <xref linkend="news" />
      and
      <xref linkend="server" />
      .
      Developers are most likely going to be interested in
      <xref linkend="extend" />
      .
      Users are most likely going to be interested in
      <xref linkend="client" />
      .
    </para>
    <para>
      In addition to reading this document, administrators and
      developers who
      are not familiar with Apache Cassandra databases are
      encouraged to read
      the
      <link xlink:href="http://docs.datastax.com/en/cassandra/">Cassandra documentation</link>
      provided by DataStax.
    </para>

    <section xml:id="overview.architecture">
      <title>Architecture</title>
      <para>
        The Cassandra PV Archiver acts as a bridge between an Apache
        Cassandra
        database and control-system applications.
        It takes care
        of monitoring process variables for changes and persisting
        them
        in the database.
        At the same time, it provides an interface for
        querying the data stored
        in the database in a convenient way,
        without having to deal with
        low-level details like the exact
        storage layout.
        The architecture of the Cassandra PV Archiver is
        depicted in
        <xref linkend="overview.architecture.fig.architecture" />
        .
      </para>
      <figure xml:id="overview.architecture.fig.architecture">
        <title>Cassandra PV Archiver architecture</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_overview_architecture.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        The control-system servers provide process variables that are
        monitored
        by the Cassandra PV Archiver server.
        The Cassandra PV
        Archiver can support arbitrary control-systems through
        so-called
        control-system supports.
        The Cassandra PV Archiver server is
        bundled with a control-system
        support for the Channel Access
        protocol (see
        <xref linkend="channel_access" />
        ), but it can easily be extended with
        other control-system
        supports (see
        <xref linkend="extend" />
        ).
        The protocol used for communication between the control-system
        entirely
        depends on the control-system support, so that the
        control-system’s
        native protocol can be used for optimal
        performance.
      </para>
      <para>
        The Cassandra PV Archiver server takes care of managing
        archived
        process variables (which are called “channels” in the
        terminology of the
        Cassandra PV Archiver).
        This includes managing
        configuration and meta-data as well as storing
        the archived
        samples in the Cassandra database.
        However, the actual storage
        format of individual samples is defined by
        each control-system
        support.
        This allows each control-system support to choose a
        storage format that
        is optimized for the structure of samples as
        they are supplied by the
        underlying control-system framework.
      </para>
      <para>
        The Cassandra PV Archiver server uses Cassandra’s native
        protocol for
        writing data to and reading data from the Apache
        Cassandra database.
        Even though the Cassandra PV Archiver and the
        Cassandra database are
        depicted as monolithic blocks in
        <xref linkend="overview.architecture.fig.architecture" />
        , each of these
        blocks can actually consist of many sever
        instances that form a cluster.
        The Cassandra PV Archiver server
        instances and the Apache Cassandra
        database servers can be
        deployed on separate clusters, but in a typical
        setup they will
        actually be colocated on the same servers.
      </para>
      <para>
        For accessing archived samples, a user uses an archive client
        (see
        <xref linkend="client" />
        ).
        This archive client accesses the Cassandra PV Archiver server
        through a
        JSON-based web-service protocol.
        Each server instance
        can provide access to the complete archive, so a
        client can use a
        round-robin strategy when choosing the server that is
        contacted
        in order to retrieve data.
        As an alternative to that, special
        server instances that are dedicated
        to providing read access to
        the archive might be deployed.
      </para>
    </section>

    <section xml:id="overview.data_storage">
      <title>Data storage</title>
      <para>
        In order to offer good read and write performance, the
        Cassandra PV
        Archiver arranges the data in a way that is
        optimized for the Cassandra
        database.
        Cassandra tables organize
        rows in so-called partitions.
        A partition is a set of rows that
        is stored on the same node.
        While the rows within a partition
        have an order (and thus range queries
        are possible), there is no
        order between partitions.
      </para>
      <para>
        When storing time-series data, this means that only data in the
        same
        partition can easily be queried for a certain period of
        time.
        Unfortunately, storing all data for a certain channel in a
        single
        partition is typically not an option because the size of a
        partition
        should typically
        <link
          xlink:href="https://docs.datastax.com/en/landing_page/doc/landing_page/planning/planningPartitionSize.html">not exceed 100 MB</link>
        in order to attain a good performance .
      </para>
      <para>
        The Cassandra PV Archiver solves this issue by dividing the data
        stored
        for each channel into so-called sample buckets (see
        <xref linkend="overview.data_storage.fig.sample_buckets" />
        ).
        Each sample bucket stores the data for a certain period of
        time.
        When a sample buckets hits a size of about 100 MB, a new
        sample bucket
        is started.
        The information about how periods of
        time map to sample buckets is
        stored in a separate table.
        When
        reading data, the Cassandra PV Archiver first finds out which
        sample buckets exist for the specified period of time and then
        retrieves
        the actual data from these sample buckets.
      </para>
      <note>
        <para>
          By default, Apache Cassandra compresses data before
          writing it to
          disk.
          For this reason, the on-disk size of a
          sample bucket is typically
          significantly less than 100 MB.
          However, the 100 MB limit recommended for partitions applies
          to the
          uncompressed size.
        </para>
      </note>
      <figure xml:id="overview.data_storage.fig.sample_buckets">
        <title>Division of samples into sample buckets</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_overview_sample_buckets.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        Typically, an administrator or developer does not have to
        deal with
        these details of how data is stored.
        However, it is
        important to understand these details when optimizing the
        configuration of the Cassandra database cluster for performance
        and when
        reading data directly from the database, bypassing the
        query interface
        provided by the Cassandra PV Archiver.
      </para>
      <para>
        Each control-system support uses a separate table (or
        possibly even a
        set of tables) for storing its samples.
        However,
        the control-system support does not have to deal with managing
        sample buckets.
        When writing a sample, the Cassandra PV Archiver
        tells the
        control-system support to which sample bucket a sample
        belongs.
        This way, the control-system support can simply store
        the sample in this
        sample bucket.
        In the same way, when reading
        data, the Cassandra PV Archiver only asks
        the control-system
        support for data from a single sample bucket, so that
        the
        control-system support can use simple range queries.
      </para>
    </section>

    <section xml:id="overview.decimated_samples">
      <title>Decimated samples</title>
      <para>
        Users often want to retrieve samples for an extended period
        of time,
        for example in order to get a trend of how a process
        variable changed
        over months or even years.
        In this case,
        retrieving the raw samples as they were logged is rather
        inefficient.
        For example, if a process variable is logged at an
        update rate of one
        sample per second, there are 86,400 samples
        per day or 31,536,000
        samples per year.
        When plotting the trend of
        a process variable’s value for a whole year,
        using 31 million
        samples does not make sense because the effective
        resolution of
        the plot will limit the amount of details that can be seen
        to a
        much coarser level.
        More importantly, retrieving the data for 31
        million samples can take a
        considerable amount of time and
        typically a user will not want to wait
        for a long time if she is
        just interested in getting a quick overview.
      </para>
      <para>
        For this reason, the Cassandra PV archiver supports
        so-called decimated
        samples.
        These decimated samples are generated
        asynchronously in the background
        while data is being archived.
        When retrieving data from the archive, this decimated data can
        be used
        when lower resolution data is sufficient for satisfying
        the user’s
        request.
        Decimated samples are organized in so-called
        decimation levels.
        Each decimation level for a certain channel
        stores samples at a fixed
        rate.
      </para>
      <para>
        Typcially, the density of these decimation levels is chosen
        so that the
        distance between two samples increases exponentially
        with each
        decimation level.
        For example, when having a process
        variable with a native update rate of
        approximately one sample
        per second, the administrator might add
        decimation levels with
        decimation periods of 30 seconds, 15 minutes, and
        6 hours.
        When
        plotting data for a whole year, one might then select the data
        from
        the decimation level with a decimation period of 6 hours,
        resulting in
        only 1,460 samples being returned instead of
        approximately 31 million
        raw samples.
      </para>
      <para>
        The samples that are generated for decimation levels are
        always
        generated with a fixed distance specified by the
        decimation period of
        that decimation level.
        The details of how a
        decimated sample is generated are left to each
        control-system
        support.
        For example, a simple algorithm might choose to simply
        use one raw
        sample for each decimated sample, resulting in a
        “decimation” process
        in the literal sense.
        A more advanced
        algorithm, on the other hand, might choose to apply
        statistical
        operations on the source samples for the relevant period of
        time, calculating a mean and other stastical properties.
      </para>
      <figure xml:id="overview.decimated_samples.fig.sample_decimation">
        <title>Mapping of raw samples to decimated samples</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_overview_sample_decimation.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        <xref linkend="overview.decimated_samples.fig.sample_decimation" />
        shows how decimated samples are generated from raw samples.
        For
        each decimated sample, the Cassandra PV Archiver passes one raw
        sample before or at the same time as the decimated sample to be
        generated and all raw samples after the decimated sample but
        before the
        next decimated sample to be generated.
        This way, the
        control-system support has all relevant information for
        the whole
        period for which the decimated sample is generated.
        This means
        that a decimated sample represents the period after its time
        stamp.
        For example, when having a decimation level with a
        decimation period of
        30 seconds, the decimated sample with a time
        stamp of 14:12:30 will
        represent the interval [14:12:30,
        14:13:00).
      </para>
      <para>
        When there are multiple decimation levels for a channel, the
        decimated
        samples for longer decimation period are generated from
        decimated
        samples from shorter decimation periods (if the longer
        period is an
        integer multiple of the shorter period).
        This way,
        the amount of data that has to be processed is reduced
        dramatically (see
        <xref
          linkend="overview.decimated_samples.fig.cascaded_decimation_levels" />
        ).
      </para>
      <figure
        xml:id="overview.decimated_samples.fig.cascaded_decimation_levels">
        <title>Sample generation for cascaded decimation levels</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_overview_cascaded_decimation_levels.png" />
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section xml:id="overview.scaling_and_limits">
      <title>Scalability and limitations</title>
      <para>
        One of the key goals that were in mind when designing the
        Cassandra PV
        Archiver was scalability.
        The Cassandra PV Archiver
        is designed to work both for very small setups
        (possibly as small
        as a single node installation) and very large scale
        setups (with
        tens or even hundreds of nodes).
        By using Apache Cassandra as the
        data store, the Cassandra PV Archiver
        can scale linearly,
        increasing the number of channels that can be
        handled and the
        amount of data that can be stored with each node added.
      </para>
      <para>
        The Cassandra PV Archiver is not just scalable when making
        the first
        deployment.
        In fact, an existing deployment can easily
        be scaled up by adding more
        nodes with zero downtime as the
        demand grows.
        However, there are a few limitations regarding the
        data that can be
        stored for individual channels, of which the
        administrator should be
        aware.
        These limitations are largely
        instrinsic to the use of Apache Cassandra
        as the data store, but
        for some of them there exist workarounds that are
        described in
        the next paragraphs.
      </para>

      <section>
        <title>High update rates</title>
        <para>
          The archiving of each sample results in an
          <literal>INSERT</literal>
          statement being executed in the Cassandra database.
          As the
          number of statements that can be executed per second is
          usually
          limited to something in the order of 100,000 statements
          per second per
          node, archiving samples at extremely high rates
          is typically not a
          good idea.
          For example, when having channels
          with an update rate of about 1 kHz,
          only about one hundred
          channels could be archived per node.
          In additition to that,
          samples for the same channel are archived one
          after another.
          This means that the next sample is only archived once the
          <literal>INSERT</literal>
          statement for the precding sample has
          finished.
          Due to the
          latency involved in executing each statement, this
          effectively
          limits the rate at which samples for a single channel can
          be
          written.
        </para>
        <para>
          The workaround for this issue can be implemented by providing
          a custom
          control-system support (see
          <xref linkend="extend" />
          ) that archives
          samples at a lower rate.
          For example, a
          control-system support can choose to accumulate all
          samples
          that are received within a second and then create and archive
          a “meta-sample” that actually contains the data of all these
          samples.
          This reduces the number of
          <literal>INSERT</literal>
          statements
          required and can thus reduce the load significantly.
          As a side effect, this also resolves the latency problem.
        </para>
        <para>
          For most scenarios, it should not be necessary to
          implement this
          workaround:
          The Cassandra PV Archiver typically
          works fine at update rates of
          about 10 Hz and supervisory
          control and data acquisition (SCADA)
          systems rarely deal with
          significantly higher data rates.
          Therefore, implementing this
          workaround only has to be considered when
          archiving data from a
          system with exceptionally high update rates.
        </para>
      </section>

      <section>
        <title>Very large samples</title>
        <para>
          As described in
          <xref linkend="overview.data_storage" />
          , archived
          samples are organized in sample buckets.
          In order to
          ensure data consistency even in the event of a server
          crash at
          a very incovenient point in time, the Cassandra PV Archiver
          takes special precautions when creating a new sample bucket.
          These precautions result in a significant overhead when
          creating a new
          sample bucket, so that creating a new sample
          bucket very frequently is
          not advisable.
          This means that a
          channel producing data at a rate of tens of
          megabytes per
          second should not be (directly) archived with the
          Cassandra PV
          Archiver.
        </para>
        <para>
          More importantly, the meta-data about which sample buckets
          exist is
          stored in a single partition.
          When deleting old
          samples, the corresponding reference to the sample
          bucket is
          removed by issuing a
          <literal>DELETE</literal>
          statement
          in the database.
          In Apache Cassandra, a
          <literal>DELETE</literal>
          statement results in
          a so-called tombstone being written.
          When a
          lot of tombstones accumulate, this can have a significant
          impact on read operations, which is why Apache Cassandra
          aborts a read
          opertion when it encounters too many tombstones
          (please refer to the
          <link xlink:href="http://docs.datastax.com/en/cassandra/">Cassandra documentation</link>
          for details).
        </para>
        <para>
          Typically, this is not a problem, but when inserting large
          amounts of
          data at comparedly high rates and only retaining
          this data for a
          limited amount of time, the number of
          tombstones generated when
          deleting old data might actually
          exceed this limit.
        </para>
        <para>
          There are two possible workarounds. The first one is changing
          the
          configuration options for Apache Cassandra. By reducing the
          so-called
          GC grace period, tombstones can be discarded earlier
          so that the
          number of tombstones that is accumulated can be
          reduced.
          Please be sure to understand the consequences of this
          change before
          applying it.
          It is very important that the
          periodic
          <literal>nodetool repair</literal>
          operation runs more frequently than
          the GC grace period.
          If not,
          deleted data can reappear, which in the context of the
          Cassandra PV Archiver can result in data corruption.
          The other
          change is increasing the number of tombstones that may be
          encountered before aborting a read operation.
          Increasing this
          number has an impact on the memory consumption of read
          operations and read operations that encounter many tombstones
          may run
          very slowly.
        </para>
        <para>
          The second and preferred workaround is to store large amounts
          of data
          outside the Apache Cassandra database, for example
          using a scalable,
          distributed file-system (like
          <link xlink:href="http://ceph.com/">Ceph</link>
          ).
          Such a solution can be implemented by providing a custom
          control-system support that stores the raw data in files and
          archives
          the meta-data (which file contains the data for a
          specific sample)
          using the Cassandra PV Archiver.
        </para>
        <para>
          As a rule of thumb, you should consider storing the sample
          data
          outside the Cassandra database when the average data rate
          of a single
          channel exceeds the order of 50 KB per second.
          The
          average data rate means the rate averaged over an extended
          amount
          of time.
          For example, having a burst of data at a rate of
          5 MB per second for
          ten seconds is fine when it is typically
          followed by a period of 30
          minutes where virtually no data is
          archived.
        </para>
      </section>
    </section>
  </chapter>

  <chapter xml:id="news">
    <title>What’s new in Cassandra PV Archiver 3.x</title>

    <section xml:id="news.version_3.0">
      <title>Cassandra PV Archiver 3.0</title>
      <para>
        The Cassandra PV Archiver 3.0 is intended as a replacement
        for the
        Cassandra Archiver for CSS 2.x.
        While sharing some of the
        concepts with the Cassandra Archiver for CSS
        2.x, the code for
        the Cassandra PV Archiver 3.0 has actually been
        rewritten from
        scratch.
        The Cassandra PV Archiver 3.0 uses a new, CQL-based
        storage
        architecture that provides a significant improvement in
        performance and
        also simplifies the structure of the stored data,
        enabling direct data
        access for special applications.
        Unfortunately, this means that data archived with the Cassandra
        Archiver
        for CSS 2.x is not compatiable with the Cassandra PV
        Archiver 3.0 and
        has to be converted manually.
      </para>
      <para>
        In addition to the change of the data format, the Cassandra
        PV Archiver
        3.0 brings many new features that make it more
        scalable and simplify the
        deployment and operation:
      </para>
      <itemizedlist>
        <listitem>
          <simpara>
            Completely new web interface for monitoring and
            configuring the
            archive cluster.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            Changing the configuration of channels (including
            renaming channels
            and moving channels between servers)
            without having to shutdown
            archiving servers.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            Asynchronous sample writer, making the best use of
            multi-core CPUs.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            Web-service interface for accessing the archive,
            simplifying the
            deployment of clients.
          </simpara>
        </listitem>
      </itemizedlist>
      <para>
        As the list of changes is so vast, even users already
        familiar with the
        Cassandra Archiver for CSS 2.x are strongly
        encouraged to read the
        complete manual of the Cassandra PV
        Archiver 3.0.
      </para>
      <section xml:id="news.version_3.0.1">
        <title>Cassandra PV Archiver 3.0.1</title>
        <para>
          Version 3.0.1 is a bugfix release that fixes three bugs in
          the
          archive-access JSON interface.
          The first bug caused an
          exception when trying to retrieve enum
          samples, making it
          impossible to retrieve such samples via the JSON
          interface.
          The
          second bug caused incorrect values to be sent when an enum
          sample
          had more than a single element.
          The third bug concerned
          the serialization of the special “disabled”
          and “disconnected”
          samples.
          Those samples where always presented with a quality of
          “original”,
          even if they actually were decimated samples and
          should thus have had
          a quality of “interpolated”.
        </para>
        <para>
          All the bugs fixed in this release only concern the
          archive-access
          interface.
          This means that data written by
          previous releases has not been
          affected by the aforementioned
          bugs and is correctly serialized after
          installing this update.
        </para>
      </section>
      <section xml:id="news.version_3.0.2">
        <title>Cassandra PV Archiver 3.0.2</title>
        <para>
          Version 3.0.2 is a bugfix release that fixes an issue that
          could
          result in an extreme memory consumption when generating
          decimated
          samples.
          When the source samples that were used for
          generating decimated were
          very scarce (had a density that was
          much smaller than the density of
          the generated samples), this
          could lead to an extreme memory
          consumption, resulting in a
          denial of service.
          As a side-effect, the server process would
          not respond any longer
          because the thread generating the
          decimated samples would hold a mutex
          for an extended period of
          time.
          Typically, this issue would primarily occur when starting
          the server
          after it had been stopped for some time or when
          adding new decimation
          levels.
        </para>
        <para>
          The bugfix limits the number of samples that are generated
          from a
          single source sample, interrupting the process when the
          limit is
          reached and waiting for the generated samples having
          been written to
          the database before continuing. This limits the
          memory consumption and
          also releases the mutex periodically so
          that threads waiting for the
          mutex do not block for an extended
          period of time.
        </para>
        <para>
          The bug fixed in this release only concerns internal
          implementation
          details.
          This means that data written by previous
          releases is correct and does
          not have to be regenerated or
          updated.
        </para>
      </section>
      <section xml:id="news.version_3.0.3">
        <title>Cassandra PV Archiver 3.0.3</title>
        <para>
          Version 3.0.3 is a bugfix release that fixes four issues.
          Three of these issues affected the generation of decimated
          samples.
          The fourth issue was in a shared component and would
          cause an
          exception in certain situations with a very high
          system load.
        </para>
        <para>
          The three bugs in the sample generation process could
          result in no
          more decimated samples being generated for a
          certain channel.
          This was caused by a problem that would result
          in already existing
          decimated samples being generated again
          when the decimation process
          was previously interrupted
          unexpectedly (e.g. due to a server
          restart).
          On its own, this
          bug would only have performance implications and not
          affect
          correct behavior.
          However, due to a second bug that was
          introduced in version 3.0.2, it
          would lead to the whole
          decimation process for the channel being
          brought to a halt.
          The
          third bug could have a negative impact on performance because
          the
          decimation process would not always be interrupted as
          intended, thus
          potentially blocking the channel mutex for a
          long time.
          However, it is believed that this bug did not result
          in incorrect
          behavior.
        </para>
        <para>
          The fourth bug concerned a component that provides a queue
          that is
          time bounded, meaning that elements that have been
          added to the queue
          some time ago, but have not been removed
          yet, are automatically
          removed when new elements are added.
          Due
          to a bug in the algorithm that takes care of automatically
          removing such elements, an exception would be thrown if all
          elements
          in the queue were considered old and thus marked for
          removal.
          This lead to an exception when samples were added to
          the write queue,
          but the write queue was not processed for a
          long time and no new
          samples were added in this period of time.
          In this case, the exception would occur when new samples were
          finally
          added to the queue.
          Typically, such a situation would
          only occur when the system was under
          extremely high load,
          resulting in samples neither being written nor
          new samples
          being added to the queue for more than 30 seconds.
        </para>
        <para>
          The bugs fixed in this release only concern internal
          implementation
          details.
          This means that data written by previous
          releases is correct and does
          not have to be regenerated or
          updated.
        </para>
      </section>
    </section>

    <section xml:id="news.version_3.1">
      <title>Cassandra PV Archiver 3.1</title>
      <para>
        The Cassandra PV Archiver 3.1 adds a few new features and
        updates its
        dependencies to their respective newest versions.
        It
        is compatible with the Cassandra PV Archiver 3.0.x, meaning that
        it
        can operate on data stored by the Cassandra PV Archiver 3.0.x
        and the
        APIs supported by the Cassandra PV Archiver 3.0.x are
        fully supported.
      </para>
      <para>
        The following features have been added in this release:
      </para>
      <itemizedlist>
        <listitem>
          <simpara>
            A web-service API for managing the server has been added.
            This API is described in detail in
            <xref linkend="admin_api" />
            .
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The administrative user-interface now uses AJAX to
            load the list of
            channels asynchronously.
            This improves the
            performance when displaying a list containing a
            large number
            of channels.
          </simpara>
        </listitem>
      </itemizedlist>
      <para>
        There also are some bugfixes and minor improvements:
      </para>
      <itemizedlist>
        <listitem>
          <simpara>
            For each module containing Java code, a source JAR is
            generated in
            addition to the binary JAR.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            A
            <literal>NullPointerException</literal>
            that could occur when
            updating a channel while concurrently
            moving or deleting it has been
            fixed.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The launcher script on Windows now works correctly
            when the path
            where the Cassandra PV Archiver is installed
            contains spaces.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            All library dependencies have been updated to their
            newest versions.
          </simpara>
        </listitem>
      </itemizedlist>
      <section xml:id="news.version_3.1.1">
        <title>Cassandra PV Archiver 3.1.1</title>
        <para>
          Version 3.1.1 is a bugfix release that fixes an issue with
          displaying
          the channel state in the channel list.
        </para>
        <para>
          Unfortunately, a regression was introduced shortly before
          the release
          of version 3.0.0.
          This regression caused the state
          of a channel not to be visible in the
          list view (but it would
          show on the details page for a channel).
          This problem is fixed
          in version 3.0.1 so that the state now is also
          visible in the
          list view (like it was in older versions).
        </para>
      </section>
      <section xml:id="news.version_3.1.2">
        <title>Cassandra PV Archiver 3.1.2</title>
        <para>
          Version 3.1.2 is a bugfix release that includes an updated
          version of
          the EPICS Jackie library and brings a few minor
          improvements:
        </para>
        <itemizedlist>
          <listitem>
            <simpara>
              EPICS Jackie has been updated to version 1.0.2.
              This version includes a fix for a bug that could cause
              connectivity issues for channels that are hosted by
              servers based
              on older EPICS versions.
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              When an archive configuration command fails, the
              corresponding
              exception is now logged in the logfile.
              Expected exceptions (e.g. trying to add a channel that
              already
              exists) are logged with the level INFO, while
              unexpected
              exceptions (e.g. database errors) are logged
              with level ERROR.
              Such errors were already reported to the
              user through the user
              interface, but the logged exception
              (including the stack trace)
              might give additional insights
              into the actual cause of the error.
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              Write timeouts when creating, updating, or deleting a
              “pending
              channel operation” are now handled more
              gracefully.
              These timeouts caused configuration commands to
              fail with a
              message like “Cassandra timeout during write
              query at consistency
              SERIAL…”.
              While the
              <link linkend="server.configuration.throttling">throttling options</link>
              should still be used to avoid overloading the server, the
              new
              logic can help in handling short spikes by retrying an
              operation
              that timed out after a short delay.
              Configuring
              the throttling at a reasonable value is still needed
              because this mechanism will not work in a situation where
              the
              database is overloaded for a longer period of time (the
              operation
              will simply fail after reaching the maximum
              number of retries).
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              The timeout for inter-node communication has been
              increased.
              When running a large number (typically
              thousands) of configuration
              commands that affected a remote
              server, the commands would fail
              with a timeout error due to
              the HTTP communication timing out.
              While this timeout would
              be reported to the user, the commands
              would still continue
              running in the background.
              The timeout for the HTTP
              communication has now been increased to
              15 minutes, so that
              the HTTP connection should not time out, even
              when a large
              number of commands is processed.
            </simpara>
          </listitem>
        </itemizedlist>
      </section>
      <section xml:id="news.version_3.1.3">
        <title>Cassandra PV Archiver 3.1.3</title>
        <para>
          Version 3.1.3 is a bugfix release that includes an updated
          version of
          the EPICS Jackie library and one minor improvement:
        </para>
        <itemizedlist>
          <listitem>
            <simpara>
              EPICS Jackie has been updated to version 1.0.3.
              This version includes a fix for a bug that would cause
              connections
              to channels providing large values (waveforms
              with many elements)
              to fail.
              As a side effect, this bug
              would also cause the connections for
              all other channels
              hosted by the same server to be disrupted.
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              A few minor improvements have been added to the
              changes regarding
              timeouts when creating, updating, or
              deleting a “pending
              channel operation” that have been added
              in the last release.
              This means that the code should now
              recover from timeouts in a few
              more cases.
            </simpara>
          </listitem>
        </itemizedlist>
      </section>
    </section>

    <section xml:id="news.version_3.2">
      <title>Cassandra PV Archiver 3.2</title>
      <para>
        The Cassandra PV Archiver 3.2 adds a few new configuration
        options and
        updates its dependencies to their respective newest
        versions.
        It is compatible with the Cassandra PV Archiver 3.1.x,
        meaning that it
        can operate on data stored by the Cassandra PV
        Archiver 3.1.x and the
        APIs supported by the Cassandra PV
        Archiver 3.1.x are fully supported.
      </para>
      <para>
        Due to newly introduced configuration options, configuration
        files for
        version 3.2.x are not compatible with version 3.1.x.
        However, configuration files for version 3.1.x remain compatible
        with
        version 3.2.x.
      </para>
      <para>
        The following improvements have been made in this release:
      </para>
      <itemizedlist>
        <listitem>
          <simpara>
            The memory consumption when generating decimated samples
            based on
            pre-existing source samples has been reduced
            significantly.
            This is important when adding new decimation
            levels to a large
            number of channels.
            In earlier versions, the
            sample decimation process could allocate
            so much memory that
            the heap space would be exhausted, resulting in
            an
            <exceptionname>OutOfMemoryError</exceptionname>
            .
            Two new configuration options have been introduced for
            controlling
            the memory consumption of the sample decimation
            process:
            <link
              linkend="server.configuration.throttling.sample_decimation.max_fetched_samples_in_memory">
              <literal>throttling.sampleDecimation.maxFetchedSamplesInMemory
              </literal>
            </link>
            and
            <link
              linkend="server.configuration.throttling.sample_decimation.max_running_fetch_operations">
              <literal>throttling.sampleDecimation.maxRunningFetchOperations
              </literal>
            </link>
            .
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The implementation of
            <classname>AbstractObjectResultSet</classname>
            has been improved in order to avoid unnecessary copy
            operations.
            This change should improve the performance when
            reading samples from
            the database.
            In order to profit from
            this change, control-system supports using
            <classname>AbstractObjectResultSet</classname>
            for implementing
            their sample result sets should change the
            result set’s
            <methodname>fetchNextPage()</methodname>
            method to return a
            <interfacename>SizedIterator</interfacename>
            instead of a regular
            <interfacename>Iterator</interfacename>
            .
            This change has already been implemented for the
            <classname>ResultSetBasedObjectResultSet</classname>
            , so
            control-system supports using this class (like the
            Channel Access
            control-system support) will automatically
            profit from this
            improvement.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The
            <link linkend="server.configuration.cassandra.fetch_size">
              <literal>cassandra.fetchSize</literal>
            </link>
            option has been introduced in order to control the default
            fetch
            size used for queries.
            Usually, the default fetch size
            of the Cassandra driver should be
            fine, but users wanting to
            fine-tune the fetch size can now do so.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The
            <link
              linkend="server.configuration.server.inter_node_communication_request_timeout">
              <literal>server.interNodeCommunicationRequestTimeout
              </literal>
            </link>
            option has been introduced in order to control the timeout
            for
            requests sent from one archiving server to another one.
            This timeout has been significantly increased in version
            3.1.2, but
            now it is possible to increase it even further if
            necessary or to
            choose a shorter timeout if sufficient.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The way how the throttling of statements executed on
            the Cassandra
            cluster is handled has been improved.
            In older
            versions, the limit for read statements would only apply
            for
            the initial execution of a statement.
            If a statement later
            fetched more results (because there were more
            rows than the
            configured fetch size), this fetch operation would not
            count
            towards the limit.
            Now, a fetch operation is treated like a
            read statement and fully
            counts towards the limit.
            This means
            that in certain situations it might be possible to
            slightly
            raise the limit for read statements.
          </simpara>
        </listitem>
        <listitem>
          <simpara>
            The naming scheme for the MBeans exposed via JMX has
            been changed so
            that all MBeans of the archiving server are
            in a single domain.
            This means that clients using JMX to
            monitor the archiving server
            have to be changed to use the
            new object names.
            The JMX interface is not considered a
            public API and thus might
            again change in future versions.
          </simpara>
        </listitem>
      </itemizedlist>
      <para>
        There also was one bug that has been fixed in this release:
      </para>
      <itemizedlist>
        <listitem>
          <simpara>
            The way how write operations to the
            <literal>generic_data_store</literal>
            table were handled was unsafe
            because light-weight
            transactions (LWTs) were mixed with regular
            updates.
            This
            could theoretically lead to invalid data if writes were
            happening very rapidly or server clocks had an extremely
            large clock
            skew.
            As data is only rarely written to this table
            (once when the
            archiving cluster is initialized and every
            time the administrator’s
            password is changed), this bug was
            very unlikely to cause any
            actual problems.
          </simpara>
        </listitem>
      </itemizedlist>
      <para>
        The Cassandra driver has been updated to version 3.2.0 in this
        release.
        That version includes a change to how user-defined types
        (UDTs) are
        handled when using the schema builder to create a
        table.
        Control-system supports using the schema builder to create
        a table with
        UDT columns might have to be changed to use the
        schema builder’s
        <methodname>addUDTColumn(…)</methodname>
        method with a parameter
        constructed using
        <literal>SchemaBuilder.frozen(…)</literal>
        instead of
        using
        <methodname>addColumn(…)</methodname>
        with an instance of
        <classname>UserType</classname>
        .
      </para>
      <section xml:id="news.version_3.2.1">
        <title>Cassandra PV Archiver 3.2.1</title>
        <para>
          Version 3.2.1 is a bugfix release that fixes an issue
          introduced in
          the 3.2.0 release.
        </para>
        <para>
          This issue caused the archiving server not to start if the
          configuration file contained a line for the sample-decimation
          throttling options, but not any actual options.
          Unfortunately,
          the default configuration file provided with the
          distribution
          contained such a line so that the archiving server would
          not
          start with its default configuration file.
        </para>
        <para>
          Starting with version 3.2.1, the archiving server accepts
          such a line
          in the configuration file and thus will work with
          the unchanged
          configuration file.
        </para>
      </section>
      <section xml:id="news.version_3.2.2">
        <title>Cassandra PV Archiver 3.2.2</title>
        <para>
          Version 3.2.2 is a bugfix release that fixes an issue with
          the
          throttling mechanism introduced in the 3.2.0 release.
        </para>
        <para>
          This issue caused the throttling mechanism to not work
          correctly in
          certain cases, thus fetching (significantly) more
          samples than allowed
          by the specified limit.
        </para>
      </section>
      <section xml:id="news.version_3.2.3">
        <title>Cassandra PV Archiver 3.2.3</title>
        <para>
          Version 3.2.3 is a bugfix release that fixes an issue with
          the generation of decimated samples.
        </para>
        <para>
          Due to this issue, the generation of decimated samples
          would permanently stop if there was an error while reading
          source samples from the database.
          The code will now catch such an error and retry periodically.
        </para>
      </section>
      <section xml:id="news.version_3.2.4">
        <title>Cassandra PV Archiver 3.2.4</title>
        <para>
          Version 3.2.4 is a bugfix release that fixes a regression introduced
          with the 3.2.0 release and improves the initialization logic of the
          archiving service.
        </para>
        <para>
          The regression would cause the generation process for decimated
          samples to be brought to a halt when more than 100 source samples were
          used to generate a single decimated sample.
          This regression would only affect the generation of decimated samples
          from source samples in the database (typically when a new decimation
          level was added).
          When generating decimated samples as new samples were written, the
          regression would not be triggered.
        </para>
        <para>
          The initialization logic of the archiving service has been improved so
          that it will be run again if there is an error while trying to
          initialize the channels.
          Before, the initialization would only be attempted again when the
          server went offline (because the database was unavailable) and then
          back online.
          This had the consequence that a very brief database problem (possibly
          caused by the database being overloaded) might cause the
          initialization logic to fail without the server going offline,
          resulting in a server that was online, but did not have any active
          channels.
        </para>
      </section>
    </section>
  </chapter>

  <chapter xml:id="server">
    <title>Cassandra PV Archiver server</title>
    <para>
      The Cassandra PV Archiver server is the central component of
      the archiving
      system.
      It is responsible for monitoring process
      variables (channels in the
      terminology of the Cassandra PV
      Archiver) for changes and writing these
      changes to the archive.
      At
      the same time, it is also responsible for providing access to the
      data
      stored in the archive through a web-service interface.
      This
      chapter explains how to install, configure, and use the Cassandra
      PV
      Archiver server.
    </para>

    <section xml:id="server.prerequisites">
      <title>Prerequisites</title>
      <para>
        The Cassandra PV Archiver server is a pure Java application.
        This means that it can run on any platform providing the Java 7
        Standard
        Edition or a newer version of the Java runtime
        environment (JRE).
        Even though the JRE is sufficient for running
        the Cassandra PV Archiver
        server, users are encouraged to install
        the Java Development Kit (JDK)
        because of the additional
        diagnostics tools it provides.
      </para>
      <para>
        The Cassandra PV Archiver server has been tested on Linux, OS X,
        and
        Windows.
        On some of these platforms, it might make use of the
        <link xlink:href="https://github.com/java-native-access/jna">JNA library</link>
        for accessing platform-specific functions.
        However, the
        availability of these functions is not critical for the
        operation of the Cassandra PV Archiver server.
      </para>
      <para>
        In addition to the JRE or JDK, an
        <link xlink:href="http://cassandra.apache.org/">Apache Cassandra</link>
        cluster is needed.
        Users that want to setup an Apache Cassandra
        cluster are encouraged to
        check out the Cassandra distributions
        available at
        <link xlink:href="http://www.planetcassandra.org/">Planet Cassandra</link>
        .
        The Cassandra PV Archiver server is compatible with Cassandra
        2.2 and
        3.x. Most likely, it is also going to be compatible with
        newer versions
        of Cassandra.
      </para>
      <warning>
        <para>
          Apache Cassandra 3.0.0 through 3.0.8 and 3.1 through 3.7 have
          a
          <link xlink:href="https://issues.apache.org/jira/browse/CASSANDRA-12107">bug</link>
          that affects the Cassandra PV Archiver.
          This bug can cause
          serious issues when deleting or renaming channels.
          The symptoms
          are channels appearing in some views and missing in
          others,
          even channels that have been added after deleting some other
          channels.
        </para>
        <para>
          For this reason, it is strongly recommended to avoid the
          affected
          versions of Apache Cassandra. The bug has been fixed
          in versions 3.0.9
          and 3.8.0.
          Apache Cassandra 2.2.x should not
          be affected either.
          When using one of the affected version of
          Apache Cassandra, avoid
          deleting or moving channels until you
          have upgraded to a version of
          Apache Cassandra that is not
          affected.
        </para>
      </warning>
      <para>
        In the simplest case, the Cassandra cluster may consist of
        only a single
        node running on the same system as the Cassandra PV
        Archiver server.
        In general, it is a good idea to colocate
        Cassandra PV Archiver server
        nodes and Apache Cassandra nodes on
        the same set of computers, but
        technically speaking, there is no
        need for such a setup and the two
        software components can safely
        be separated into two sets of computers
        if this is preferred for
        administrative reasons.
      </para>
      <para>
        Installing the JRE or JDK and the Cassandra cluster is outside
        the scope
        of this document.
        Readers are encouraged to refer to the
        documentation of the JRE / JDK of
        their choice for installation
        instructions.
        On most Linux distributions, choosing the JRE / JDK
        available from the
        distributions’s repositories is typically the
        best choice.
        For setup instructions for Apache Cassandra, please
        refer to the
        <link xlink:href="http://docs.datastax.com/en/cassandra/">Cassandra documentation</link>
        provided by DataStax.
      </para>

      <section xml:id="server.prerequisites.clock_sync">
        <title>Clock synchronization</title>
        <para>
          For operation of both Apache Cassandra and the Cassandra
          PV Archiver
          server, it is critical that the clocks of all
          servers are well
          synchronized.
          In an Apache Cassandra database,
          a large clock skew can lead to data
          corruption.
          The
          administrator should take appropriate means for synchronizing
          the
          servers’ clocks and monitoring the clock skew.
        </para>
        <para>
          The setup of a proper clock synchronization solution is
          outside the
          scope of this document.
          As a minimum, it is
          suggested that the administrator provides at least
          two NTP
          servers with which all servers are synchronized.
          These servers
          should be synchronized with each other and with some
          external
          reference, preferably a set of low-stratum NTP servers or
          even
          a GPS clock.
          NTP servers should typically run on physical
          hosts, not inside virtual
          machines.
          Many virtual machine
          solutions do not provide an adequately stable
          clock, so that
          NTP servers might be unreliable when running inside a
          virtual
          machine.
        </para>
        <para>
          The Cassandra PV Archiver server contains some rudimentary
          clock skew
          monitoring system that tries to detect the clock
          skew between the
          servers.
          When this system detects that the
          clock of a server is skewed by more
          than 800 ms, it logs a
          warning.
          When it detects that the clock is skewed by more than
          1200 ms, it
          immediately kills the server.
          The server is also
          killed when the monitoring process detects that the
          server’s
          clock skipped back in time.
        </para>
        <para>
          Due to inherent limitiations of the implementation (for
          example using
          a TCP based protocol), this mechanism will
          typically underestimate the
          actual clock skew.
          For this reason,
          it is suggested that additional means are used for
          monitoring
          the clock skew and the mechanism provided by the Cassandra
          PV
          Archiver server is only considered a “last line of defense” in
          case
          all other mechanisms fail.
        </para>
      </section>
    </section>

    <section xml:id="server.installation">
      <title>Installation</title>
      <para>
        The Cassandra PV Archiver server is provided in two forms of
        distribution:
        The first one is a binary archive that can be used
        on Windows and most
        Unix-like platforms.
        The second one comes in
        the form of a Debian package.
        This Debian package has been
        designed to work on Ubuntu 14.04 LTS and
        Ubuntu 16.04 LTS.
        Most
        likely it is also going to work on most other modern,
        Debian-based
        distributions, as long as they use Upstart or
        systemd.
        The Debian package does
        <emphasis>not</emphasis>
        provide a traditional
        System-V style init script, so it will not
        work on distributions using
        this kind of init system.
      </para>
      <para>
        When installing the Debian package, the package scripts take
        care of
        creating a user and group with the names
        <literal>cassandra-pv-archiver</literal>
        and registering the server with
        the init system.
        This means that
        after installing the package, the
        <literal>cassandra-pv-archiver-server</literal>
        job is automatically
        started with the privileges of that user.
      </para>
      <para>
        When using the binary distribution, users have to take care
        of manually
        creating a user and group for running the server and
        also have to
        register the server with their init system.
        It is
        possible to run the the server as an existing user or even as
        the
        root user, but for a production setup, using a separate user
        is strongly
        encouraged for security reasons.
      </para>
      <para>
        When using the binary distribution (and not the Debian package),
        the
        start script for running the archive server is located in the
        <literal>bin</literal>
        directory and is called
        <literal>cassandra-pv-archiver-server</literal>
        (
        <literal>cassandra-pv-archiver-server.bat</literal>
        on Windows).
        The server runs in the foreground, so the terminal
        that is running the
        server has to be kept alive.
      </para>
      <para>
        When installing the Cassandra PV Archiver for the first time,
        the
        keyspace used for storing data has to be created in the
        Cassandra
        cluster.
        The default name for the keyspace is
        <literal>pv_archive</literal>
        .
        You can choose a different name, but in this case the name has
        to be
        explicitly specified in the configuration file of the
        Cassandra PV
        Archiver server.
      </para>
      <para>
        In order to create the
        <literal>pv_archive</literal>
        keyspace in a
        single node cluster, you can run the following
        command in the CQL shell
        (
        <literal>cqlsh</literal>
        ):
      </para>
      <programlisting><![CDATA[
CREATE KEYSPACE pv_archive
  WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'};
]]></programlisting>
      <para>
        When using a multi-node cluster, you typically do not want to
        use the
        <literal>SimpleStrategy</literal>
        for replication and the replication
        factor should be at least
        three.
        Please refer to the
        <link xlink:href="http://docs.datastax.com/en/cassandra/">Cassandra documentation</link>
        provided by DataStax for details.
      </para>
      <note>
        <para>
          When enabling authentication for the Cassandra cluster,
          ensure that
          the user used for the Cassandra PV Archiver server
          has full write
          access to its keyspace.
          In particular, it has to
          be able to create tables and query and modify
          data.
        </para>
        <para>
          For this purpose, the user at least needs the
          <literal>CREATE</literal>
          permission on the keyspace and the
          <literal>MODIFY</literal>
          and
          <literal>SELECT</literal>
          permissions
          for all tables in the keyspace.
          In order to be ready
          for potential modifications made by future
          versions of the
          Cassandra PV Archiver server, it is suggested to grant
          all the
          necessary permissions on the keyspace instead of the table
          level and to also grant the
          <literal>ALTER</literal>
          and
          <literal>DROP</literal>
          permissions on the keyspace.
        </para>
      </note>
      <para>
        When using a local, single-node Cassandra setup with the default
        keyspace name and not requiring authentication, the default
        configuration should be fine for getting started.
        Otherwise,
        please refer to
        <xref linkend="server.configuration" />
        .
      </para>
      <para>
        Once the server has been started, its administrative
        web-interface is
        available on port 4812 (unless the port number
        has been changed in the
        configuration file). Please refer to
        <xref linkend="server.admin_ui" />
        to learn more about using the administrative interface.
      </para>
    </section>

    <section xml:id="server.configuration">
      <title>Server configuration</title>
      <para>
        The configuration options used by the Cassandra PV Archiver
        server are
        controlled through a configuration file in the
        <link xlink:href="http://yaml.org/">YAML</link>
        format.
        The configuration file is located in the
        <literal>conf</literal>
        directory of the binary distribution or in the
        <literal>/etc/cassandra-pv-archiver</literal>
        directory when using the
        Debian package.
        In either case, the
        configuration file is called
        <literal>cassandra-pv-archiver.yaml</literal>
        .
        It is not an error if the configuration file does not exists at
        the
        expected location.
        In this case the server starts using
        default values for all
        configuration options.
      </para>
      <para>
        The path to the configuration file can be overridden by
        specifying the
        <literal>--config-file</literal>
        command line option to the
        <literal>cassandra-pv-archiver-server</literal>
        script.
        When this configuration option is specified, the default
        location is not
        used.
        Unlike the configuration file in the default
        location, a configuration
        file specified with
        <literal>--config-file</literal>
        option must exist
        and the server does not start if it is missing.
      </para>
      <para>
        The configuration options are organized in a hierarchy.
        For
        the rest of this document, the first level of this hierarchy is
        called the section.
        The hierarchical path to a configuration
        option can either be specified
        inline or through indentation.
        For
        example, specifying
      </para>
      <programlisting><![CDATA[
level1a:
  option1: value1
  level2:
    option1: value2
level1b:
  option1: value3
]]></programlisting>
      <para>
        is equivalent to specifying
      </para>
      <programlisting><![CDATA[
level1a.option1: value1
level1a.level2.option1: value2
level1b:option1: value3
]]></programlisting>
      <para>
        The default values specified in this document are the
        default values
        that are used when a configuration option is not
        specified at all, not
        the value of the option that is specified
        in the configuration file
        distributed as part of the binary
        distribution or Debian package.
      </para>
      <para>
        This section only describes the part of the configuration that
        is stored
        in the per-server configuration file, not the
        configuration that is
        stored in the database.
        Regarding the latter
        one, please refer to
        <xref linkend="server.admin_ui" />
        .
      </para>

      <section xml:id="server.configuration.cassandra">
        <title>Cassandra cluster</title>
        <para>
          The
          <literal>cassandra</literal>
          section configures the server’s
          connection to the Cassandra
          cluster.
        </para>

        <section>
          <title>Hosts</title>
          <para>
            The
            <literal>cassandra.hosts</literal>
            option specifies the list
            of hosts which are used for
            initially establishing the connection
            with the Cassandra
            cluster.
            This list does not have to contain all Cassandra
            hosts because all
            hosts in the cluster are detected
            automatatically once the
            connection to at least one host has
            been established.
            However, it is still a good idea to specify
            more than one host here
            because this will ensure that the
            connection can be established
            even if one of the hosts is
            down when the Cassandra PV Archiver
            server is started.
          </para>
          <para>
            By default, the list only contains
            <literal>localhost</literal>
            .
            The list of hosts has to be specified as a YAML list, using
            the
            regular or the inline list syntax. For example, a list
            specifying
            three hosts might look like this:
          </para>
          <programlisting><![CDATA[
cassandra:
  hosts:
    - server1.example.com
    - server2.example.com
    - server3.example.com
]]></programlisting>
        </section>

        <section>
          <title>Port</title>
          <para>
            The
            <literal>cassandra.port</literal>
            option specifies the port
            number on which the Cassandra hosts
            are listening for incoming
            connections (for Cassandra’s
            native protocol).
            The default value is 9042, which is also
            the default value used by
            Cassandra.
          </para>
        </section>

        <section>
          <title>Keyspace</title>
          <para>
            The
            <literal>cassandra.keyspace</literal>
            option specifies the name
            of the keyspace in which the
            Cassandra PV Archiver stores its data.
            The default value is
            <literal>pv_archive</literal>
            .
            While strictly speaking mixed-case names are allowed, the
            use of
            such names is discouraged because many tools have
            problem with them
            and they typically require quoting.
            For this
            reason, the keyspace name should be all lower-case when
            possible.
          </para>
        </section>

        <section>
          <title>Username</title>
          <para>
            The
            <literal>cassandra.username</literal>
            option specifies the
            username that is specified when
            authenticating with the Cassandra
            cluster.
            When empty, the
            connection to the Cassandra cluster is established
            without
            trying to authenticate the client.
            The default value is the
            empty string (no authentication).
          </para>
        </section>

        <section>
          <title>Password</title>
          <para>
            The
            <literal>cassandra.password</literal>
            option specifies the
            password that is specified when
            authenticating with the Cassandra
            cluster.
            The password is
            only used when the username is not empty.
            The default value
            is the empty string.
          </para>
        </section>

        <section xml:id="server.configuration.cassandra.fetch_size">
          <title>Fetch size</title>
          <para>
            The
            <literal>cassandra.fetchSize</literal>
            option specifies the
            default fetch size that is used when
            reading data from the Cassandra
            database.
            The fetch size
            specifies how many rows are read from the database in
            a
            single page.
            Specifying a larger value typically improves
            performance when
            processing a query that returns many rows,
            but results in more
            memory usage in both the database server
            and the client because the
            full page of rows has to be kept
            in memory.
          </para>
          <para>
            The default value is zero, which causes the default
            fetch size of
            the Cassandra driver to be used.
            As of version
            3.1.4 of the Cassandra driver, that default fetch size
            is
            5000 rows.
            If specified, this option has to be set to an
            integer between 0 and
            2147483647.
          </para>
          <para>
            The fetch size specified here is only used for queries
            that do not
            explicitly specify a fetch size.
          </para>
        </section>

        <section>
          <title>Use local consistency level</title>
          <para>
            The
            <literal>cassandra.useLocalConsistencyLevel</literal>
            option
            specifies the consistency level that is used for all
            database
            operations.
            The default value is
            <literal>false</literal>
            .
            This option only has an effect when the Cassandra cluster
            is
            distributed across multiple data centers.
            By setting this
            option to
            <literal>true</literal>
            , the
            <literal>LOCAL_QUORUM</literal>
            consistency level is used where
            usually the
            <literal>QUORUM</literal>
            consistency level would be
            used.
            In the same way, the
            <literal>LOCAL_SERIAL</literal>
            consistency
            level is used instead of the
            <literal>SERIAL</literal>
            consistency
            level.
          </para>
          <para>
            This option must only be enabled if only a single data
            center makes
            modifications to the data and all other data
            centers only use the
            database for read access.
            In this case,
            enabling this option can reduce the latency of
            operations
            because the client only has to wait for nodes local to
            the
            data center.
            The most likely scenario is a situation where
            all nodes running the
            Cassandra PV Archiver servers are in a
            single data center, but there
            is a second data center to
            which all data is replicated for disaster
            recovery.
          </para>
          <important>
            <para>
              Never enable this option when there is more than one
              data center
              that is used for write access to the database.
              In this case, enabling this option will lead to data
              corruption
              because operations that are expected to result
              in a consistent
              state might actually leave inconsistencies.
            </para>
            <para>
              This option merely provides a performance optimization, so
              in case
              of doubt, leave it at its default value of
              <literal>false</literal>
              .
            </para>
          </important>
        </section>
      </section>

      <section xml:id="server.configuration.server">
        <title>Archiving server</title>
        <para>
          The
          <literal>server</literal>
          section configures the archiving server
          (for example the ID
          assigned to each server instance and on which
          address and ports
          the archiving server listens).
          While the address and port
          settings can usually be left at their
          defaults the server’s ID
          has to be set.
        </para>

        <section>
          <title>Server UUID</title>
          <para>
            Each server in the cluster is identified by a unique ID
            (UUID).
            As this UUID has to be unique for each server, there
            is no
            reasonable default value, but it has to be specified
            explicitly.
            The server’s UUID can be specified using the
            <literal>server.uuid</literal>
            option.
            Alternatively, it can be specified by passing the
            <literal>--server-uuid</literal>
            parameter to the server’s start
            script.
          </para>
          <important>
            <para>
              Starting two server instances with the same UUID
              results in data
              corruption, regardless of whether these
              instances are started on
              the same host or different hosts.
              For this reason, care should be taken to ensure that each
              UUID is
              only used for exactly one process.
            </para>
          </important>
        </section>

        <section>
          <title>Server UUID file</title>
          <para>
            As an alternative to specifying the server’s UUID in the
            configuration file or on the command line, it is possible to
            have a
            separate file that specifies the UUID.
            The path to this
            file can be specified with the
            <literal>server.uuidFile</literal>
            option.
            If this file exists, it is expected to contain a
            single line with
            the UUID that is then used as the server’s
            UUID.
            If this file does not exist, the server tries to create
            it on
            startup, using a randomly generated UUID.
            By default
            this option is not set so that the server expects an
            explicitly specified UUID.
            This option is particularly useful
            in an environment where servers
            are deployed automatically
            and should thus automatically generate a
            UUID the first time
            they are started.
          </para>
        </section>

        <section>
          <title>Listen address</title>
          <para>
            The
            <literal>server.listenAddress</literal>
            option specifies the IP
            address (or the hostname resolving to
            the IP address) on which the
            server listens for incoming
            connections.
            If it is empty (the default), the server listens
            on the first
            non-loopback address that is found.
            This means
            that typically, this option only has to be set for
            servers
            that have more than one (non-loopback) interface.
          </para>
          <para>
            The specified address is used for the administrative
            user-interface,
            the archive-access interface, and the
            inter-node communication
            interface.
            In addition to the
            specified address, the administrative
            user-interface and the
            archive-access interface are also made
            available on the
            loopback address.
          </para>
          <para>
            This option should never be set to
            <literal>localhost</literal>
            ,
            <literal>127.0.0.1</literal>
            ,
            <literal>::1</literal>
            , or any other
            loopback address because other servers will
            try to contact the
            server on the specified address and
            obviously this will lead to
            unexpected results when the
            address is a loopback address.
          </para>
        </section>

        <section>
          <title>Admin port</title>
          <para>
            The
            <literal>server.adminPort</literal>
            option specifies the TCP
            port number on which the
            administrative user-interface is made
            available.
            The default
            is port 4812.
          </para>
        </section>

        <section>
          <title>Archive access port</title>
          <para>
            The
            <literal>server.archiveAccessPort</literal>
            option specifies the
            TCP port number on which the
            archive-access interface is made
            available.
            The default is
            port 9812.
            The archive-access interface is the web-interface
            through which
            clients access the data stored in the archive.
          </para>
        </section>

        <section>
          <title>Inter-node communication port</title>
          <para>
            The
            <literal>server.interNodeCommunicationPort</literal>
            option
            specifies the TCP port number on which the inter-node
            communication
            interface is made available.
            The default is port
            9813.
            Like the name suggests, the inter-node communication
            interface is
            used for internal communication between
            Cassandra PV Archiver
            servers that is needed in order to
            coordinate the cluster operation
            (for example in case of
            configuration changes).
          </para>
        </section>

        <section
          xml:id="server.configuration.server.inter_node_communication_request_timeout">
          <title>Inter-node communication request timeout</title>
          <para>
            The
            <literal>server.interNodeCommunicationRequestTimeout
            </literal>
            option specifies the timeout used for the communication
            between
            nodes.
            The timeout is specified in milliseconds.
            If
            chosen too low, complex requests (e.g. a request to modify
            the
            configuration of many channels when importing a
            configuration file)
            may time out.
            If chosen too high, requests
            will take a very long time before
            timing out in case of a
            sudden server crash or network disruption.
          </para>
          <para>
            The default value is 900000 milliseconds (15 minutes).
            Valid values are integer numbers between 1 and 2147483647.
          </para>
        </section>
      </section>

      <section xml:id="server.configuration.throttling">
        <title>Throttling</title>
        <para>
          The
          <literal>throttling</literal>
          section contains options for
          throttling database operations.
          The Cassandra PV Archiver server tries to run database
          operations in
          parallel in order to reduce the effective latency
          of complex
          operations (e.g. operations involing many channels).
          However, depending on the exact configuration of the Cassandra
          cluster
          (for example the size of the cluster, network bandwidth
          and latency,
          hardware used for the cluster, load caused by
          other applications), the
          number of operations that can safely
          be run in parallel might differ.
        </para>
        <para>
          When running too many operations in parallel, this results
          in some of
          the operations timing out.
          This can be avoided by
          reducing the number of operations allowed to
          run in parallel.
          On the other hand, when operations never time out, one might
          try to
          increase the limits in order to improve the performance.
        </para>
        <para>
          The limits can be controlled separately for read and write
          operations
          and for operations touching the channels’ meta-data
          (for example the
          configuration and information about sample
          buckets) and the actual
          samples.
          Operations modifying channel
          meta-data are typically carried out using
          the
          <literal>SERIAL</literal>
          consistency level, so in this case write
          operations typically
          are more expensive than read operations.
          Thus the limit for
          write operations should be lower than the limit for
          read
          operations.
          In the case of operations dealing with actual
          samples, read operations
          typically are more expensive than
          write operation (due to how
          Cassandra works internally), so the
          limit for read operations shold be
          lower than the limit for
          write operations.
        </para>
        <note>
          <para>
            When trying to optimize the throttling settings, it can
            be helpful
            to connect to the Cassandra PV Archiver server via
            JMX (for example
            using JConsole from the JDK).
            The current
            number of operations that are running and waiting is
            exposed
            via MBeans, so that it is possible to monitor how changing
            the throttling parameters affects the operation.
          </para>
        </note>

        <section>
          <title>Max. concurrent channel meta-data read statements
          </title>
          <para>
            The
            <literal>throttling.maxConcurrentChannelMetaDataReadStatements
            </literal>
            configuration option controls how many read operations for
            channel
            meta-data should be allowed to run in parallel.
            Usually, these are statements reading from the
            <literal>channels</literal>
            ,
            <literal>channels_by_server</literal>
            ,
            and
            <literal>pending_channel_operations_by_server</literal>
            tables.
            Typically, this limit should be greater than the
            limit set by the
            <literal>throttling.maxConcurrentChannelMetaDataWriteStatements
            </literal>
            option.
            The default value is 64.
          </para>
        </section>

        <section>
          <title>Max. concurrent channel meta-data write statements
          </title>
          <para>
            The
            <literal>throttling.maxConcurrentChannelMetaDataWriteStatements
            </literal>
            configuration option controls how many write operations for
            channel
            meta-data should be allowed to run in parallel.
            Usually, these are statements writing to the
            <literal>channels</literal>
            ,
            <literal>channels_by_server</literal>
            ,
            and
            <literal>pending_channel_operations_by_server</literal>
            tables.
            Typically, such operations are light-weight
            transactions and thus
            this limit should be less than the
            limit set by the
            <literal>throttling.maxConcurrentChannelMetaDataReadStatements
            </literal>
            option.
            The default value is 16.
          </para>
        </section>

        <section>
          <title>Max. concurrent control-system support read statements
          </title>
          <para>
            The
            <literal>throttling.maxConcurrentControlSystemSupportReadStatements
            </literal>
            configuration option controls how many read operations the
            control-system supports (all of them combined) are allowed
            to run in
            parallel.
            Usually, these are statements that read
            actual samples and thus read
            from the tables used by the
            control-system support(s).
            Typically, this limit should be
            less than the limit set by the
            <literal>throttling.maxConcurrentControlSystemSupportWriteStatements
            </literal>
            option, but significantly greater than the limit set by the
            <literal>throttling.maxConcurrentChannelMetaDataReadStatements
            </literal>
            option.
            The default value is 128.
          </para>
        </section>

        <section>
          <title>Max. concurrent control-system support write statements
          </title>
          <para>
            The
            <literal>throttling.maxConcurrentControlSystemSupportWriteStatements
            </literal>
            configuration option controls how many write operations the
            control-system supports (all of them combined) are allowed
            to run in
            parallel.
            Usually, these are statements that write
            actual samples (for each
            sample that is written, an
            <literal>INSERT</literal>
            statement is
            triggered) and that thus write to the tables
            used by the
            control-system support(s).
            Typically, this limit
            should be greater than the limit set by the
            <literal>throttling.maxConcurrentControlSystemSupportReadStatements
            </literal>
            option and significantly greater than the limits set by the
            <literal>throttling.maxConcurrentChannelMetaDataReadStatements
            </literal>
            and
            <literal>throttling.maxConcurrentChannelMetaDataWriteStatements
            </literal>
            options.
            The default value is 512.
          </para>
        </section>

        <section
          xml:id="server.configuration.throttling.sample_decimation.max_fetched_samples_in_memory">
          <title>
            Max. number of samples fetched into memory for sample
            decimation
          </title>
          <para>
            The
            <literal>throttling.sampleDecimation.maxFetchedSamplesInMemory
            </literal>
            configuration option controls how many samples may be
            fetched into
            memory when generating decimated samples.
          </para>
          <para>
            The sample decimation process might consume a lot of
            memory when
            generating decimated samples from already
            existing source samples
            for a lot of channels.
            The amount of
            samples that may be fetched into memory is directly
            connected to memory usage.
            Each fetched sample occupies about
            1 KB of memory (for scalar
            Channel Access samples), so one
            million samples are roughly
            equivalent to 1 GB of memory.
          </para>
          <para>
            As the exact number of samples returned by a fetch operation
            cannot
            be known in advance, this threshold might actually be
            exceeded
            slightly.
            The
            <link
              linkend="server.configuration.throttling.sample_decimation.max_running_fetch_operations">
              <literal>maxRunningFetchOperations</literal>
            </link>
            option can be used to control by how much the threshold may
            be exceeded.
          </para>
          <para>
            The default value for this option is 1000000 samples.
          </para>
        </section>

        <section
          xml:id="server.configuration.throttling.sample_decimation.max_running_fetch_operations">
          <title>
            Max. number of concurrent fetch operations for sample
            decimation
          </title>
          <para>
            The
            <literal>throttling.sampleDecimation.maxRunningFetchOperations
            </literal>
            configuration option controls how many fetch operations may
            run in
            parallel when generating decimated samples.
          </para>
          <para>
            As the exact number of samples returned by a fetch operation
            cannot
            be known in advance, the threshold set by the
            <link
              linkend="server.configuration.throttling.sample_decimation.max_fetched_samples_in_memory">
              <literal>maxFetchedSamplesInMemory</literal>
            </link>
            option might actually be exceeded slightly.
            This
            configuration option can be used to control by how much the
            threshold may be exceeded.
            The max. number of running fetch
            operations multiplied by the
            <link linkend="server.configuration.cassandra.fetch_size">fetch size</link>
            is the max. number of samples by which the limit might be
            exceeded.
          </para>
          <para>
            The default value for this option is 20.
          </para>
        </section>
      </section>

      <section xml:id="server.configuration.control_system_support">
        <title>Control-system supports</title>
        <para>
          The
          <literal>controlSystemSupport</literal>
          section contains the
          configuration options for the various
          control-system supports.
          For each available control-system
          support, this section has a
          corresponding sub-section.
          The
          configuration options in these sub-sections are not handled by
          the Cassandra PV Archiver server itself but passed as-is to
          the
          respective control-system support.
          For this reason, the
          names of the available options entirely depend
          on the
          respective control-system support.
          Please refer to the
          documentation of the respective control-system
          support for
          details.
          For example, the documentation for the Channel Access
          control-system
          support is available in
          <xref linkend="channel_access" />
          .
        </para>
      </section>

      <section xml:id="server.configuration.logging">
        <title>Logging</title>
        <para>
          The Cassandra PV Archiver server is based on the
          <link xlink:href="http://projects.spring.io/spring-boot/">Spring Boot</link>
          framework.
          For this reason, the options supported for
          configuring logging are
          actually the same ones that are
          supported by Spring Boot.
          These options are
          <link
            xlink:href="http://docs.spring.io/spring-boot/docs/${spring.boot.version}/reference/htmlsingle/#boot-features-logging">documented</link>
          in the
          <link
            xlink:href="http://docs.spring.io/spring-boot/docs/${spring.boot.version}/reference/htmlsingle/">Spring Boot Reference Guide</link>
          .
          The Cassanra PV Archiver server uses
          <link xlink:href="http://logback.qos.ch/">Logback</link>
          as its logging backend, so the specifics of
          <link
            xlink:href="http://docs.spring.io/spring-boot/docs/${spring.boot.version}/reference/htmlsingle/#howto-configure-logback-for-logging">how to configure Logback for Spring Boot</link>
          might also be interesting.
        </para>
        <para>
          In order to get started more easily, this section contains
          a few
          pointers on how the logging configuration can be
          modified.
        </para>

        <section>
          <title>Log levels</title>
          <para>
            The log level can be set both globally and for specific
            subtrees of
            the class hierarchy.
            When specifying different log
            levels for different parts of the
            hierarchy, more specific
            definitions (the ones covering a smaller
            sub-tree of the
            hierarchy) take precedence over more general
            definitions.
          </para>
          <para>
            The available log levels are
            <literal>ERROR</literal>
            ,
            <literal>WARN</literal>
            ,
            <literal>INFO</literal>
            ,
            <literal>DEBUG</literal>
            , and
            <literal>TRACE</literal>
            .
            Each log level contains the preceding log levels (for
            example
            the log level
            <literal>INFO</literal>
            also contains
            <literal>ERROR</literal>
            and
            <literal>WARN</literal>
            ).
          </para>
          <para>
            The log level for the root of the hierarchy (that is used
            for all
            loggers that do not have a more specific definition)
            is set through
            the
            <literal>logging.root.level</literal>
            option.
            By default, this log level is set to
            <literal>INFO</literal>
            .
            This results in a lot of diagnostic messages being logged,
            so you
            might want to consider reducing it to
            <literal>WARN</literal>
            .
          </para>
          <para>
            The log level for individual parts of the hierarchy can be
            set by
            using a configuration option containing the path to
            the respective
            hierarchy level.
            For example, in order to
            enable DEBUG messages for all classes in
            the
            <literal>com.aquenos.cassandra.pvarchiver</literal>
            package (and
            its sub-packages), one could set
            <literal>logging.com.aquenos.cassandra.pvarchiver.level
            </literal>
            to
            <literal>DEBUG</literal>
            .
          </para>
        </section>

        <section>
          <title>Log file</title>
          <para>
            The path to the log file can be specified using the
            <literal>logging.file</literal>
            option.
            If no log file is specified (the default),
            log
            messages are only written to the standard output.
            In order to
            log to more than one log file (for example depending
            on the
            log level or the class writing the log message) or in order
            to disable logging to the standard output, one has to
            specify a
            custom logback configuration file (see the next
            section).
          </para>
        </section>

        <section>
          <title>Logging configuration file</title>
          <para>
            When the configuration options directly available through
            the
            Cassandra PV Archiver server configuration-file are not
            sufficient,
            one can specify a custom Logback configuration
            file.
            The path to this file is specified using the
            <literal>logging.config</literal>
            option.
            The
            <link
              xlink:href="http://docs.spring.io/spring-boot/docs/${spring.boot.version}/reference/htmlsingle/#howto-configure-logback-for-logging">information</link>
            available in the
            <link
              xlink:href="http://docs.spring.io/spring-boot/docs/${spring.boot.version}/reference/htmlsingle/">Spring Boot Reference Guide</link>
            might be useful when using this option.
          </para>
        </section>
      </section>

      <section xml:id="server.configuration.environment_variables">
        <title>Environment variables</title>
        <para>
          In addition to the configuration options that can be specified
          in the
          server’s configuration file, there are two environment
          variables that
          can be passed to the server’s startup script.
          When using the Debian package, these environment variables
          should be
          set in the file
          <literal>/etc/default/cassandra-pv-archiver-server</literal>
          .
        </para>
        <para>
          The first environment variable is
          <envar>JAVA_HOME</envar>
          .
          It specifies the path to the JRE.
          When starting the Java
          process, the server’s startup scripts uses the
          <literal>$JAVA_HOME/bin/java</literal>
          executable
          (
          <literal>%JAVA_HOME%/bin/java.exe</literal>
          on Windows).
          When
          <envar>JAVA_HOME</envar>
          is not set, the startup script uses the
          <literal>java</literal>
          executable that is in the search
          <literal>PATH</literal>
          of the shell executing the startup script.
        </para>
        <para>
          The second environment variable is
          <envar>JAVA_OPTS</envar>
          .
          When set, the value of this environment variable is added to
          the
          parameters passed to the
          <literal>java</literal>
          executable.
          It can be used to configure JVM options like the
          maximum heap size.
        </para>
      </section>
    </section>

    <section xml:id="server.admin_ui">
      <title>Administrative user interface</title>
      <para>
        The administrative user interface (UI) is provided in form of a
        web UI.
        It is available for each Cassandra PV Archiver server and
        (if the port
        has not been changed manually) can be accessed at
        <uri>http://myserver.example.com:4812/</uri>
        .
      </para>
      <para>
        The administrative UI is the main point for monitoring the
        operation of
        the Cassandra PV Archiver cluster and configuring
        archived channels.
        Unlike the server’s configuration file (see
        <xref linkend="server.configuration" />
        ), which usually is only setup
        once and then rarely changes, the
        admin UI is used for regular
        configuration tasks like adding,
        modifying, and removing channels.
        All these configuration changes
        take effect immediately and do not
        require a restart of the
        Cassandra PV Archiver server.
        All channels can be configured
        through the UIs of all Cassandra PV
        Archiver servers, regardless
        of which server actually archives the
        respective channel.
      </para>
      <para>
        For all functions of the administrative UI to work
        correctly, JavaScript
        has to be enabled in the browser.
        Due to the
        extensive use of JavaScript, CSS 3, and web fonts, only
        fairly
        modern versions of most browsers are supported.
        In particular,
        Microsoft Internet Explorer is only supported starting
        with
        version 11.
      </para>
      <para>
        The UI is divided into four sections which can be acccessed
        through the
        navigation bar at the top of the UI (see
        <xref linkend="overview.server.fig.admin_ui_navigation_bar_full" />
        ).
        On very narrow screens (e.g. on smartphones), the navigation
        bar is
        hidden and has to be opened by pressing the button with
        the three
        horizontal bars (see
        <xref linkend="overview.server.fig.admin_ui_navigation_bar_collapsed" />
        ).
      </para>
      <figure xml:id="overview.server.fig.admin_ui_navigation_bar_full">
        <title>Administrative UI navigation bar (full screen size)
        </title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_server_admin_ui_navigation_bar_full.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <figure xml:id="overview.server.fig.admin_ui_navigation_bar_collapsed">
        <title>Administrative UI navigation bar (small screens)</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_server_admin_ui_navigation_bar_collapsed.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        The dashboard provides an overview of the Cassandra PV
        archiver server
        and cluster status.
        The server status is the only
        part of the administrative UI that is
        actually different on each
        of the servers.
        When logged in with administrative privileges,
        the UI has the option to
        remove servers from the cluster view
        when they have been offline for
        some time.
      </para>
      <para>
        The channels section is the section through which the status of
        archived channels can be monitored and through which their
        configuration can be changed.
        This section is discussed in more
        detail in
        <xref linkend="server.admin_ui.channels" />
        .
        The about section provides information about which version of
        the
        Cassandra PV Archiver server is running.
        Finally, the sign in
        section allows for signing in to the UI in order
        to show elements
        that require administrative privileges.
        In general, all actions
        that change the configuration require
        administrative privileges,
        while all functions that do not
        affect the
        Cassandra PV Archiver
        server’s operation can be used without having to
        sign in.
        When the
        user is already signed in, the current username and the option
        to sign out are displayed instead of the sign in button.
      </para>

      <section xml:id="server.admin_ui.authentication">
        <title>Authentication</title>
        <para>
          When signing in to the administrative UI, one has to specify a
          username and a password.
          The Cassandra PV Archiver server
          automatically creates an
          administrative user with the username
          <literal>admin</literal>
          and the
          password
          <literal>admin</literal>
          (case sensitive).
          After having signed in for the first time,
          the password can be changed
          by selecting the corresponding link
          from the menu that opens when
          clicking on the username in the
          navigation bar (see
          <xref linkend="overview.server.fig.admin_ui_change_password" />
          ).
        </para>
        <figure xml:id="overview.server.fig.admin_ui_change_password">
          <title>Changing the password</title>
          <mediaobject>
            <imageobject>
              <imagedata
                fileref="images/cassandra_pv_archiver_server_admin_ui_change_password.png" />
            </imageobject>
          </mediaobject>
        </figure>
        <para>
          The credentials are stored in the Cassandra database, so
          signing in
          and changing the password is only possible while the
          server is
          connected to the Cassandra cluster.
        </para>
      </section>

      <section xml:id="server.admin_ui.channels">
        <title>Managing channels</title>
        <para>
          The channels section of the administrative UI provides
          functions for
          monitoring and configuring channels.
          There are two
          different views how channels can be displayed.
          The “All
          Channels” view shows all channels that exist in the whole
          cluster.
          The other view is opened by selecting a specific
          server and only shows
          the channels that are hosted by that
          server.
          While mostly these two views provide the same
          functionality, there are
          two fundamental differences:
        </para>
        <para>
          The “All Servers” view displays all channels for the whole
          cluster.
          For this reason, it does not display the status of
          each channel.
          The status of a channel is only known by its
          server and collecting the
          status of all channels could take a
          very long time when there are many
          servers.
          For this reason, the
          status of a channel is only displayed in the
          per-server view or
          when selecting a specific channel.
        </para>
        <para>
          The other difference concerns the import and export of
          configuration
          files.
          Configuration files always contain the
          channels managed by a certain
          server.
          For this reason, the
          import and export functions are only available
          from the
          per-server view.
        </para>

        <section xml:id="server.admin_ui.channels.add">
          <title>Adding a channel</title>
          <para>
            A channel can be added by clicking on the
            <guibutton>Add Channel</guibutton>
            button displayed above the
            channel list.
            This button is only
            shown when the user is signed in and has
            administrative
            privileges.
            When adding a channel, a number of options can be
            specified, a few
            of them being mandatory (see
            <xref linkend="overview.server.fig.admin_ui_add_channel" />
            ).
          </para>
          <figure xml:id="overview.server.fig.admin_ui_add_channel">
            <title>Add channel view</title>
            <mediaobject>
              <imageobject>
                <imagedata
                  fileref="images/cassandra_pv_archiver_server_admin_ui_add_channel.png" />
              </imageobject>
            </mediaobject>
          </figure>
          <para>
            The channel name is mandatory and specifies the name
            under which the
            channel is going to be identified in the
            cluster.
            For this reason, the channel name has to be unique
            within the whole
            cluster.
            Typically, the channel name is also
            the name that is used by the
            control-system support when
            trying to monitor the corresponding
            process variable.
            However, some control-system supports may choose to specify
            this
            information separately.
          </para>
          <para>
            Selecting a server that hosts the channel is also
            mandatory.
            This means that this server is responsible for
            managing the channel,
            starting the control-system support and
            initializing it with the
            channel’s configuration when the
            server goes online.
            When opening the “Add Channel” view from
            the per-server view, this
            option is already set to point to
            the respective server.
            When opening it from the “All
            Channels” view, the server has to be
            selected.
          </para>
          <para>
            The “Control System” option is mandatory and specifies
            the
            control-system support for the channel.
            Unlike all other
            options, this option cannot be changed after
            creating the
            channel and is fixed until the channel is deleted (also
            deleting all samples that have been archived for the
            channel).
            The reason for this restriction is that the format
            of the archived
            data depends on the control-system support
            and there is no generic
            way how data archived by one
            control-system support could be
            converted to the format
            required by another control-system support.
          </para>
          <para>
            The “Enable Archiving” flag is enabled by default.
            This
            means that the control-system support for the channel is
            initialized when the server hosting the channel goes online.
            When disabling this option, the control-system support is
            not
            started, but apart from this the channel can be used like
            any other
            channel.
            In particular, decimated samples (if
            configured) are still being
            generated and the archived
            samples can be accessed.
            Disabling archiving is useful when a
            channel is not used any longer
            (for example because the
            corresponding process variable has been
            removed from the
            control-system), but its data might still be useful
            for
            historic purposes.
            As long as archiving is disabled, no new
            samples are going to be
            archived for the channel, even if the
            corresponding process variable
            still exists and is active.
          </para>
          <para>
            The “Decimation Levels” section of the “Add Channel” view
            defines
            which decimation levels exist and how long their
            retention period
            is.
            Please refer to
            <xref linkend="overview" />
            ,
            <xref linkend="overview.decimated_samples" />
            for an introduction to
            the concept of decimation levels.
            The
            retention period specifies how long samples are kept before
            they
            are deleted.
            A sample is deleted when the difference
            between its time stamp and
            the time stamp of the newest
            sample that exists in the same
            decimation level is greater
            than the specified time period.
            As only complete sample
            buckets are deleted, a sample might actually
            be kept a bit
            longer than the specified amount of time.
          </para>
          <para>
            A retention period of zero specifies that samples in the
            respective
            decimation level are supposed to be kept
            indefinitely.
            Each decimation level must have a retention
            period that is greater
            than or equal to the retention period
            of all decimation levels with
            a shorter decimation period.
            This also means that the retention period of all decimation
            levels
            has to be greater than or equal to the retention
            period of the raw
            samples.
            As a retention period of zero
            specifies indefinite retention, it is
            considered greater than
            all other retention periods.
          </para>
          <para>
            The “Control-System Options” sections of the “Add
            Channel” view
            allows for specifying configuration options
            that are passed to the
            control-system support as-is.
            Control-system options are not verified except for checking
            that
            each control-system option is only specified once.
            However, specifying a control-system option that is not
            supported by
            the corresponding control-system support or
            specifying an invalid
            value for a supported option can result
            in the control-system
            support reporting an error when the
            channel is initialized.
            In this case, the channel is put into
            an error state and archiving
            is disabled until the
            configuration is fixed.
          </para>
          <para>
            As the support for control-system options entirely depends
            on the
            respective control-system support, please refer to the
            control-system support’s documentation for a list of
            supported
            options.
            The documentation for the Channel Access
            control-system support can
            be found in
            <xref linkend="channel_access" />
            .
          </para>
          <para>
            After clicking
            <guibutton>Add Channel</guibutton>
            the administrative
            UI verifies that the specified options are
            valid.
            If there is an error, the “Add Channel” view is shown
            again with the
            problematic fields being marked.
            Otherwise, the
            channel is added immediately and the details view for
            the
            newly created channel is shown.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.details">
          <title>Inspecting a channel</title>
          <para>
            A channel’s configuration and status can be inspected by
            clicking on
            the channel name in the channel list.
            In addition
            to the channel’s configuration some status information
            is
            shown.
            Which information is shown depends on the channel’s
            state.
          </para>
          <para>
            Typically, the channel’s state (OK, Disabled,
            Disconnected, or
            Error) is shown.
            If the channel is in the
            error state, an error message is shown too.
            In addition to
            that, the number of samples that have been dropped,
            that
            skipped back in time, and that have been written is shown.
            These numbers are counted since the last time the channel
            has been
            initialized.
            A channel is initialized when its server
            goes online and when its
            configuration is changed.
          </para>
          <para>
            The number of samples dropped is the number of samples
            that were
            queued by the control-system support for archiving,
            but actually
            were not written to the archive because there
            was an overflow of the
            queue.
            Samples are queued for up to
            thirty seconds.
            After this time, they are removed from the
            queue when new samples
            arrive.
            This mechanism helps to avoid a
            denial of service due to unbounded
            memory consumption when a
            control-system support constantly queues
            samples more quickly
            they can be written.
            This number might be non-zero due to
            load peaks, in particular
            during server startup.
            However, when
            it grows constantly, this is an indication that the
            control-system supports writes too many samples and either
            the
            sample rate should be reduced or the server load should
            be reduced
            by archiving fewer channels on this server (and
            possibly increasing
            the number of database servers).
          </para>
          <para>
            The number of samples that skipped back in time
            typcially is very
            small.
            It counts the number of samples that
            were queued by the
            control-system support for archiving, but
            actually were not written
            because they had a time stamp less
            than or equal to the time stamp
            of the most recent sample.
            Such a situation typically occurs when a channel is
            initialized and
            the control-system support tries to archive a
            sample that has
            already been received before.
            A similar
            situation can occur when the control-system support loses
            its connection to the underlying control-system and
            reestablishes it
            later.
            When this number grows constantly, it
            can indicate a problem with
            the clock that is used for the
            sample’s time-stamp.
          </para>
          <para>
            The number of samples written is exactly what the name
            suggests.
            It counts the samples that have actually been
            successfully written
            to the database.
          </para>
          <para>
            When signed in with administrative privileges, the
            channel details
            view also provides buttons for modifying the
            channel’s configuration
            These buttons are shown at the top of
            the view, above the channel’s
            status.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.edit">
          <title>Modifying a channel’s configuration</title>
          <para>
            After adding a channel, its configuration can be changed.
            In
            order to change the configuration, one first opens the
            channel’s
            <link linkend="server.admin_ui.channels.details">details view</link>
            and then clicks on the
            <guibutton>Edit Channel</guibutton>
            button.
            Modifying a channel’s configuration requires
            administrative
            privileges.
          </para>
          <para>
            The “Edit Channel” view is very similar to the
            <link linkend="server.admin_ui.channels.add">“Add Channel” view</link>
            ,
            the main difference being that the channel name, the
            server, and the
            control-system cannot be changed.
            A channel
            can be moved to a different server and its name can be
            changed, but these actions cannot be triggered from the
            “Edit Channel” view, but are handled
            <link linkend="server.admin_ui.channels.move_and_rename">separately</link>
            .
            A channel’s control-system must be specified when adding
            the channel
            and cannot be changed later.
          </para>
          <para>
            Care should be taken when modifying retention periods:
            When decreasing the retention period of a decimation level
            (or the
            raw samples), samples that are older than the time
            specified by the
            new retention period might get deleted
            immediately.
            The deletion of old samples happens
            asynchronously, so there is a
            small chance that samples might
            be retained for a short moment
            before actually being deleted,
            but one cannot rely on that.
          </para>
          <para>
            When removing a decimation level, the corresponding
            samples are
            deleted immediately and cannot be recovered.
            When
            the decimation level is added back later, the decimated
            samples
            have to be generated again.
            When the decimation level
            of the samples used as the source for
            generating the
            decimated samples has a shorter retention period than
            the
            decimation leve that has been removed and readded, it is
            possible that not all decimated samples can be generated
            again and
            thus data is lost unrecoverably.
          </para>
          <para>
            When changing a channel’s configuration, archiving of
            the channel
            has to be stopped for a short amount of time in
            order to apply the
            configuration changes.
            This happens
            automatically and typically takes less than a second.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.remove">
          <title>Removing a channel</title>
          <para>
            When a channel is not needed any longer, it can be removed
            from the
            archive.
            Removing a channel results in the immediate
            deletion of all its data
            (including all samples).
            When a
            channel should not be archived any longer, but the existing
            data should be kept, the channel should not be removed, but
            it
            should only be disabled.
            A channel can be disabled by
            <link linkend="server.admin_ui.channels.edit">editing its configuration</link>
            .
          </para>
          <para>
            In order to remove a channel, one first has to go to the
            channel’s
            <link linkend="server.admin_ui.channels.details">details view</link>
            .
            In the details view, one can click on the
            <guibutton>Remove Channel</guibutton>
            button, and after confirming
            that the channel should in fact
            be removed, the channel and all its
            data are deleted
            immediately.
          </para>
          <para>
            Removing a channel requires administrative privileges.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.move_and_rename">
          <title>Moving and renaming a channel</title>
          <para>
            It is possible to move a channel to a different server and
            to rename
            an existing channel.
            Both functions are available
            from the channel’s
            <link linkend="server.admin_ui.channels.details">details view</link>
            .
          </para>
          <para>
            For moving a channel, one clicks on the
            <guibutton>Move Channel</guibutton>
            button and after selecting the
            server to which the channel
            shall be moved, it is shutdown and on
            the old server and
            brought back up on the new one.
            In order to compensate for
            potential clock skew between different
            servers, archiving for
            the channel has to be disabled for some time,
            but this should
            typically not take longer than 30 seconds.
          </para>
          <para>
            For renaming a channel, one clicks on the
            <guibutton>Rename Channel</guibutton>
            button and enters the new name
            for the channel.
            The new name
            must be a name that is not already used for a different
            channel.
            After entering the name and confirming, the channel
            is renamed.
            Renaming the channel involves copying some
            meta-data, which might
            take a few seconds.
            Archiving is
            disabled while the rename operation is in progress and
            is
            automatically started again once the operation has finished.
          </para>
          <para>
            Moving or renaming a channel requires administrative
            privileges.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.import">
          <title>Importing channel configurations</title>
          <para>
            When adding or modifying a large number of channels at
            the same
            time, the import function can be useful because it
            allows for using
            external scripts for generating a
            configuration file that can then
            be imported into the
            Cassandra PV Archiver.
          </para>
          <para>
            The import function can be accessed by clicking on the
            <guibutton>Import Configuration</guibutton>
            button in the channels
            overview.
            The
            <guibutton>Import Configuration</guibutton>
            button is only
            available in the per-server view, not in the
            “All Channels” view.
            The reason is that the configuration
            format does not allow for
            specifying a server for each
            channel and thus the server needs to be
            specified for all
            channels when importing the file.
          </para>
          <para>
            The configuration file has to be supplied in an XML format.
            The XML namespace URI for the channel configuration is
            <uri>http://www.aquenos.com/2016/xmlns/cassandra-pv-archiver-configuration
            </uri>
            and the format is specified by an
            <link
              xlink:href="http://www.aquenos.com/2016/xmlns/cassandra-pv-archiver-configuration-${project.version}.xsd">XML Schema file</link>
            .
          </para>
          <para>
            When importing a configuration file, one can specify
            which kind of
            actions should be taken.
            One can choose to add
            channels that exist in the configuration file,
            but do not yet
            exist in the Cassandra PV Archiver configuration.
            One can
            also choose to update channels that already exist, but have
            a different configuration in the configuration file.
            Finally, one can choose to remove channels that exist in the
            server’s configuration, but not in the configuration file.
            The last option is particularly dangerous because it results
            in
            channels being removed unrecoverably without further
            confirmation.
          </para>
          <para>
            If a channel that is specified in the configuration file
            already
            exists, but is managed by a different server or uses
            a different
            control-system support, it is not touched.
            A
            channel’s control-system support cannot be changed and
            moving a
            channel to a different server is only supported
            through the
            <link linkend="server.admin_ui.channels.move_and_rename">explicit move function</link>
            .
          </para>
          <para>
            Importing channel configurations requires administrative
            privileges.
          </para>
        </section>

        <section xml:id="server.admin_ui.channels.export">
          <title>Exporting channel configurations</title>
          <para>
            The configuration of all channels managed by a server can be
            exported into a configuration file.
            This is mainly useful for
            using such a file as a template for
            generating a
            configuration file that can then be used with the
            <link linkend="server.admin_ui.channels.import">import function</link>
            .
            However, it might also be useful to save a certain
            configuration
            state outside of the database in case one want
            to return to this
            configuration at a later point in time.
          </para>
          <para>
            In order to export the current configuration, one has to go
            the
            channels overview.
            The export function is only available
            from the per-server view, not
            the “All Channels” view.
            In the
            channels overview, one has to click on the
            <guibutton>Export Configuration</guibutton>
            button.
            This results in an XML file being generated that can
            then be saved
            to the user’s hard disk.
            The generated file
            conforms to the format that is required by the
            <link linkend="server.admin_ui.channels.import">import function</link>
            .
          </para>
        </section>
      </section>
    </section>

    <section xml:id="server.troubleshooting">
      <title>Troubleshooting</title>
      <para>
        This section gives some hints on how to fix certain problems
        that might
        appear while running the Cassandra PV Archiver server.
        Readers may skip this section and come back later in case they
        experience one of the problems.
      </para>

      <section xml:id="server.troubleshooting.timeouts">
        <title>Timeouts</title>
        <para>
          Apache Cassandra limits the time that is spent trying to
          process a
          statement.
          When a statement cannot be processed within
          this time limit, it fails
          with a timeout error.
          Such an error
          might appear in the form of a message like
          “Cassandra timeout
          during write query at consistency SERIAL…” or a
          similar message
          being displayed when trying to apply configuration
          changes or
          being displayed as the error message for a channel that is
          in
          the error state.
        </para>
        <para>
          Typically, statements time out because the Cassandra cluster
          is
          overloaded with requests and thus cannot process all of them
          in a
          timely manner.
          In this case, reducing the number of
          statements that are run in
          parallel can help alleviate the
          problem.
          When a write statement with a consistency level of
          <literal>SERIAL</literal>
          fails, this is most likely caused by the
          <literal>throttling.maxConcurrentChannelMetaDataWriteStatements
          </literal>
          option having a too large value.
          Please refer to
          <xref linkend="server.configuration.throttling" />
          for
          details regarding the throttling of concurrent statements.
        </para>
        <para>
          Timeouts when reading data might also occur because of too
          many
          tombstones being present.
          In this case, there typically is
          a coressponding message in the log
          file of the Cassandra
          server.
          Please refer to
          <xref linkend="server.troubleshooting.tombstones" />
          for details about handling tombstones.
        </para>
      </section>

      <section xml:id="server.troubleshooting.channel_inconsistencies">
        <title>Inconsistencies in the channels list</title>
        <para>
          There are two ways how channels can be listed:
          All channels
          in the cluster can be listed or only the channels managed
          by a
          certain server can be listed.
          It can happen that these two
          lists get out of sync, so that channels
          are shown in the list
          of all channels, but not in the list for a
          specific server.
        </para>
        <para>
          The reason for this is that the two lists are retrieved in
          different
          ways.
          The all channels list is generated by getting
          the channels from the
          database (technically speaking, there is
          a cache layer involved, but
          typically this layer is not
          responsible for the inconsistencies).
          The per-server list, on
          the other hand, is retrieved from the server’s
          in-memory
          configuration when the server is online.
        </para>
        <para>
          When adding or removing channels fails, it can happen that
          the
          operation actually succeeded up to a point where the
          channel already
          exists in the database, but the server’s
          in-memory configuration has
          not been updated.
        </para>
        <para>
          When a channel that has been removed still exists in the
          per-server
          list, but has been removed from the all channels
          list, forcing a
          reinitialization of the channel usually fixes
          the problem.
          When, on the other hand, a channel that has been
          added exists in the
          all channels list but is missing in the
          per-server list, the only way
          to solve this is by restarting
          the affected server.
        </para>
        <para>
          Usually, either problem only occurs when some database
          operations
          fail due to a transient database problem or
          timeouts.
          Please refer to
          <xref linkend="server.troubleshooting.timeouts" />
          for
          more information about how to fix timeouts.
        </para>
      </section>

      <section xml:id="server.troubleshooting.pending_channel_operation">
        <title>Pending channel operations</title>
        <para>
          Some operations regarding channels (in particular
          configuration
          changes and the creation of new sample buckets)
          require special
          protection in order to avoid data corruption.
          Without this protection, data corruption could happen when the
          server
          crashes after the operation has started but before it
          has completed.
          Because of how Cassandra applies data changes
          and due to possible
          clock skew in distributed systems, this
          mechanism has to ensure that
          no other modification is attempted
          for a certain amount of time after
          such an operation failed.
        </para>
        <para>
          This means that any further modifications (including the
          archiving of
          samples) are blocked for up to ten minutes after
          an operation has
          failed.
          When being initialized, the channel
          switches to the error state with
          an error message like “The
          channel cannot be initialized because an
          operation of type … is
          pending”.
          When trying to make changes to the channel’s
          configuration, a similar
          message is displayed.
        </para>
        <para>
          There is only one way to resolve this issue: Waiting until
          the
          protection period has passed.
          Usually, the channel is
          automatically initialized again after the
          period has passed.
          Otherwise, a reinitialization can be triggered from the
          administrative
          UI.
        </para>
        <para>
          There is a very similar message after moving a channel
          from one server
          to another.
          In this case, further modifications
          are also blocked in order to
          allow for some clock skew between
          servers.
          In contrast to the issue described earlier, the
          protection period is
          very short in this case and the channel is
          typically put back in
          operation after less than 30 seconds.
        </para>
      </section>

      <section xml:id="server.troubleshooting.tombstones">
        <title>Too many tombstones</title>
        <para>
          When deleting data from a Cassandra database, this data is
          actually
          not deleted immediately.
          Instead, special markers
          (so-called tombstones) are inserted in order
          to mark the data
          as deleted.
          Due to how Cassandra works internally, these
          tombstones might not be
          present on all nodes when some of the
          nodes were down while the data
          was being deleted.
          In this case,
          it is important that the tombstones are replicated to
          these
          nodes before they can safely be removed (together with the
          data
          thas has been marked as deleted).
        </para>
        <para>
          The time how long tombstones are kept is configured in
          Cassandra by
          setting the GC grace period.
          It is very important
          that
          <literal>nodetool repair</literal>
          (which
          ensures consistent replication) is run more frequently
          than the time
          specified by the GC grace period.
          After the GC
          grace period has passed, a failed node must not be
          brought back
          online because this would result in deleted data suddenly
          reappearing, which in the context of the Cassandra PV Archiver
          could
          lead to data corruption.
        </para>
        <para>
          When reading data, Cassandra has to keep all the
          tombstones it finds
          on the way, so that data presented by other
          nodes can be checked
          against these tombstones (because it might
          actually have been marked
          as deleted).
          Keeping track of these
          tombstones consumes memory on the coordinator
          node and affects
          performance, which is why Cassandra limits the number
          of
          tombstones that it allows before aborting a query.
          Even before
          hitting this limit, Cassandra starts logging a warning
          message
          to inform the user that a high number of tombstones has been
          detected.
          Such a message might look like “Read … live rows and
          … tombstone cells
          for query SELECT * FROM … WHERE server_id = …
          LIMIT 5000 (see
          tombstone_warn_threshold)”.
        </para>
        <para>
          In the Cassandra PV Archiver, there are three tables where
          such a
          problem is likely to appear: the
          <literal>pending_channel_operations_by_server</literal>
          ,
          <literal>channels</literal>
          , and
          <literal>channels_by_server</literal>
          tables.
          The
          <literal>pending_channel_operations_by_server</literal>
          table
          and (even though less likely) the
          <literal>channels_by_server</literal>
          table are affected when a
          large number of channels is modified,
          in particular when they are
          added or removed.
          The
          <literal>channels</literal>
          tables might be affected when a large
          number of samples is
          deleted in a rather short period of time
          (typically because
          samples are archived at a very high data rate).
        </para>
        <para>
          In general, reducing the GC grace period is a good idea to
          avoid such
          a situation, but the GC grace period must only be
          reduced when
          anti-entropy repairs are run more often.
        </para>
        <para>
          For problems with the
          <literal>pending_channel_operations_by_server</literal>
          table, there
          is a workaround that involves manually deleting
          all data from that
          table.
          Before using this workaround, one has
          to ensure that all Cassandra PV
          Archiver servers have been
          shutdown for at least ten minutes (and stay
          shutdown while
          applying the workaround) and all Cassandra database
          nodes are
          up.
          One can then use the following statement on the CQL shell
          after
          switching to the keyspace used by the Cassandra PV
          Archiver:
        </para>
        <programlisting><![CDATA[
TRUNCATE pending_channel_operations_by_server;
]]></programlisting>
        <para>
          This statement deletes all data for this table, including
          all
          tombstones.
          This is why it is important that all Cassandra
          nodes are up and
          running.
          After applying this statement, the
          Cassandra PV Archiver servers can
          be started again.
        </para>
        <para>
          When this problem appears for the
          <literal>channels_by_server</literal>
          table, adding a new server and
          moving all channels from the
          affected server to the new server can
          help.
          After this, the
          affected server can be brought up again with a new
          UUID (the
          old UUID should not be reused in order to avoid hitting the
          problem again).
        </para>
        <para>
          When this problem appears for the
          <literal>channels</literal>
          table,
          renaming the channel and then renaming it back to the
          original name
          might help.
          However, sometimes this workaround
          will not show any effect.
          In this case, one can only wait until
          the GC grace period has passed.
        </para>
      </section>

      <section xml:id="server.troubleshooting.clock_skew">
        <title>Too large clock skew</title>
        <para>
          The Cassandra PV Archiver server (and Apache Cassandra,
          too) relies on
          well-synchronized server clocks.
          When the clock
          skew between servers is too large or when the clock of
          a server
          skips back in time, this results in an error message like
          “The
          system clock of this server is skewed by at least … ms
          compared
          to server … - shutting down now” or “System clock
          skipped back -
          shutting down now”.
          In this case, one should
          check the mechanism (typically NTP) that is
          used for
          synchronizing the server clocks.
        </para>
        <para>
          A clock that leaps forward should only be synchronized by
          slewing it,
          not by jumping back to an earlier point in time.
          Jumping back to an earlier point in time is problematic
          because Apache
          Cassandra decides which update has been applied
          last by checking the
          time stamp associated with the update.
          This means that going back to an earlier time can result in
          data
          being written, but being superseded by data that has been
          written
          earlier, but appears newer because of a more recent
          time stamp.
        </para>
      </section>

      <section xml:id="server.troubleshooting.sign_in_failure">
        <title>Credentials are not accepted</title>
        <para>
          When trying to sign in to the administrative UI, one might
          get an
          error message like “You could not be signed in. Please
          check the
          username and password”.
          Typically, this message
          indicates that the username or password were
          wrong, but this
          message might also be displayed when they are actually
          correct.
          In this case, the reason is that the credentials
          cannot be verified
          because the server cannot read from the
          Cassandra database.
        </para>
        <para>
          For this reason, when trying to sign in and presumably
          correct
          credentials are rejected, one should go the dashboard
          of the
          administrative UI and verify that the server is actually
          connected to
          the Cassandra database cluster.
        </para>
      </section>

      <section xml:id="server.troubleshooting.reset_password">
        <title>Resetting a lost password</title>
        <para>
          When one cannot sign in to the administrative UI any
          longer because
          the password has been lost, one might have to
          reset this password.
          This can be done by connecting to the
          Cassandra database with the CQL
          shell, switching to the
          keyspace used by the Cassandra PV Archiver,
          and issuing the
          following statement:
        </para>
        <programlisting><![CDATA[
DELETE FROM generic_data_store WHERE
  component_id = ad5e517b-4ab6-4c4e-8eed-5d999de7484f AND
  item_key = 'admin'
  IF EXISTS;
]]></programlisting>
        <para>
          This deletes the entry for the
          <literal>admin</literal>
          user from the
          database.
          As this user is always assumed to exist,
          even if it is not in the
          database, the Cassandra PV Archiver
          server will assume that it again
          uses the default password
          <literal>admin</literal>
          .
          After signing in using the default password, one can
          immediately
          change the password back to a secure one.
        </para>
      </section>
    </section>
  </chapter>

  <chapter xml:id="client">
    <title>Cassandra PV Archiver clients</title>
    <para>
      Clients for the Cassandra PV Archiver allow users to query the
      archive,
      retrieving archived samples for each channel.
      For most
      users, the plugin for Control System Studio’s Data Browser (see
      <xref linkend="client.css" />
      ) is the easiest option for accessing the
      archive.
      However, other
      clients are supported as well through an open web-service
      interface.
      Please refer to
      <xref linkend="client.others" />
      for details.
    </para>

    <section xml:id="client.css">
      <title>Control System Studio</title>
      <para>
        The Data Browser view of
        <link xlink:href="http://controlsystemstudio.org/">Control System Studio</link>
        (CSS) provides powerful tools for finding, plotting, and
        exporting
        archived data.
        Integration with the Cassandra PV
        Archiver is provided by the
        <link xlink:href="http://oss.aquenos.com/epics/json-archive-proxy/">JSON Archive Proxy</link>
        client plugin.
        Please download the newest version of the JSON
        Archive Proxy that
        matches your version of CSS.
      </para>
      <para>
        In order to install the plugin, the files from the
        <literal>archive-json-reader-plugins</literal>
        directory in the
        distribution archive have to be copied to the
        <literal>plugins</literal>
        directory of the CSS installation.
        The
        <literal>source</literal>
        files can, but do not have to be included.
      </para>
      <para>
        For some versions of CSS, the plugin is detected automatically
        the next
        time CSS is started.
        For other versions, it is necessary
        to register the plugin manually
        (e.g. by manually adding the two
        bundles to
        <literal>configuration/org.eclipse.equinox.simpleconfigurator/bundles.info
        </literal>
        ).
      </para>
      <para>
        After starting CSS, the Cassandra PV Archiver has to be added as
        a data
        source. In the preferences, go to
        <menuchoice>
          <guimenu>CSS Applications</guimenu>
          <guisubmenu>Trends</guisubmenu>
          <guimenuitem>Data Browser</guimenuitem>
        </menuchoice>
        (see
        <xref linkend="client.css.fig.preferences_tree" />
        ).
      </para>
      <figure xml:id="client.css.fig.preferences_tree">
        <title>CSS Data Browser options in the preferences tree</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_client_css_preferences_tree.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        The archive URL has to be added to the list of
        “Archive Data
        Server URLs” (see
        <xref linkend="client.css.fig.preferences_data_server_url" />
        ).
        The URL is
        <uri>http://server&gt;:9812/archive-access/api/1.0/</uri>
        , where
        <literal>&lt;server&gt;</literal>
        has to be replaced by the host name or
        IP address of one of the
        archive servers of course.
        The port is 9812 unless the archive
        access port has been changed in the
        server’s configuration.
      </para>
      <figure xml:id="client.css.fig.preferences_data_server_url">
        <title>CSS Data Browser archive data server URLs</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_client_css_preferences_data_server_url.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        For a large installation, one should provide a load balancer
        that
        forwards requests, distributing them over the whole cluster.
        This also has the advantage that clients will still work when
        one of the
        servers is down.
        For the latter benefit, the load
        balancer itself has to be part of a
        high availability setup, of
        course.
      </para>
      <para>
        In addition to adding the URL to the list of “Archive Data
        Server URLs”,
        it can also be added to the list of “Default
        Archive Data Sources” (see
        <xref linkend="client.css.fig.preferences_default_data_sources" />
        ).
        Strictly speaking, this is not necessary for retrieving data
        from the
        archive, but it has the advantage that the archive can
        be used as a
        data source when no data source has been selected
        explicitly (e.g. when
        using historic data for a trend plot in a
        BOY panel).
        The key used for the Cassandra PV Archiver is always
        1.
      </para>
      <figure xml:id="client.css.fig.preferences_default_data_sources">
        <title>CSS Data Browser default archive data sources</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_client_css_preferences_default_data_sources.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        After adding the data source to CSS, CSS has to be restarted in
        order
        for the changes to take effect.
        After restarting, the
        archive can be accessed from the “Data Browser”
        perspective (see
        <xref linkend="client.css.fig.data_browser_perspective" />
        ).
      </para>
      <figure xml:id="client.css.fig.data_browser_perspective">
        <title>CSS Data Browser perspective</title>
        <mediaobject>
          <imageobject>
            <imagedata
              fileref="images/cassandra_pv_archiver_client_css_data_browser_perspective.png" />
          </imageobject>
        </mediaobject>
      </figure>
      <para>
        After seleting the archive URL from the list, one can search for
        channels.
        The search expression may contain glob patterns (e.g.
        <literal>myC*5</literal>
        ,
        <literal>myChannel?</literal>
        , etc.).
        Alternatively, regular expression may be used.
        The data
        for a channel can be plotted by right clicking it in the result
        list and selecting
        <menuchoice>
          <guisubmenu>Process Variable</guisubmenu>
          <guimenuitem>Data Browser</guimenuitem>
        </menuchoice>
        from the context menu.
        When there is already an open trend plot,
        one can add additional
        channels to this plot by simply dragging
        channels from the result list
        and dropping them on the plot.
      </para>
      <para>
        The data that is visible in the plot can also be examined
        through the
        “Inspect Samples” view.
        In addition to that, it can be
        exported into a file through the
        “Export Samples” view.
        When using
        the “Export Samples” view and selecting
        “Optimized Archived
        Data”, the most appropriate decimation level of the
        channel (the
        one which returns a number close to the requested number)
        is
        used.
        When selecting “Raw Archived Data”, only raw samples are
        used.
      </para>
    </section>

    <section xml:id="client.others">
      <title>Other clients</title>
      <para>
        The web-service interface that is used for integrating with
        <link linkend="client.css">Control System Studio</link>
        can also be used
        by other clients.
        The protocol used by this
        web-service is specified in
        <xref linkend="json_archive_access_v1" />
        .
        At the moment, this protocol is limited to providing basic
        information
        (scalar and array samples of a limited set of types,
        including some
        meta-data).
        In the future this interface is going
        to be extended, so that it will be
        possible for each
        control-system support to use a custom data format.
      </para>
      <para>
        For some applications, using the web-service protocol might
        not be a
        viable solution because the actual sample objects (as
        internally stored
        by the control-system support) are needed or
        high troughput for
        mass-processing data is required.
        In this case,
        there are two options.
      </para>
      <para>
        The first option is writing a Java application that uses the
        <interfacename>ArchiveAccessService</interfacename>
        (or rather its
        implementation, the
        <classname>ArchiveAccessServiceImpl</classname>
        )
        from the
        <literal>cassandra-pv-archiver-server</literal>
        module.
        This will directly expose the sample objects as they are
        provided by the
        control-system support.
      </para>
      <para>
        The second option is directly accessing the Cassandra database.
        The layout of the tables (as far as samples are concerned) is
        described
        in
        <xref linkend="cql_layout" />
        .
        Applications accessing the database directly should only read
        data,
        never insert new data or update existing data.
        Ensuring data
        consistency in a distributed system is very tricky and it
        is very
        likely that third-party applications would break the data
        consistency guarantees carefully protected by the Cassandra PV
        Archiver.
      </para>
    </section>
  </chapter>

  <chapter xml:id="extend">
    <title>Extending Cassandra PV Archiver</title>
    <para>
      The Cassandra PV Archiver has been designed to be modular, so
      that it can
      easily be extended.
      The standard distribution is built
      from five Maven modules:
    </para>
    <itemizedlist>
      <listitem>
        <simpara>
          cassandra-pv-archiver-common
        </simpara>
      </listitem>
      <listitem>
        <simpara>
          cassandra-pv-archiver-control-system-api
        </simpara>
      </listitem>
      <listitem>
        <simpara>
          cassandra-pv-archiver-control-system-channel-access
        </simpara>
      </listitem>
      <listitem>
        <simpara>
          cassandra-pv-archiver-server
        </simpara>
      </listitem>
      <listitem>
        <simpara>
          cassandra-pv-archiver-server-app
        </simpara>
      </listitem>
    </itemizedlist>
    <para>
      The
      <literal>cassandra-pv-archiver-common</literal>
      module provides code
      that is shared by most modules, in particular
      some utility classes.
      For details please refer to the
      <link
        xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-common/apidocs/">API reference</link>
      .
    </para>
    <para>
      The
      <literal>cassandra-pv-archiver-control-system-api</literal>
      module
      provides the API classes that have to be implemented by a
      control-system
      support.
      Please refer to
      <xref linkend="extend.control_system_support" />
      and the
      <link
        xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-control-system-api/apidocs/">API reference</link>
      for details.
    </para>
    <para>
      The
      <literal>cassandra-pv-archiver-control-system-channel-access
      </literal>
      module provides the control-system support for integration with
      Channel
      Access based control-systems.
      Please refer to
      <xref linkend="channel_access" />
      and the
      <link
        xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-control-system-channel-access/apidocs/">API reference</link>
      for details.
    </para>
    <para>
      The
      <literal>cassandra-pv-archiver-server</literal>
      module provides the
      actual Cassandra PV Archiver server.
      When
      building a custom server application, one will typically build on
      top
      of this module.
      For details please refer to the
      <link
        xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-server/apidocs/">API reference</link>
      .
    </para>
    <para>
      The
      <literal>cassandra-pv-archiver-server-app</literal>
      module bundles the
      <literal>cassandra-pv-archiver-server</literal>
      module with the
      <literal>cassandra-pv-archiver-control-system-channel-access
      </literal>
      module.
      This module can be used as an example of how to build a
      custom
      distribution of the Cassandra PV Archiver server that
      contains additional
      control-system supports.
    </para>
    <para>
      Instead of using the existing code for accessing the archive, some
      applications might want to access the database directly. In this
      case,
      please refer to
      <xref linkend="cql_layout" />
      for details about the
      database structure.
    </para>

    <section xml:id="extend.control_system_support">
      <title>Adding a control-system support</title>
      <para>
        The most common extension to the Cassandra PV Archiver is an
        additional
        control-system support.
        A control-system support
        provides the connectivity to a certain
        control-system so that
        process variables from that control-system can be
        archived.
        This
        section explains the basics of how a control-system support is
        implemented and registered with the Cassandra PV Archiver
        server.
        It is intended as an addendum to and not a replacement of
        the
        <link
          xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-control-system-api/apidocs/">API reference</link>
        ,
        which should also be studied carefully.
      </para>
      <para>
        The entry point for a control-system support is its
        implementation of
        the
        <link
          xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-control-system-api/apidocs/com/aquenos/cassandra/pvarchiver/controlsystem/ControlSystemSupportFactory.html">
          <interfacename>ControlSystemSupportFactory</interfacename>
        </link>
        interface.
        Each control-system support has to provide such an
        implementation and
        register it by adding the file
        <literal>META-INF/cassandra-pv-archiver.factories</literal>
        to the class
        path.
        This file should contain a single entry for
        registering the
        <interfacename>ControlSystemSupportFactory</interfacename>
        :
      </para>
      <programlisting><![CDATA[
com.aquenos.cassandra.pvarchiver.controlsystem.ControlSystemSupportFactory = \
  com.example.MyControlSystemSupportFactory
]]></programlisting>
      <para>
        This file is a Java properties file and thus has to adhere to
        the syntax
        expected by the
        <classname>java.util.Properties</classname>
        class.
        In this example,
        <classname>com.example.MyControlSystemSupportFactory</classname>
        is the
        factory class for the new control-system support.
      </para>
      <para>
        The factory class has to provide the prefix that is used to
        identify
        configuration options in the
        <literal>controlSystem</literal>
        section of
        the
        <link linkend="server.configuration">server’s configuration file</link>
        .
        In addition to that, it provides a method for instantiating the
        actual
        control-system support class (which has to implement
        <link
          xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-control-system-api/apidocs/com/aquenos/cassandra/pvarchiver/controlsystem/ControlSystemSupport.html">
          <interfacename>ControlSystemSupport</interfacename>
        </link>
        ).
        While the factory needs to have a default constructor, the
        actual
        control-system support can be initialized using the
        control-system
        options that have been specified in the server’s
        configuration file.
      </para>
      <para>
        The control-system support is identified by an identifier
        and a name.
        The identifier is used in configuration files (when
        importing or
        exporting channels) and in the database.
        The name, on
        the other hand, is displayed to the user in the
        administrative
        user interface.
        It is important that the identifer for a
        control-system support does not
        change after its first release
        because existing channels using the
        control-system support would
        otherwise become unusable.
        The name, on the other hand, is only
        used for informational purposes and
        can thus be changed at a
        later point in time without having any impact
        on existing
        channels.
      </para>
      <para>
        The control-system support has to implement methods for creating
        a
        channel (so that the corresponding process variables is
        monitored for
        changes), writing single samples, and reading
        samples from a single
        sample bucket.
        Each control-system support
        uses at least one table for storing its
        samples.
        This table should
        be created when instantiating the implementation of
        the
        <interfacename>ControlSystemSupport</interfacename>
        interface for
        the first time.
        For details about the methods that
        have to be implemented, please refer
        to the
        <link
          xlink:href="http://oss.aquenos.com/cassandra-pv-archiver/docs/${project.version}/maven-site/cassandra-pv-archiver-server/apidocs/">API reference</link>
        .
      </para>
      <para>
        Unless explicitly specified otherwise, all methods of a
        control-system
        support are expected to not block.
        Operations that
        may not be able to finish instantly (e.g. retrieving
        data from
        the database) return a
        <interfacename>Future</interfacename>
        that finishes asynchronously.
        This design has been chosen to
        allow the parallel processing of many
        channels without having to
        use a very high number of threads.
        You might want to study the
        code of the
        <link linkend="channel_access">Channel Access control-system support</link>
        as an example of how such an implementation might work.
      </para>
    </section>
  </chapter>

  <appendix xml:id="cql_layout">
    <title>CQL table layout</title>
    <para>
      The Cassandra PV Archiver stores its data in several CQL tables,
      listed in
      <xref linkend="cql_layout.tbl.tables" />
      .
    </para>
    <table xml:id="cql_layout.tbl.tables">
      <title>Cassandra PV Archiver CQL tables</title>
      <tgroup align="left" cols="2">
        <colspec colwidth="2*" />
        <colspec colwidth="3*" />
        <thead>
          <row>
            <entry>Table name</entry>
            <entry>Description</entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>cluster_servers</entry>
            <entry>
              Status and location information for Cassandra PV
              Archiver servers
            </entry>
          </row>
          <row>
            <entry>pending_channel_operations_by_server</entry>
            <entry>
              Protective entries for channels in order to prevent
              concurrent
              modifications
            </entry>
          </row>
          <row>
            <entry>channels</entry>
            <entry>
              Channel configuration and information about sample
              buckets for
              each channel
            </entry>
          </row>
          <row>
            <entry>channels_by_server</entry>
            <entry>
              Channel configuration and state for all channels
              associated with
              each server (for faster startup)
            </entry>
          </row>
          <row>
            <entry>generic_data_store</entry>
            <entry>
              Generic configuration information (e.g. credentials
              for the
              administrative user interface)
            </entry>
          </row>
        </tbody>
      </tgroup>
    </table>
    <para>
      In addition to these tables, each control-system support has one
      ore more
      tables.
      Please refer to the documentation of the respective
      control-system support
      for details.
      Most of the tables listed
      earlier are considered internal to the operation
      of the Cassandra
      PV Archiver and thus are not discussed in greater detail.
      Only the
      <literal>channels</literal>
      table is relevant for accessing data
      stored in the archive. This
      table is discussed in
      <xref linkend="cql_layout.channels" />
      .
    </para>

    <section xml:id="cql_layout.channels">
      <title>Table channels</title>
      <para>
        The
        <literal>channels</literal>
        table stores configuration information
        and information about
        sample buckets for each channel.
        The table’s structure is
        described by
        <xref linkend="cql_layout.channels.tbl.columns" />
        .
      </para>
      <table xml:id="cql_layout.channels.tbl.columns">
        <title>Columns of table channels</title>
        <tgroup align="left" cols="4">
          <colspec colwidth="1*" />
          <colspec colwidth="1*" />
          <colspec colwidth="1*" />
          <colspec colwidth="2*" />
          <thead>
            <row>
              <entry>Column name</entry>
              <entry>Column type</entry>
              <entry>Data type</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>channel_name</entry>
              <entry>Partition key</entry>
              <entry>text</entry>
              <entry>
                Channel name.
              </entry>
            </row>
            <row>
              <entry>decimation_level</entry>
              <entry>Clustering Key</entry>
              <entry>int</entry>
              <entry>
                Decimation level (identified by the decimation
                period in
                seconds). Zero indicates raw samples.
              </entry>
            </row>
            <row>
              <entry>bucket_start_time</entry>
              <entry>Clustering Key</entry>
              <entry>bigint</entry>
              <entry>
                Start time of the sample bucket (in nanoseconds since
                epoch,
                which is January 1
                <superscript>st</superscript>
                , 1970, 00:00:00
                UTC).
              </entry>
            </row>
            <row>
              <entry>bucket_end_time</entry>
              <entry>Regular</entry>
              <entry>bigint</entry>
              <entry>
                End time of the sample bucket (in nanoseconds since
                epoch,
                which is January 1
                <superscript>st</superscript>
                , 1970, 00:00:00
                UTC).
              </entry>
            </row>
            <row>
              <entry>channel_data_id</entry>
              <entry>Static</entry>
              <entry>uuid</entry>
              <entry>
                Data ID associated with the channel. This
                information is used to
                identify associated data in the
                control-system support’s
                table(s).
              </entry>
            </row>
            <row>
              <entry>control_system_type</entry>
              <entry>Static</entry>
              <entry>text</entry>
              <entry>
                ID of the control-system support used for the
                channel.
              </entry>
            </row>
            <row>
              <entry>decimation_levels</entry>
              <entry>Static</entry>
              <entry>set&lt;int&gt;</entry>
              <entry>
                Set containing all decimation levels that exist for
                the channel
                (identified by their decimation periods in
                seconds).
              </entry>
            </row>
            <row>
              <entry>server_id</entry>
              <entry>Static</entry>
              <entry>uuid</entry>
              <entry>
                UUID of the server to which the channel belongs.
              </entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para>
        The channel name is used as the partition key and the
        decimation level
        and bucket start time are used as clustering
        keys.
        This means that for each channel, there is a partition and
        for each
        sample bucket there is a row in this partition.
        The
        ordering of the clustering keys (decimation level first, bucket
        start time second) makes it possible to search for sample
        buckets for
        a specific decimation level that are in a certain
        time range.
        All configuration information is stored in static
        columns (columns that
        are shared among all rows in the partition)
        because this information
        obviously does not depend on the sample
        bucket.
      </para>
      <para>
        The bucket end time is a regular column and thus it is not
        possible to
        search by end time. However, the end time is
        typically just one
        nanosecond before the start time of the
        following bucket (it is
        guaranteed to be strictly less than the
        start time of the next bucket).
        Therefore, there is usually no
        need to search based on the end time.
      </para>
      <para>
        When reading samples, one has to search for the sample
        buckets that
        store the samples for the relevant period of time.
        One can use a query like the following to search for all sample
        buckets
        that start in a certain period of time:
      </para>
      <programlisting><![CDATA[
SELECT * FROM channels WHERE
  channel_name = 'myChannel' AND
  decimation_level = 0 AND
  bucket_start_time >= 1468429000000000000 AND
  bucket_start_time <= 1468431000000000000
  ORDER BY decimation_level ASC;
]]></programlisting>
      <para>
        In this example,
        <literal>myChannel</literal>
        is the name of the channel
        and we search for sample buckets
        storing raw samples (decimation period of
        <literal>0</literal>
        ) and starting between the time stamps
        <literal>1468429000000000000</literal>
        and
        <literal>1468431000000000000</literal>
        .
        It might seem strange to order by the
        <literal>decimation_level</literal>
        column when we actually want to
        order by the
        <literal>bucket_start_time</literal>
        column.
        However, Cassandra (currently) only allows specifying the
        first column
        of a composite clustering key in the
        <literal>ORDER BY</literal>
        clause.
        The
        <literal>ORDER BY</literal>
        clause still has the intended effect of
        (also) ordering by the
        <literal>bucket_start_time</literal>
        column.
      </para>
      <para>
        Typically, one also needs the sample bucket that starts
        before the lower
        time-stamp, unless there is a sample bucket
        starting right at the lower
        limit of the search period, which
        will only happen by chance.
        One can retrieve information about
        this sample bucket with a query like
        the following:
      </para>
      <programlisting><![CDATA[
SELECT * FROM channels WHERE
  channel_name = 'myChannel' AND
  decimation_level = 0 AND
  bucket_start_time < 1468429000000000000
  ORDER BY decimation_level DESC
  LIMIT 1;
]]></programlisting>
      <para>
        We are only interested in the first sample bucket just
        before our lower
        limit, which is why we use descending order and
        limit the results to a
        single row.
      </para>
      <para>
        Once we know the sample buckets, we can retrieve the
        corresponding
        samples from the control-system support’s table(s).
        We need the
        <literal>channel_data_id</literal>
        ,
        <literal>decimation_level</literal>
        , and
        <literal>bucket_start_time</literal>
        in order to identify the sample
        bucket in the control-system
        support’s table(s).
        When querying these tables, the time stamp of
        the samples should be
        limited to the range specified by the
        <literal>bucket_start_time</literal>
        and
        <literal>bucket_end_time</literal>
        , unless the limits imposed by the
        time period that is queried
        are more narrow.
        Always using these limits ensures that we do not
        read samples that have
        accidentally been written into a sample
        bucket where they do not belong.
        Usually, such samples should not
        exist, but it is better to be safe.
      </para>
    </section>
  </appendix>

  <appendix xml:id="json_archive_access_v1">
    <title>JSON archive access protocol 1.0</title>
    <para>
      The JSON-based archive access protocol is the protocol that is
      used by the
      <link linkend="client.css">plugin</link>
      for Control System Studio’s Data
      Browser.
      This protocol may also be
      used by other clients that want to retrieve data
      from the archive.
    </para>
    <para>
      Unless the archive-access port has been changed, the base URL used
      for all
      requests concerning the JSON-based archive-access protocol
      1.0 is
      <uri>http://myserver.example.com:9812/archive-acess/api/1.0</uri>
      .
      This base has to be prepended to all URLs that are mentioned in
      this
      protocol specification.
      The host name
      <literal>myserver.example.com</literal>
      is just an example
      and has to be replaced with the real hostname of
      a Cassandra PV Archiver
      server.
      The port 9812 is the default port
      used for the archive-access protocol and
      only has to be changed if
      the archive access port has been changed in the
      server’s
      configuration file.
    </para>
    <para>
      All requests are made by specifying query parameters in the URL.
      The request body is always empty.
      The response is always sent in
      the JSON format (MIME type
      application/json) unless there is an
      error (which is identified by a
      corresponding HTTP status code).
      All requests are sent as
      <literal>GET</literal>
      requests.
    </para>
    <para>
      The Cassandra PV Archiver server supports deflate and gzip
      compression of
      the response body if support for compression is
      indicated by the client.
      For JSON data, compression can
      dramatically reduce the amount of data that
      has to be transferred,
      so clients should support compression when
      possible.
    </para>

    <section xml:id="json_archive_access_v1.archive_info">
      <title>Requesting the list of available archives</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving the list of available
          archives has the
          following form:
        </para>
        <programlisting><![CDATA[
/archive/[?prettyPrint]
]]></programlisting>
        <para>
          If the optional
          <literal>prettyPrint</literal>
          parameter is present,
          the output is formatted nicely, which can
          be useful for debugging.
          Usually, this parameter should be
          omitted because this will result in
          a more compact
          representation, saving bandwidth.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON array, each element being one
          available archive
          (JSON object).
          Each of these JSON objects has
          the following fields:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>key</entry>
                <entry>int</entry>
                <entry>number (must be in integer format)</entry>
                <entry>
                  numeric key identifying the archive (unique)
                </entry>
              </row>
              <row>
                <entry>name</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the archive (might not be unique)
                </entry>
              </row>
              <row>
                <entry>description</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  description of the archive
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          Originally, the JSON protocol was not designed for the
          Cassandra PV
          Archiver, but as a general protocol for accessing
          archives.
          For this reason, it supports servers that provide
          more than one
          archive.
          The Cassandra PV Archiver server only
          provides a single archive, so
          simple clients can simply assume
          that the archive key is always
          <literal>1</literal>
          .
          The server still supports retriving the archive information
          so that it
          is compatible with clients implementing the protocol
          completely and
          thus supporting multiple archives.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /archive-access/api/1.0/archive/?prettyPrint HTTP/1.0
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
[ {
  "key" : 1,
  "name" : "Cassandra",
  "description" : "Cassandra PV Archive"
} ]
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="json_archive_access_v1.search_channels">
      <title>Searching for channels</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL used in order to search for channels takes
          one of the
          following two forms:
        </para>
        <programlisting>
          /archive/
          <replaceable>&lt;archive key&gt;</replaceable>
          /channels-by-pattern/
          <replaceable>&lt;glob pattern expression&gt;</replaceable>
          ↪[?prettyPrint]
          /archive/
          <replaceable>&lt;archive key&gt;</replaceable>
          /channels-by-regexp/
          <replaceable>&lt;regular expression&gt;</replaceable>
          ;[?prettyPrint]
        </programlisting>
        <para>
          The
          <replaceable>archive key</replaceable>
          is the numeric key of the
          archive as specified in the list of
          archives (typically
          <literal>1</literal>
          ).
        </para>
        <para>
          The search for a channel name can be done with a glob
          pattern or a
          regular expression.
          In either case, the pattern
          needs to be URL encoded so that all
          special characters (in
          particular those that have a special meaning in
          a URL, like the
          question mark) are encoded with %xx where xx is the
          hexadecimal character code.
          This includes the special wildcard
          characters that are part of the
          pattern.
          When the expression
          contains non-ASCII characters, those characters
          are expected to
          be specified in UTF-8 encoding.
        </para>
        <para>
          When using a glob pattern, the
          <literal>channels-by-pattern</literal>
          URL has to be used.
          In the
          <replaceable>glob pattern expression</replaceable>
          , the ? and *
          characters have a special meaning.
          The question
          mark acts as wildcard that matches exactly one character.
          The
          asterisk acts as a wildcard that matches an arbitrary number
          of
          characters (including zero characters).
        </para>
        <para>
          When using a regular expression, the
          <literal>channels-by-regexp</literal>
          URL has to be used.
          The
          <replaceable>regular expression</replaceable>
          must be specified in
          a form that is understood by the
          <literal>java.util.regex.Pattern.compile(java.lang.String)
          </literal>
          method.
        </para>
        <para>
          If the optional
          <literal>prettyPrint</literal>
          parameter is present,
          the output is formatted nicely, which can
          be useful for debugging.
          Usually, this parameter should be
          omitted because this will result in
          a more compact
          representation, saving bandwidth.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON array, containing JSON strings,
          where each
          string is a channel name.
          When no matching channel is
          found, an empty array is returned.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /archive-access/api/1.0/archive/1/channels-by-pattern/my%2AExample?
  ↪prettyPrint HTTP/1.0
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
[ "myTest1Example", "myTest2Example" ]
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="json_archive_access_v1.samples">
      <title>Retrieving samples for a channel</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving samples for a specific
          channel has the
          following form:
        </para>
        <programlisting>
          /archive/
          <replaceable>&lt;archive key&gt;</replaceable>
          /samples/
          <replaceable>&lt;channel name&gt;</replaceable>
          ?start=
          <replaceable>&lt;start time-stamp&gt;</replaceable>
          &amp;
          ↪end=
          <replaceable>&lt;end time-stamp&gt;</replaceable>[&amp;count=
          <replaceable>&lt;desired number of samples&gt;</replaceable>][&amp;prettyPrint]
        </programlisting>
        <para>
          The
          <replaceable>archive key</replaceable>
          is the numeric key of the
          archive as specified in the list of
          archives (typically
          <literal>1</literal>
          ).
        </para>
        <para>
          The
          <replaceable>channel name</replaceable>
          is the name of the channel
          for which samples are requested.
          The
          channel name must be URL encoded so that all special
          characters
          (in particular those that have a special meaning in
          a URL, like the
          question mark) are encoded with %xx where xx is
          the hexadecimal
          character code.
          When the channel name contains
          non-ASCII characters, those characters
          are expected to be
          specified in UTF-8 encoding.
        </para>
        <para>
          The
          <replaceable>start time-stamp</replaceable>
          specifies the start of
          the interval for which samples are
          requested.
          The time stamp is specified as the number of
          nanoseconds since epoch
          (January 1
          <superscript>st</superscript>
          , 1970, 00:00:00 UTC).
        </para>
        <para>
          The
          <replaceable>end time-stamp</replaceable>
          specifies the end of
          the interval for which samples are
          requested.
          The time stamp is specified as the number of
          nanoseconds since epoch
          (January 1
          <superscript>st</superscript>
          , 1970, 00:00:00 UTC).
        </para>
        <para>
          The
          <literal>count</literal>
          parameter is optional.
          If specified, the
          <replaceable>desired number of samples</replaceable>
          is a strictly positive number that specifies the number of
          samples
          that should be returned.
          The number of samples returned
          will usually not match this number
          exactly.
          However, if samples
          with various densities are available, the density
          which will
          result in the number of samples closest to the requested
          number is chosen.
          If this parameter is not specified, raw
          samples are used.
        </para>
        <para>
          If the optional
          <literal>prettyPrint</literal>
          parameter is present,
          the output is formatted nicely, which can
          be useful for debugging.
          Usually, this parameter should be
          omitted because this will result in
          a more compact
          representation, saving bandwidth.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON array, each element being one
          sample (JSON
          object).
          In addition to the samples between the
          start and the end time-stamp,
          one sample at or before the start
          time-stamp and one sample at or
          after the end time-stamp is
          returned (if such samples exist at all).
          This way, the returned
          data is sufficient for creating a plot covering
          the whole
          interval, even if the specified time stamps do not exactly
          match the time stamps of samples.
        </para>
        <para>
          Each of the sample objects can have the following fields:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>time</entry>
                <entry>big integer</entry>
                <entry>number (must be in integer format)</entry>
                <entry>
                  time-stamp in nanoseconds since epoch (January
                  1
                  <superscript>st</superscript>
                  , 1970, 00:00:00 UTC)
                </entry>
              </row>
              <row>
                <entry>severity</entry>
                <entry>see below</entry>
                <entry>object</entry>
                <entry>
                  alarm severity
                </entry>
              </row>
              <row>
                <entry>status</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  alarm status (might contain additional
                  information about the
                  severity)
                </entry>
              </row>
              <row>
                <entry>quality</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  sample quality - one of “Original” or
                  “Interpolated” (not
                  case-sensitive)
                </entry>
              </row>
              <row>
                <entry>metaData</entry>
                <entry>see below</entry>
                <entry>object</entry>
                <entry>
                  meta-data of the sample
                </entry>
              </row>
              <row>
                <entry>type</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  sample type - must be one of “double”, “enum”,
                  “long”,
                  “minMaxDouble”, or “string” (not
                  case-sensitive)
                </entry>
              </row>
              <row>
                <entry>value</entry>
                <entry>depends on sample type</entry>
                <entry>array</entry>
                <entry>
                  array of values making up the sample
                </entry>
              </row>
              <row>
                <entry>minimum</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  minimum value – must be in number format unless
                  it cannot be
                  expressed as a JSON number (e.g. infinity)
                </entry>
              </row>
              <row>
                <entry>maximum</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  maximum value – must be in number format unless
                  it cannot be
                  expressed as a JSON number (e.g. infinity)
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          The
          <literal>type</literal>
          ,
          <literal>time</literal>
          ,
          <literal>severity</literal>
          ,
          <literal>status</literal>
          ,
          <literal>quality</literal>
          , and
          <literal>value</literal>
          fields are
          always present.
          The
          <literal>minimum</literal>
          and
          <literal>maximum</literal>
          fields
          are only present if the type is
          <literal>minMaxDouble</literal>
          .
          The
          <literal>type</literal>
          field must always come before the
          <literal>value</literal>
          field.
        </para>
        <para>
          The
          <literal>quality</literal>
          field indicates whether the sample is a
          raw sample (“Original”)
          or a decimated sample (“Interpolated”).
        </para>
        <para>
          The
          <literal>metaData</literal>
          field may be present for all types
          except the
          <literal>string</literal>
          type.
          The format of the meta-data depends on the type (see
          below).
        </para>
        <para>
          At places where a number may also be expressed as a JSON
          string, the
          use of a string is reserved to cases where the
          number cannot be
          represented as a JSON number (infinity and
          not-a-number).
          Valid strings are
          <literal>inf</literal>
          ,
          <literal>infinity</literal>
          ,
          <literal>+inf</literal>
          ,
          <literal>+infinity</literal>
          ,
          <literal>-inf</literal>
          ,
          <literal>-infinity</literal>
          , and
          <literal>nan</literal>
          (all not case-sensitive).
        </para>
        <para>
          The value is always represented as a JSON array. The type
          of the array
          elements depends on the sample type:
        </para>
        <informaltable>
          <tgroup align="left" cols="3">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Sample type</entry>
                <entry>Element JSON type</entry>
                <entry>Remarks</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  must be in number format unless it cannot be
                  expressed as a
                  JSON number (e.g. infinity)
                </entry>
              </row>
              <row>
                <entry>enum</entry>
                <entry>number</entry>
                <entry>
                  must be in integer format, numbers outside the
                  interval
                  [-2
                  <superscript>31</superscript>
                  ,
                  2
                  <superscript>31</superscript>
                  -1] may be truncated
                </entry>
              </row>
              <row>
                <entry>long</entry>
                <entry>number</entry>
                <entry>
                  must be in integer format, numbers outside the
                  interval
                  [-2
                  <superscript>63</superscript>
                  ,
                  2
                  <superscript>63</superscript>
                  -1] may be truncated
                </entry>
              </row>
              <row>
                <entry>minMaxDouble</entry>
                <entry>number or string</entry>
                <entry>
                  must be in number format unless it cannot be
                  expressed as a
                  JSON number (e.g. infinity)
                </entry>
              </row>
              <row>
                <entry>string</entry>
                <entry>string</entry>
                <entry></entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          The
          <literal>minMaxDouble</literal>
          type is used for samples that have
          been aggregates from several
          raw samples and the
          <literal>minimum</literal>
          and
          <literal>maximum</literal>
          represent
          the least and the greatest value of any of the
          original samples.
          Sample of type
          <literal>minMaxDouble</literal>
          typically have a
          <literal>quality</literal>
          of “Interpolated” because they represent
          decimated samples.
        </para>
        <para>
          The severity is a JSON object with the following fields
          (all
          mandatory):
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>level</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  sample severity - one of “OK”, “MINOR”, “MAJOR”,
                  or “INVALID”
                  (all not case-sensitive)
                </entry>
              </row>
              <row>
                <entry>hasValue</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  tells whether the sample has a value (or just
                  signals a
                  condition with a certain severity)
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          The meta-data is a JSON object.
          The format depends on the
          sample type.
          Samples that are of the
          <literal>string</literal>
          type do not have
          meta data.
          Samples that are of the
          <literal>enum</literal>
          type can have meta
          data in the following format (all fields are
          mandatory):
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>type</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  value is always “enum” (not case-sensitive)
                </entry>
              </row>
              <row>
                <entry>states</entry>
                <entry>array of strings</entry>
                <entry>array of strings</entry>
                <entry>
                  labels for the enum states
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          Samples that are of the
          <literal>double</literal>
          ,
          <literal>long</literal>
          , or
          <literal>minMaxDouble</literal>
          type can
          have meta data in the following format (all fields are
          mandatory):
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>type</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  value is always “numeric” (not case-sensitive)
                </entry>
              </row>
              <row>
                <entry>precision</entry>
                <entry>integer</entry>
                <entry>number</entry>
                <entry>
                  number of fractional digits to be displayed, must
                  be in
                  integer format
                </entry>
              </row>
              <row>
                <entry>unit</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  engineering units of the value
                </entry>
              </row>
              <row>
                <entry>displayLow</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  lower display limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
              <row>
                <entry>displayHigh</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  upper display limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
              <row>
                <entry>warnLow</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  lower warning limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
              <row>
                <entry>warnHigh</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  upper warning limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
              <row>
                <entry>alarmLow</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  lower alarm limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
              <row>
                <entry>alarmHigh</entry>
                <entry>double</entry>
                <entry>number or string</entry>
                <entry>
                  upper alarm limit – must be in number format
                  unless it
                  cannot be expressed as a JSON number (e.g.
                  infinity)
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /archive-access/api/1.0/archive/1/samples/testCalc?start=0&
  ↪end=1500000000000000000&prettyPrint HTTP/1.0
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
[ {
  "time" : 1468429059824011000,
  "severity" : {
    "level" : "OK",
    "hasValue" : true
  },
  "status" : "NO_ALARM",
  "quality" : "Original",
  "metaData" : {
    "type" : "numeric",
    "precision" : 2,
    "units" : "V",
    "displayLow" : 0.0,
    "displayHigh" : 0.0,
    "warnLow" : "NaN",
    "warnHigh" : 12.0,
    "alarmLow" : "NaN",
    "alarmHigh" : 15.0
  },
  "type" : "double",
  "value" : [ 7.0 ]
}, {
  "time" : 1468429060825564000,
  "severity" : {
    "level" : "MINOR",
    "hasValue" : true
  },
  "status" : "HIGH",
  "quality" : "Original",
  "metaData" : {
    "type" : "numeric",
    "precision" : 2,
    "units" : "V",
    "displayLow" : 0.0,
    "displayHigh" : 0.0,
    "warnLow" : "NaN",
    "warnHigh" : 12.0,
    "alarmLow" : "NaN",
    "alarmHigh" : 15.0
  },
  "type" : "double",
  "value" : [ 12.0 ]
} ]
]]></programlisting>
      </simplesect>
    </section>
  </appendix>

  <appendix xml:id="admin_api">
    <title>Administrative API</title>
    <para>
      The JSON-based administrative web-service API can be used to
      monitor and
      configure the Cassandra PV Archiver server.
      It offers
      most of the functions available through the
      <link linkend="server.admin_ui">administrative user interface</link>
      , but
      is designed to be used by other software (e.g. scripts used
      for automating
      the configuration management).
    </para>
    <section xml:id="admin_api.general">
      <title>General considerations</title>
      <para>
        The base URL used for all requests concerning this API is:
        <programlisting>
          http://
          <replaceable>&lt;server&gt;</replaceable>
          :
          <replaceable>&lt;port&gt;</replaceable>
          /admin/api/
          <replaceable>&lt;version number&gt;</replaceable>
        </programlisting>
        In this URL
        <replaceable>&lt;server&gt;</replaceable>
        is the hostname or
        IP address of the archive server,
        <replaceable>&lt;port&gt;</replaceable>
        is the TCP port number of the
        administrative interface, and
        <replaceable>&lt;version number&gt;</replaceable>
        is the protocol
        version.
        At the moment, the only protocol version
        supported by the server is 1.0.
        This base has to be prepended to
        all URLs that are mentioned in this
        protocol specification.
        If not
        configured explicitly in the server configuration, the
        administrative interface is made available on port 4812.
      </para>
      <para>
        The API uses JSON for both request and response bodies.
        Requests
        only reading data typically use the
        <literal>GET</literal>
        method and have an empty request body.
        If there are any
        parameters, they are passed as part of the URL (in the
        path or
        query string).
        When passing parameters as part of the path (not
        the query string), they
        have to be encoded in a non-standard way
        (see
        <xref linkend="admin_api.general.uri_encode" />
        for details).
        Read requests do not require authentication.
      </para>
      <simplesect>
        <title>Request</title>
        <para>
          Requests making modification typically use the
          <literal>POST</literal>
          method (unless specified differently).
          Such requests typically
          expect parameters in the request’s body.
          For some requests
          however, some of the parameters might still have to
          be
          specified as part of the URL.
          Requests making modifications
          must be accompanied by an
          <literal>Authorization</literal>
          HTTP header for HTTP basic
          authentication.
        </para>
      </simplesect>
      <simplesect>
        <title>Response</title>
        <para>
          Invalid credentials result may result in a response with
          status 403
          (forbidden), even if the requested resource does
          actually not require
          authentication.
          For this reason, requests
          to resources not requiring authentication
          should rather be made
          without an
          <literal>Authorization</literal>
          header than a header containing invalid credentials.
        </para>
        <para>
          Invalid request parameters (e.g. a request body that does
          not adhere
          to the format specified for the respective function)
          may result in a
          response with status 400 (bad request).
        </para>
        <para>
          The response is always sent in the JSON format (MIME type
          <literal>application/json</literal>
          ) unless there is an error (which
          is identified by a
          corresponding HTTP status code).
          The request body (if present)
          also has to be sent in the JSON format
          (MIME type
          <literal>application/json</literal>
          ).
        </para>
      </simplesect>
      <simplesect>
        <title>JSON format</title>
        <para>
          Unless specified differently, numbers are always
          serialized as JSON
          strings for three reasons:
          First, JSON
          numbers cannot be used as keys in maps (attribute names in
          JSON objects).
          Second, certain special numbers (e.g. positive
          and negative infinity)
          cannot be specified as JSON numbers.
          Third, many JSON parsers convert all numbers to 64-bit
          floating point
          values, resulting in precision loss for large
          integers.
        </para>
        <para>
          As a general rule, when the member of a JSON object may have a
          value
          of
          <literal>null</literal>
          , it may also be missing.
          A missing member must always be
          interpreted in the same way as the
          respective member having a
          <literal>null</literal>
          value.
        </para>
      </simplesect>
      <simplesect xml:id="admin_api.general.uri_encode">
        <title>Encoding URI components</title>
        <para>
          Parameters that are passed as part of the query string use
          regular URI encoding (as specified by
          <link xlink:href="https://tools.ietf.org/html/rfc3986#section-2.1">RFC 3986</link>
          ).
          Parameters that are passed as part of the path use a
          slightly
          different encoding that is specified in this section.
        </para>
        <para>
          In order to encode a parameter value, it is first
          serialized as UTF-8.
          In the resulting byte sequence, each byte
          that does not represent one
          of the ASCII characters “A” to “Z”,
          “a” to “z”, “0” to “9”, “-”
          (minus), or “_” (underscore) is
          escaped by a three byte sequence in
          the form “~” (tilde), hex
          digit, hex digit.
          The two hex digits are the escaped byte’s
          value in hexadecimal
          representation.
          The hex digits “A” to “F”
          should be represented in upper case.
        </para>
        <para>
          For example, the string “some test” is encoded as
          “some~20test”.
          The string “allowed_characters_only” stays the
          same.
          The string “a/b” is encoded as “a~2Fb”.
          The string “süper”
          is encoded as “s~C3~BCper”.
        </para>
      </simplesect>
    </section>

    <section xml:id="admin_api.channels_all">
      <title>List all channels</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving the list of all channels
          has the
          following form:
        </para>
        <programlisting>
          /channels/all/
        </programlisting>
        <para>
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the
          <literal>channels</literal>
          attribute as its only member.
          The
          <literal>channels</literal>
          attribute has an array as its value
          that contains an element
          for each channel.
          Each of these elements is an object with the
          following attributes:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelDataId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  internal ID for the channel
                </entry>
              </row>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  channel’s name
                </entry>
              </row>
              <row>
                <entry>controlSystemName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the control-system support
                  used for the
                  channel
                </entry>
              </row>
              <row>
                <entry>controlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system
                  support used for
                  the channel
                </entry>
              </row>
              <row>
                <entry>decimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels that exist for the channel
                  (specified in
                  seconds)
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  ID of the server that owns the channel
                </entry>
              </row>
              <row>
                <entry>serverName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the server that owns the
                  channel
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If the list of channels is currently not available, HTTP
          error code
          503 (service unavailable) is returned and the
          response body is
          invalid.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /admin/api/1.0/channels/all/
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "channels": [
    {
      "channelDataId": "ef126a63-375b-4f28-a1d1-17e8f42271a9",
      "channelName": "someChannel",
      "controlSystemName": "Channel Access",
      "controlSystemType": "channel_access",
      "decimationLevels": ["0", "30", "900"],
      "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd",
      "serverName": "myserver"
    },
    {
      "channelDataId": "0993955f-d16e-486d-ac3b-6a1841c0fd3f",
      "channelName": "someOtherChannel",
      "controlSystemName": "Channel Access",
      "controlSystemType": "channel_access",
      "decimationLevels": ["0"],
      "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd",
      "serverName": "myserver"
    }
  ]
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.channels_by_server">
      <title>List channels for a server</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving the list of channels for a
          server has
          the following form:
        </para>
        <programlisting>
          /channels/by-server/
          <replaceable>&lt;server ID&gt;</replaceable>
          /
        </programlisting>
        <para>
          The
          <replaceable>&lt;server ID&gt;</replaceable>
          has to be replaced by
          the UUID associated with the respective
          server.
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the
          <literal>channels</literal>
          and
          <literal>statusAvailable</literal>
          attributes as its members.
          The
          <literal>statusAvailable</literal>
          attribute is a boolean
          indicating whether the list of channels
          includes status information
          (
          <literal>true</literal>
          ) or only configuration information
          (
          <literal>false</literal>
          ).
          Status information is only available if the specified server
          is
          online.
          The
          <literal>channels</literal>
          attribute has an array as its value
          that contains an element
          for each channel.
          Each of these elements is an object with the
          following attributes:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelDataId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  internal ID for the channel
                </entry>
              </row>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  channel’s name
                </entry>
              </row>
              <row>
                <entry>controlSystemName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the control-system support
                  used for the
                  channel
                </entry>
              </row>
              <row>
                <entry>controlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system
                  support used for
                  the channel
                </entry>
              </row>
              <row>
                <entry>decimationLevelToRetentionPeriod</entry>
                <entry>map of int to int</entry>
                <entry>object with string attribute values</entry>
                <entry>
                  decimation levels that exist for the channel and
                  their
                  respective retention periods (both specified in
                  seconds)
                </entry>
              </row>
              <row>
                <entry>enabled</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if the channel is enabled,
                  <literal>false</literal>
                  if it is disabled.
                </entry>
              </row>
              <row>
                <entry>errorMessage</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message for the channel. May be
                  <literal>null</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>map of string to string</entry>
                <entry>object with string attribute values</entry>
                <entry>
                  control-system-specific configuration options
                  that have been
                  specified for the channel (the attribute
                  name is the option
                  name and the attribute value is the
                  option value)
                </entry>
              </row>
              <row>
                <entry>state</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  channel’s current state. One of
                  <literal>destroyed</literal>
                  ,
                  <literal>disabled</literal>
                  ,
                  <literal>disconnected</literal>
                  ,
                  <literal>error</literal>
                  ,
                  <literal>initializing</literal>
                  ,
                  or
                  <literal>ok</literal>
                  .
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesDropped</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that have been dropped for the
                  channel
                  (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesSkippedBack</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that were discarded because they
                  skipped
                  back in time (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesWritten</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that have been written for the
                  channel
                  (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If the list of channels is currently not available, HTTP
          error code
          503 (service unavailable) is returned and the
          response body is
          invalid.
          If the specified server does not
          exist, HTTP error code 404 (not
          found) is returned and the
          response body is invalid.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /admin/api/1.0/channels/by-server/7cf8f393-cd00-46ae-9343-53e9cb5793fd/
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "channels": [
    {
      "channelDataId": "ef126a63-375b-4f28-a1d1-17e8f42271a9",
      "channelName": "someChannel",
      "controlSystemName": "Channel Access",
      "controlSystemType": "channel_access",
      "decimationLevelToRetentionPeriod": {
        "0": "864000",
        "30": "31536000",
        "900": "0"
      },
      "enabled": true,
      "errorMessage": null,
      "options": {},
      "state": "OK",
      "totalSamplesDropped": "0",
      "totalSamplesSkippedBack": "1",
      "totalSamplesWritten": "42"
    },
    {
      "channelDataId": "0993955f-d16e-486d-ac3b-6a1841c0fd3f",
      "channelName": "someOtherChannel",
      "controlSystemName": "Channel Access",
      "controlSystemType": "channel_access",
      "decimationLevelToRetentionPeriod": {"0": "0"},
      "enabled": true,
      "errorMessage": "Invalid control-system option \"noSuchOption\".",
      "options": {
        "noSuchOption": "some value"
      },
      "state": "ERROR",
      "totalSamplesDropped": "0",
      "totalSamplesSkippedBack": "0",
      "totalSamplesWritten": "0"
    }
  ],
  statusAvailable: true
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.channel_details">
      <title>Inspect a single channel</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving information about a single
          channel has
          the following form:
        </para>
        <programlisting>
          /channels/all/by-name/
          <replaceable>&lt;channel-name&gt;/</replaceable>
          /channels/by-server/
          <replaceable>&lt;server ID&gt;</replaceable>
          /by-name/
          <replaceable>&lt;channel-name&gt;/</replaceable>
        </programlisting>
        <para>
          Both variants return the same data.
          The only difference between
          them is that the variant that includes the
          server ID in the URL
          will return status code 404 (not found) when the
          channel
          exists, but belongs to a different server.
          The
          <replaceable>&lt;channel name&gt;</replaceable>
          has to be replaced
          by the encoded form of the channel name.
          The
          <replaceable>&lt;server ID&gt;</replaceable>
          has to be replaced by
          the UUID associated with the respective
          server.
          Only use the second variant if the query shall be
          limited to a
          specific server.
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the following
          attributes:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelDataId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  internal ID for the channel
                </entry>
              </row>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  channel’s name
                </entry>
              </row>
              <row>
                <entry>controlSystemName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the control-system support
                  used for the
                  channel
                </entry>
              </row>
              <row>
                <entry>controlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system
                  support used for
                  the channel
                </entry>
              </row>
              <row>
                <entry>decimationLevelToRetentionPeriod</entry>
                <entry>map of int to int</entry>
                <entry>object with string attribute values</entry>
                <entry>
                  decimation levels that exist for the channel and
                  their
                  respective retention periods (both specified in
                  seconds)
                </entry>
              </row>
              <row>
                <entry>enabled</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if the channel is enabled,
                  <literal>false</literal>
                  if it is disabled.
                </entry>
              </row>
              <row>
                <entry>errorMessage</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message for the channel. May be
                  <literal>null</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>map of string to string</entry>
                <entry>object with string attribute values</entry>
                <entry>
                  control-system-specific configuration options
                  that have been
                  specified for the channel (the attribute
                  name is the option
                  name and the attribute value is the
                  option value)
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  ID of the server that owns the channel
                </entry>
              </row>
              <row>
                <entry>serverName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the server that owns the
                  channel
                </entry>
              </row>
              <row>
                <entry>state</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  channel’s current state. One of
                  <literal>destroyed</literal>
                  ,
                  <literal>disabled</literal>
                  ,
                  <literal>disconnected</literal>
                  ,
                  <literal>error</literal>
                  ,
                  <literal>initializing</literal>
                  ,
                  or
                  <literal>ok</literal>
                  .
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesDropped</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that have been dropped for the
                  channel
                  (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesSkippedBack</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that were discarded because they
                  skipped
                  back in time (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
              <row>
                <entry>totalSamplesWritten</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  number of samples that have been written for the
                  channel
                  (since the last reinitialization).
                  <literal>null</literal>
                  if status information is not
                  available.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If information about the channel can currently not be
          retrieved, HTTP
          error code 503 (service unavailable) is
          returned and the response body
          is invalid.
          If the channel does
          not exist or if a server ID has been specified and
          the channel
          belongs to a different server, HTTP error code 404 (not
          found)
          is returned and the response body is invalid.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /admin/api/1.0/channels/all/by-name/someChannel/
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "channelDataId": "ef126a63-375b-4f28-a1d1-17e8f42271a9",
  "channelName": "someChannel",
  "controlSystemName": "Channel Access",
  "controlSystemType": "channel_access",
  "decimationLevelToRetentionPeriod": {
    "0": "864000",
    "30": "31536000",
    "900": "0"
  },
  "enabled": true,
  "errorMessage": null,
  "options": {},
  "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd",
  "serverName": "myserver",
  "state": "OK",
  "totalSamplesDropped": "0",
  "totalSamplesSkippedBack": "1",
  "totalSamplesWritten": "42"
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.channels_by_server_import">
      <title>Import channel configuration for a server</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for importing the channel configuration
          for a server
          has the following form:
        </para>
        <programlisting>
          /channels/by-server/
          <replaceable>&lt;server ID&gt;</replaceable>
          /import
        </programlisting>
        <para>
          The
          <replaceable>&lt;server ID&gt;</replaceable>
          has to be replaced by
          the UUID associated with the respective
          server.
          The request must use the
          <literal>POST</literal>
          method.
        </para>
        <para>
          The request body must be a JSON object with the following
          members:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>addChannels</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if channels present in the
                  configuration file, but
                  missing on the server shall be added
                  to the server.
                  <literal>false</literal>
                  if no new channels shall be added to
                  the server.
                  Default is
                  <literal>false</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>configurationFile</entry>
                <entry>array of byte</entry>
                <entry>string</entry>
                <entry>
                  Base64
                  (
                  <link xlink:href="https://tools.ietf.org/html/rfc4648">RFC 4648</link>
                  )
                  encoded contents of the configuration file that shall
                  be
                  imported.
                </entry>
              </row>
              <row>
                <entry>removeChannels</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if channels missing in the
                  configuration file, but
                  present on the server shall be removed
                  from the server.
                  <literal>false</literal>
                  if no new channels shall be removed
                  from the server.
                  Default is
                  <literal>false</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>simulate</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if no modifications shall be made.
                  This means that the
                  response will have the same content as if
                  all changes
                  where applied successfully.
                  This is useful in
                  combination with the
                  <literal>removeChannels</literal>
                  option in order to see which
                  channels would be removed.
                  Default is
                  <literal>false</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>updateChannels</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if channels present in the
                  configuration file and also
                  present on the server shall be
                  updated to match the
                  configuration specified in the file.
                  <literal>false</literal>
                  if no existing channels shall be
                  changed.
                  Default is
                  <literal>false</literal>
                  .
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the with the following
          members:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>addOrUpdateFailed</entry>
                <entry>map of string to string</entry>
                <entry>object (with string attribute values)</entry>
                <entry>
                  object with a member for each channels for which an
                  add or
                  update operation failed.
                  The channel name is the
                  member’s key and the corresponding
                  error message is the
                  member’s value.
                  May be
                  <literal>null</literal>
                  if there is a global error or
                  if the data is sent in
                  response to a request that has the
                  <literal>simulate</literal>
                  flag set.
                </entry>
              </row>
              <row>
                <entry>addOrUpdateSucceeded</entry>
                <entry>set of string</entry>
                <entry>array of string</entry>
                <entry>
                  list of channels for which an add or update operation
                  was
                  successful.
                  In case of an update operation, this
                  does not necessarily mean
                  that the server configuration
                  has been updated.
                  It might also have already been
                  identical to the configuration
                  specified by the file.
                  May be
                  <literal>null</literal>
                  if there is a global error.
                </entry>
              </row>
              <row>
                <entry>errorMessage</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message indicating a global problem.
                  Such a
                  problem does not affect a specific channel, but the
                  import process in general (e.g. a syntax error in the
                  configuration file).
                  If such an error is present, no
                  changes have been made to the
                  server configuration.
                  <literal>null</literal>
                  if there is no global error.
                </entry>
              </row>
              <row>
                <entry>removeFailed</entry>
                <entry>map of string to string</entry>
                <entry>object (with string attribute values)</entry>
                <entry>
                  object with a member for each channel for which a
                  remove
                  operation failed.
                  The channel name is the
                  member’s key and the corresponding
                  error message is the
                  member’s value.
                  May be
                  <literal>null</literal>
                  if there is a global error or
                  if the data is sent in
                  response to a request that has the
                  <literal>simulate</literal>
                  flag set.
                </entry>
              </row>
              <row>
                <entry>removeSucceeded</entry>
                <entry>set of string</entry>
                <entry>array of string</entry>
                <entry>
                  list of channels for which a remove operation was
                  successful.
                  May be
                  <literal>null</literal>
                  if there is a global error.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If there is a problem with the request parameters (e.g. a
          syntax eror
          in the configuration file), HTTP error code 400
          (bad request) is
          returned.
          If there is a general problem with
          the request body, the response body
          is invalid.
          If there only is
          a problem with the contents of the configuration
          file, a valid
          JSON response with the
          <literal>errorMessage</literal>
          set is returned.
          If the user could not be authenticated or is
          not authorized to use
          the import function, HTTP error code 403
          (forbidden) is returned and
          the response body is invalid.
          If
          there is an error when applying the changes for at least one
          channel, HTTP error code 500 (internal server error) is
          returned and
          the channel is added to the
          <literal>addOrUpdateFailed</literal>
          or
          <literal>removeFailed</literal>
          maps.
          If there is a general problem while processing the
          request (e.g. the
          database is currently unavailable), HTTP
          error code 503 (service
          unavailable) is returned and the
          <literal>errorMessage</literal>
          is
          set in the response.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
POST /admin/api/1.0/channels/by-server/7cf8f393-cd00-46ae-9343-53e9cb5793fd/import

{
  "addChannels": true,
  "configurationFile": "PD94bWwgdmVy... (shortened for this example)",
  "removeChannels": true
}
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "addOrUpdateFailed": {
    "someChannel": "Channel \"someChannel\" cannot be added because a channel
↪with the same name already exists."
  },
  "addOrUpdateSucceed": [
    "newChannel"
  ],
  "errorMessage": null,
  "removeFailed": {},
  "removeSucceeded": [
    "someOtherChannel"
  ]
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.channels_by_server_export">
      <title>Export channel configuration for a server</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for exporting the channel configuration
          for a server
          has the following form:
        </para>
        <programlisting>
          /channels/by-server/
          <replaceable>&lt;server ID&gt;</replaceable>
          /export
        </programlisting>
        <para>
          The
          <replaceable>&lt;server ID&gt;</replaceable>
          has to be replaced by
          the UUID associated with the respective
          server.
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the with the following
          members:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>configurationFile</entry>
                <entry>array of byte</entry>
                <entry>string</entry>
                <entry>
                  Base64
                  (
                  <link xlink:href="https://tools.ietf.org/html/rfc4648">RFC 4648</link>
                  )
                  encoded contents of the exported configuration file
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If there is a general problem while processing the request
          (e.g. the
          database is currently unavailable), HTTP error code
          503 (service
          unavailable) is returned and the
          <literal>errorMessage</literal>
          is
          set in the response.
          If the specified server does not exist,
          HTTP error code 404 (not
          found) is returned and the response
          body is invalid.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /admin/api/1.0/channels/by-server/7cf8f393-cd00-46ae-9343-53e9cb5793fd/export
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "configurationFile": "PD94bWwgdmVy... (shortened for this example)"
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.run_archive_configuration_commands">
      <title>Run archive configuration commands</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for running archive configuration commands
          has the
          following form:
        </para>
        <programlisting>
          /run-archive-configuration-commands
        </programlisting>
        <para>
          The request must use the
          <literal>POST</literal>
          method.
        </para>
        <para>
          The request body must be a JSON object that has a single
          member.
          This member has the key
          <literal>commands</literal>
          and an array as
          its value.
          Each of the array elements must be a
          JSON object that represents an
          archive configuration command.
        </para>
        <para>
          The format of the object depends on the respective command and
          is
          described in
          <xref linkend="admin_api.run_archive_configuration_commands.commands" />
          .
          Commands may be processed in parallel, so a single request
          should
          never specify more than one command that affects the
          same channel as
          the result is not predictable.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the with the following
          members:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>errorMessage</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message indicating a global problem.
                  Such a
                  problem does not affect a specific channel, but the
                  whole execution (e.g. problems while accessing the
                  database).
                  If such an error is present, no changes have
                  been made to the
                  server configuration.
                  <literal>null</literal>
                  if there is no global error.
                </entry>
              </row>
              <row>
                <entry>results</entry>
                <entry>array of object</entry>
                <entry>array of object</entry>
                <entry>
                  result object for each command that was specified in
                  the
                  request.
                  The results have the same order as the
                  commands had in the
                  request.
                  May be
                  <literal>null</literal>
                  if
                  <literal>errorMessage</literal>
                  is set.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          Each result object is a JSON object with the following
          structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>command</entry>
                <entry>object</entry>
                <entry>object</entry>
                <entry>
                  command to which this result belongs.
                  This command
                  object is equal to the one that has been
                  specified in
                  the request, but some members may differ slightly
                  due
                  to normalization.
                </entry>
              </row>
              <row>
                <entry>errorMessage</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message describing the reason for which the
                  operation
                  failed.
                  <literal>null</literal>
                  if the operation was successful or if
                  no explanation
                  for the error is available.
                </entry>
              </row>
              <row>
                <entry>success</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if the command was executed
                  successfully,
                  <literal>false</literal>
                  if the command failed.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If the user could not be authenticated or is not authorized to
          use
          the import function, HTTP error code 403 (forbidden) is
          returned and
          the response body is invalid.
          If there is an error
          for at least one command, HTTP error code 500
          (internal server
          error) is returned and the
          <literal>success</literal>
          member of the corresponding command or commands is set to
          <literal>false</literal>
          .
          If there is a general problem while processing the request
          (e.g. the
          database is currently unavailable), HTTP error code
          503 (service
          unavailable) is returned and the
          <literal>errorMessage</literal>
          is
          set in the response.
        </para>
      </simplesect>

      <simplesect
        xml:id="admin_api.run_archive_configuration_commands.commands">
        <title>Archive Configuration Commands</title>
        <para>
          There are seven different archive configuration commands:
        </para>
        <itemizedlist>
          <listitem>
            <simpara>
              add channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              add or update channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              move channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              refresh channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              remove channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              rename channel
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              update channel
            </simpara>
          </listitem>
        </itemizedlist>
        <para>
          Each command is described by a JSON object, but except for the
          common
          <literal>commandType</literal>
          member, each of the different commands
          has a slightly different
          structure.
        </para>
        <bridgehead>Add channel</bridgehead>
        <para>
          The add channel command adds a new channel to the archive
          configuration.
          The channel is only added if it does not exist
          yet.
          If there already is a channel with the same name, the
          operation fails.
          The object for the add channel command has the
          following structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be added.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>add_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>controlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system
                  support that shall
                  be used for the channel.
                  This is the
                  same identifier that is also used in configuration
                  files.
                </entry>
              </row>
              <row>
                <entry>decimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels for the channel (identified by their
                  decimation periods specified in seconds).
                  The raw
                  decimation level (with a decimation period of zero) is
                  always added, even if it is not specified in the
                  array.
                  If the whole array is
                  <literal>null</literal>
                  , this is
                  interpreted like an array containing zero as
                  its only element.
                </entry>
              </row>
              <row>
                <entry>decimationLevelToRetentionPeriod</entry>
                <entry>map of int to int</entry>
                <entry>object with string member values</entry>
                <entry>
                  retention period for each decimation level (specified
                  in
                  seconds).
                  Each member uses the decimation period of
                  the respective
                  decimation level as its key and the
                  retention period as its
                  value.
                  A value of zero means
                  that samples shall be retained
                  indefinitely.
                  Entries for
                  a decimation level that is not also specified in
                  <literal>decimationLevels</literal>
                  are discarded (except for
                  the raw decimation level
                  which is always included implicitly).
                  Negative
                  retention periods are converted to zero.
                  If a
                  decimation level is specified in
                  <literal>decimationLevels</literal>
                  , but not in
                  <literal>decimationLevelToRetentionPeriod</literal>
                  , a
                  retention period of zero is assumed.
                  If the whole
                  object is
                  <literal>null</literal>
                  , a retention
                  period of zero is used for all decimation
                  levels.
                </entry>
              </row>
              <row>
                <entry>enabled</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if archiving shall be enabled for the
                  channel,
                  <literal>false</literal>
                  if archiving shall be
                  disabled.
                </entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>map of string to string</entry>
                <entry>object with string member values</entry>
                <entry>
                  control-system-specific configuration options.
                  The
                  member key is the option name and the member value is
                  the
                  option value.
                  Specifying
                  <literal>null</literal>
                  has the same effect as
                  specifying an empty object.
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  UUID of the server to which the channel shall be
                  added.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Add or update channel</bridgehead>
        <para>
          The add or update channel command is very similar to the
          add channel
          command.
          However, instead of failing when the
          specified channel already exists,
          it updates the channel
          configuration to match the specified
          configuration.
        </para>
        <para>
          The control-system type of a channel cannot be changed, so
          the command
          fails if the channel exists, but its control-system
          type does not
          match the specified control-system type.
          The
          command also fails when the specified server ID does not match
          the
          server ID of the already existing channel.
          Channels can be
          moved from one server to another one, but the move
          channel
          command has to be used for this task.
        </para>
        <para>
          The object for the add or update channel command has the same
          structure as the add channel command, only the value of the
          <literal>commandType</literal>
          member is different:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be added or
                  updated.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>add_or_update_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>controlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system
                  support that shall
                  be used for the channel.
                  This is the
                  same identifier that is also used in configuration
                  files.
                </entry>
              </row>
              <row>
                <entry>decimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels for the channel (identified by their
                  decimation periods specified in seconds).
                  The raw
                  decimation level (with a decimation period of zero) is
                  always added, even if it is not specified in the
                  array.
                  If the whole array is
                  <literal>null</literal>
                  , this is
                  interpreted like an array containing zero as
                  its only element.
                </entry>
              </row>
              <row>
                <entry>decimationLevelToRetentionPeriod</entry>
                <entry>map of int to int</entry>
                <entry>object with string member values</entry>
                <entry>
                  retention period for each decimation level (specified
                  in
                  seconds).
                  Each member uses the decimation period of
                  the respective
                  decimation level as its key and the
                  retention period as its
                  value.
                  A value of zero means
                  that samples shall be retained
                  indefinitely.
                  Entries for
                  a decimation level that is not also specified in
                  <literal>decimationLevels</literal>
                  are discarded (except for
                  the raw decimation level
                  which is always included implicitly).
                  Negative
                  retention periods are converted to zero.
                  If a
                  decimation level is specified in
                  <literal>decimationLevels</literal>
                  , but not in
                  <literal>decimationLevelToRetentionPeriod</literal>
                  , a
                  retention period of zero is assumed.
                  If the whole
                  object is
                  <literal>null</literal>
                  , a retention
                  period of zero is used for all decimation
                  levels.
                </entry>
              </row>
              <row>
                <entry>enabled</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if archiving shall be enabled for the
                  channel,
                  <literal>false</literal>
                  if archiving shall be
                  disabled.
                </entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>map of string to string</entry>
                <entry>object with string member values</entry>
                <entry>
                  control-system-specific configuration options.
                  The
                  member key is the option name and the member value is
                  the
                  option value.
                  Specifying
                  <literal>null</literal>
                  has the same effect as
                  specifying an empty object.
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  UUID of the server to which the channel shall be
                  added if it
                  does not exist yet or to which it must
                  belong if it already
                  exists.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Move channel</bridgehead>
        <para>
          The move channel command moves a channel from one server to a
          another one.
          If the specified channel does not exist, the
          command fails.
          It also fails if the specified
          <literal>expectedOldServerId</literal>
          does not match the server ID of the channel’s current server.
          The object for the move channel command has the following
          structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be moved.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>move_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>expectedOldServerId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  expected UUID of the server which currently owns the
                  channel.
                  If
                  <literal>null</literal>
                  , the channel is moved regardless of
                  the server it
                  currently belongs to.
                </entry>
              </row>
              <row>
                <entry>newServerId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  UUID of the server to which the channel shall be
                  moved.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Refresh channel</bridgehead>
        <para>
          The refresh channel command causes a server to temporarily
          stop
          archiving for that channel, reload its configuration, and
          resume
          archiving with the freshly loaded configuration.
          This
          command succeeds, even if the channel does not exist or
          actually
          exists on a different server.
          However, the actual
          refresh action only happens on the specified
          server.
          The object
          for the refresh channel command has the following
          structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be refreshed.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>refresh_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  UUID of the server on which the refresh action
                  should run.
                  This does not have to be, but typically
                  should be the UUID of
                  the server that owns the channel.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Remove channel</bridgehead>
        <para>
          The remove channel command deletes a channel (and all its
          data).
          If the specified channel does not exist, the command
          fails.
          It also fails if the specified
          <literal>expectedServerId</literal>
          does not match the server ID of the channel’s current server.
          The object for the remove channel command has the following
          structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be deleted.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>remove_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>expectedServerId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  expected UUID of the server which currently owns the
                  channel.
                  If
                  <literal>null</literal>
                  , the channel is deleted regardless
                  of the server it
                  currently belongs to.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Rename channel</bridgehead>
        <para>
          The rename channel command changes the name of a channel.
          If
          the specified channel does not exist or the specified
          <literal>newChannelName</literal>
          is already in use, the command
          fails.
          It also fails if the
          specified
          <literal>expectedServerId</literal>
          does not match the server ID of the channel’s current server.
          The object for the rename channel command has the following
          structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>rename_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>expectedServerId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  expected UUID of the server which currently owns the
                  channel.
                  If
                  <literal>null</literal>
                  , the channel is renamed regardless
                  of the server it
                  currently belongs to.
                </entry>
              </row>
              <row>
                <entry>newChannelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  new name for the channel.
                </entry>
              </row>
              <row>
                <entry>oldChannelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  old name of the channel.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <bridgehead>Update channel</bridgehead>
        <para>
          The update channel command updates the configuration of an
          existing
          channel. If the specified channel does not exist, the
          operation fails.
          It also fails if the
          <literal>expectedControlSystemType</literal>
          does
          not match the actual control-system type of the channel or
          the
          <literal>expectedServerId</literal>
          does not match the ID of the
          server that owns the channel.
        </para>
        <para>
          The set of decimation levels that shall be added and removed
          can be
          described in an explicit or in a differential fashion.
          For an explicit description, use the
          <literal>decimationLevels</literal>
          member.
          For a differential description, use the
          <literal>addDecimationLevels</literal>
          and
          <literal>removeDecimationLevels</literal>
          members.
          Only one of the two ways to describe the change can be
          used at the
          same time.
          Setting both
          <literal>decimationLevels</literal>
          and either or both of
          <literal>addDecimationLevels</literal>
          and
          <literal>removeDecimationLevels</literal>
          results in an error.
        </para>
        <para>
          If decimation levels are listed in
          <literal>decimationLevels</literal>
          or
          <literal>addDecimationLevels</literal>
          , but do not have a
          corresponding entry in
          <literal>decimationLevelToRetentionPeriod</literal>
          , a retention
          period of zero is assumed for these decimation
          levels, even if they
          already exist with a different retention
          period.
        </para>
        <para>
          Like the decimation levels, the control-system-specific
          configuration
          options can also be described in an explicit or
          in a differential
          fashion.
          For an explicit description, use the
          <literal>options</literal>
          member.
          For a differential description, use the
          <literal>addOptions</literal>
          and
          <literal>removeOptions</literal>
          members.
          Only one of the two ways to describe the change can be
          used at the
          same time.
          Setting both
          <literal>options</literal>
          and either or both of
          <literal>addOptions</literal>
          and
          <literal>removeOptions</literal>
          results in an error.
        </para>
        <para>
          The object for the update channel command has the
          following structure:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>addDecimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels (identified by their decimation
                  periods
                  specified in seconds) that shall be added for
                  the channel.
                  If the whole array is
                  <literal>null</literal>
                  and
                  <literal>decimationLevels</literal>
                  is also
                  <literal>null</literal>
                  , no decimation levels are added.
                </entry>
              </row>
              <row>
                <entry>addOptions</entry>
                <entry>map of string to string</entry>
                <entry>object with string member values</entry>
                <entry>
                  control-system-specific configuration options that
                  shall be
                  added to the channel configuration.
                  The member
                  key is the option name and the member value is the
                  option value.
                  If one of the specified options already
                  exists, its value is
                  updated with the specified value.
                  If this member is
                  <literal>null</literal>
                  and
                  <literal>options</literal>
                  is also
                  <literal>null</literal>
                  ,
                  no control-system-specific options are added for the
                  channel.
                </entry>
              </row>
              <row>
                <entry>channelName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the channel that shall be updated.
                </entry>
              </row>
              <row>
                <entry>commandType</entry>
                <entry>enum</entry>
                <entry>string</entry>
                <entry>
                  always the literal string
                  <literal>update_channel</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>decimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels for the channel (identified by their
                  decimation periods specified in seconds).
                  The raw
                  decimation level (with a decimation period of zero) is
                  always added, even if it is not specified in the
                  array.
                  If the whole array is
                  <literal>null</literal>
                  and
                  <literal>addDecimationLevels</literal>
                  and
                  <literal>removeDecimationLevels</literal>
                  are also
                  <literal>null</literal>
                  , no decimation levels are added or
                  removed.
                  If the
                  array is not
                  <literal>null</literal>
                  all existing
                  decimation levels (except for the special
                  raw decimation
                  level) that are not also specified in
                  the array are removed.
                </entry>
              </row>
              <row>
                <entry>decimationLevelToRetentionPeriod</entry>
                <entry>map of int to int</entry>
                <entry>object with string member values</entry>
                <entry>
                  retention period for each decimation level (specified
                  in
                  seconds).
                  Each member uses the decimation period of
                  the respective
                  decimation level as its key and the
                  retention period as its
                  value.
                  A value of zero means
                  that samples shall be retained
                  indefinitely.
                  Entries for
                  a decimation level that are not also specified in
                  <literal>decimationLevels</literal>
                  or
                  <literal>addDecimationLevels</literal>
                  and that do not already
                  exist, are discarded (except
                  for the raw decimation level
                  which is always included
                  implicitly).
                  Negative retention periods are converted
                  to zero.
                  If a decimation level is specified in
                  <literal>decimationLevels</literal>
                  or
                  <literal>addDecimationLevels</literal>
                  , but not in
                  <literal>decimationLevelToRetentionPeriod</literal>
                  , a
                  retention period of zero is assumed.
                  If the whole
                  object is
                  <literal>null</literal>
                  , a retention
                  period of zero is used for all decimation
                  levels that are
                  newly added and the retention periods
                  of all other decimation
                  levels are not changed.
                </entry>
              </row>
              <row>
                <entry>enabled</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  <literal>true</literal>
                  if archiving shall be enabled for the
                  channel,
                  <literal>false</literal>
                  if archiving shall be
                  disabled.
                  If
                  <literal>null</literal>
                  , the enabled flag is not changed.
                </entry>
              </row>
              <row>
                <entry>expectedControlSystemType</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  internal identifier for the control-system support
                  that is
                  expected to be used for the channel.
                  If
                  <literal>null</literal>
                  , the channel is updated regardless
                  of its
                  control-system type.
                </entry>
              </row>
              <row>
                <entry>expectedServerId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  UUID of the server to which the channel must belong.
                  If
                  <literal>null</literal>
                  , the channel is updated regardless
                  of the server to
                  which it belongs.
                </entry>
              </row>
              <row>
                <entry>options</entry>
                <entry>map of string to string</entry>
                <entry>object with string member values</entry>
                <entry>
                  control-system-specific configuration options.
                  The
                  member key is the option name and the member value is
                  the
                  option value.
                  If this member is not
                  <literal>null</literal>
                  , all options
                  are replaced by the specified options,
                  removing options that
                  existed before, but were not
                  specified.
                  If this member is
                  <literal>null</literal>
                  and both
                  <literal>addOptions</literal>
                  and
                  <literal>removeOptions</literal>
                  are also
                  <literal>null</literal>
                  , the control-system specific options
                  for the channel
                  are not changed.
                </entry>
              </row>
              <row>
                <entry>removeDecimationLevels</entry>
                <entry>set of int</entry>
                <entry>array of string</entry>
                <entry>
                  decimation levels (identified by their decimation
                  periods
                  specified in seconds) that shall be removed
                  from the channel.
                  If the whole array is
                  <literal>null</literal>
                  and
                  <literal>decimationLevels</literal>
                  is also
                  <literal>null</literal>
                  , no decimation levels are removed.
                  The special
                  decimation level for raw samples is never removed,
                  even if zero is an element of this array.
                </entry>
              </row>
              <row>
                <entry>removeOptions</entry>
                <entry>set of string</entry>
                <entry>array of string</entry>
                <entry>
                  control-system-specific configuration options
                  (identified by
                  their names) that shall be removed from
                  the channel
                  configuration.
                  If one of the specified
                  options does not exist, it simply is
                  not removed.
                  If
                  this member is
                  <literal>null</literal>
                  and
                  <literal>options</literal>
                  is also
                  <literal>null</literal>
                  ,
                  no control-system-specific options are removed from
                  the
                  channel configuration.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
POST /admin/api/1.0/run-archive-configuration-commands

{
  "commands": [
    {
      "channelName": "someExistingChannel",
      "commandType": "add_channel",
      "controlSystemType": "channel_access",
      "decimationLevels": ["0", "30", "300"],
      "decimationLevelToRetentionPeriod": {
        "0": "864000"
      },
      "enabled": true,
      "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd"
    },
    {
      "channelName": "someNewChannel",
      "commandType": "add_channel",
      "controlSystemType": "channel_access",
      "decimationLevelToRetentionPeriod": {
        "0": "31536000"
      },
      "enabled": true,
      "options": {
        "someControlSystemOption": "someValue"
      },
      "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd"
    },
    {
      "addDecimationLevels": ["30"],
      "channelName": "someOtherChannel",
      "commandType": "update_channel",
      "decimationLevelToRetentionPeriod": {
        "0": "864000",
        "30": "31536000"
      }
    }
  ]
}
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "results": [
    {
      "command": {
        "channelName": "someExistingChannel",
        "commandType": "add_channel",
        "controlSystemType": "channel_access",
        "decimationLevels": ["0", "30", "300"],
        "decimationLevelToRetentionPeriod": {
          "0": "864000",
          "30": "0",
          "300": "0"
        },
        "enabled": true,
        "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd"
      },
      "errorMessage": "Channel \"someExistingChannel\" cannot be added because a
↪channel with the same name already exists.",
      "success": false
    },
    {
      "command": {
        "channelName": "someNewChannel",
        "commandType": "add_channel",
        "controlSystemType": "channel_access",
        "decimationLevels": ["0"],
        "decimationLevelToRetentionPeriod": {
          "0": "31536000"
        },
        "enabled": true,
        "options": {
          "someControlSystemOption": "someValue"
        },
        "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd"
      },
      "success": true
    },
    {
      "command": {
        "addDecimationLevels": ["30"],
        "channelName": "someOtherChannel",
        "commandType": "update_channel",
        "decimationLevelToRetentionPeriod": {
          "0": "864000",
          "30": "31536000"
        }
      },
      "success": true
    }
  ]
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.cluster_status">
      <title>Get the cluster status</title>
      <simplesect>
        <title>Request</title>
        <para>
          The request URL for retrieving the cluster status has the
          following
          form:
        </para>
        <programlisting>
          /cluster-status/
        </programlisting>
        <para>
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the
          <literal>servers</literal>
          attribute as its only member.
          The
          <literal>servers</literal>
          attribute has an array as its value
          that contains an element
          for each server in the cluster.
          Each of these elements is an
          object with the following attributes:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>lastOnlineTime</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  last time the server successfully registered
                  itself with the
                  cluster. The time is specified as the
                  number of milliseconds
                  since January 1st, 1970,
                  00:00:00 UTC.
                </entry>
              </row>
              <row>
                <entry>online</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  flag indicating whether the server is considered
                  online. The
                  server is considered online when it has
                  recently renewed its
                  registration.
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  ID of the server.
                </entry>
              </row>
              <row>
                <entry>serverName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the server. Typically,
                  this is the
                  hostname of the server.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
        <para>
          If the cluster status is currently not available, HTTP
          error code 503
          (service unavailable) is returned and the
          response body is invalid.
        </para>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /cluster-status/
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "servers": [
    {
      "lastOnlineTime": "1490634430220",
      "online": true,
      "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd",
      "serverName": "myserver"
    },
    {
      "lastOnlineTime": "1490634432760",
      "online": true,
      "serverId": "6fc4efe0-ea4a-438e-9b0a-b5e5654cbed9",
      "serverName": "otherserver"
    },
    {
      "lastOnlineTime": "1490631012050",
      "online": false,
      "serverId": "8c6959e2-0388-4854-8ebf-88a752375962",
      "serverName": "thirdserver"
    }
  ]
}
]]></programlisting>
      </simplesect>
    </section>

    <section xml:id="admin_api.server_status">
      <title>Get the server status</title>
      <simplesect>
        <title>Request</title>
        <para>
          This function provides status information about the
          targeted server.
          In contrast to most other functions, it
          actually matters which server
          is used when running this command
          because the result will actually
          depend on the targeted server.
          The request URL has the following form:
        </para>
        <programlisting>
          /server-status/this-server/
        </programlisting>
        <para>
          The request must use the
          <literal>GET</literal>
          method.
        </para>
      </simplesect>

      <simplesect>
        <title>Response</title>
        <para>
          The response is a JSON object with the following
          attributes:
        </para>
        <informaltable>
          <tgroup align="left" cols="4">
            <colspec colwidth="1*" />
            <colspec colwidth="1*" />
            <colspec colwidth="2*" />
            <colspec colwidth="4*" />
            <thead>
              <row>
                <entry>Field name</entry>
                <entry>Internal data type</entry>
                <entry>JSON data type</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>cassandraClusterName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the Cassandra cluster to which
                  this
                  server is connected. May be
                  <literal>null</literal>
                  if the
                  server has not connected to the Cassandra
                  cluster yet. In this
                  case,
                  <literal>cassandraError</literal>
                  is not
                  <literal>null</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>cassandraError</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  error message indicating a problem that occurred while
                  trying
                  to connect to the Cassandra cluster. This is
                  <literal>null</literal>
                  if the connection to the Cassandra
                  cluster has been
                  established after starting the server (even
                  if the
                  connection is currently disrupted).
                </entry>
              </row>
              <row>
                <entry>cassandraKeyspaceName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  name of the Cassandra keyspace which is used by the
                  Cassandra
                  PV Archiver. May be
                  <literal>null</literal>
                  if the server has
                  not connected to the Cassandra
                  cluster yet. In this case,
                  <literal>cassandraError</literal>
                  is not
                  <literal>null</literal>
                  .
                </entry>
              </row>
              <row>
                <entry>channelsDisconnected</entry>
                <entry>int</entry>
                <entry>string</entry>
                <entry>
                  number of channels that are in the disconnected
                  state.
                </entry>
              </row>
              <row>
                <entry>channelsError</entry>
                <entry>int</entry>
                <entry>string</entry>
                <entry>
                  number of channels that are in the error state.
                </entry>
              </row>
              <row>
                <entry>channelsTotal</entry>
                <entry>int</entry>
                <entry>string</entry>
                <entry>
                  total number of channels on this server. If the
                  server has not
                  been initialized yet (e.g. because it
                  cannot connect to the
                  database), this number is zero,
                  even if there are channels
                  that belong to the server.
                </entry>
              </row>
              <row>
                <entry>serverId</entry>
                <entry>UUID</entry>
                <entry>string</entry>
                <entry>
                  ID of the server.
                </entry>
              </row>
              <row>
                <entry>serverLastOnlineTime</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  last time this server successfully registered
                  itself with the
                  cluster. The time is specified as the
                  number of milliseconds
                  since January 1st, 1970,
                  00:00:00 UTC. This number might be
                  zero if the server
                  has not successfully registered itself with
                  the cluster
                  since it was started.
                </entry>
              </row>
              <row>
                <entry>serverName</entry>
                <entry>string</entry>
                <entry>string</entry>
                <entry>
                  human-readable name of the server. Typically,
                  this is the
                  hostname of the server.
                </entry>
              </row>
              <row>
                <entry>serverOnline</entry>
                <entry>boolean</entry>
                <entry>boolean</entry>
                <entry>
                  flag indicating whether the server considers
                  itself to be
                  online. The server considers itself online
                  when a sufficient
                  amount of time has passed since
                  successfully registering with
                  the cluster and the
                  renewal of the registration has not failed
                  since.
                </entry>
              </row>
              <row>
                <entry>totalSamplesDropped</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  total number of samples that have been dropped
                  (discarded) by
                  this server because they arrived to
                  quickly and could not be
                  written in time. This counter
                  is reset when the server is
                  restarted.
                </entry>
              </row>
              <row>
                <entry>totalSamplesWritten</entry>
                <entry>long</entry>
                <entry>string</entry>
                <entry>
                  total number of samples that have been written
                  (persisted) by
                  this server. This counter is reset when
                  the server is
                  restarted.
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </simplesect>

      <simplesect>
        <title>Example</title>
        <para>Request:</para>
        <programlisting><![CDATA[
GET /admin/api/1.0/server-status/this-server/
]]></programlisting>
        <para>Response:</para>
        <programlisting><![CDATA[
{
  "cassandraClusterName": "My Cassandra cluster",
  "cassandraError": null,
  "cassandraKeyspaceName": "pv_archive",
  "channelsDisconnected": "1",
  "channelsError": "0",
  "channelsTotal": "2",
  "serverId": "7cf8f393-cd00-46ae-9343-53e9cb5793fd",
  "serverLastOnlineTime": "1490634430220",
  "serverName": "myserver",
  "serverOnline": "true",
  "totalSamplesDropped": "3",
  "totalSamplesWritten": "4242"
}
]]></programlisting>
      </simplesect>
    </section>
  </appendix>

  <appendix xml:id="channel_access">
    <title>Channel Access control-system support</title>
    <para>
      The Channel Access control-system support is bundled with the
      standard
      distribution of the Cassandra PV Archiver server.
      It
      provides support for process variables that can be accessed
      through the
      Channel Access protocol, which is the protocol
      typically used by
      control systems that are based on
      <link xlink:href="http://www.aps.anl.gov/epics/">EPICS</link>
      .
      The Channel Access control-system support is identified by the ID
      <literal>channel_access</literal>
      .
    </para>
    <para>
      This control-system support is based on the
      <link xlink:href="http://oss.aquenos.com/epics/jackie/">EPICS Jackie</link>
      library, which is internally used for implementing the Channel
      Access
      protocol.
      This way, the control-system support works on all
      platforms without having
      dependencies on any platform-specific
      libraries.
    </para>
    <para>
      This appendix describes how the control-system support is
      configured
      (see
      <xref linkend="channel_access.configuration" />
      ), how the sample
      decimation is implemented (see
      <xref linkend="channel_access.decimated_samples" />
      ), and how it stores
      samples in the database (see
      <xref linkend="channel_access.cql_layout" />
      ).
    </para>

    <section xml:id="channel_access.configuration">
      <title>Configuration</title>
      <para>
        The Channel Access control-system support offers a number of
        configuration options that can be specified for each channel.
        The same options can also be specified in the server’s
        configuration
        file (see
        <xref linkend="server" />
        ,
        <xref linkend="server.configuration" />
        ).
        When specified in the server’s configuration file, the options
        serve as
        defaults that are used when an option is not specified
        for a specific
        channel that is managed by the respective server.
      </para>
      <para>
        When specified in the server’s configuration file, the options
        must be
        specified in the
        <literal>controlSystem</literal>
        →
        <literal>channelAccess</literal>
        section of the file or the prefix
        <literal>controlSystem.channelAccess</literal>
        must be added to the
        option name.
        When specified for a channel,
        the option names are used without any
        prefix being added.
        Option
        names are case-sensitive.
      </para>

      <section xml:id="channel_access.configuration.clock_source">
        <title>Clock source option</title>
        <para>
          The
          <literal>clockSource</literal>
          option specifies which time stamp
          is used when archiving
          samples.
          When set to
          <literal>local</literal>
          , the time of the archiving
          server’s system clock is used.
        </para>
        <para>
          When set to
          <literal>origin</literal>
          , the time that is sent by the
          Channel Access server (together
          with the sample’s value) is used and
          the
          <link linkend="channel_access.configuration.max_clock_skew">
            <literal>maxClockSkew</literal>
            option
          </link>
          controls when a sample is discarded without being archived.
        </para>
        <para>
          When set to
          <literal>prefer_origin</literal>
          (the default), the
          original time (as sent by the Channel Access
          server) is preferred.
          However, when the difference between the
          time specified by the
          archiving server’s system clock and the
          original time is greater than
          the limit specified by the
          <link linkend="channel_access.configuration.max_clock_skew">
            <literal>maxClockSkew</literal>
            option
          </link>
          ,
          the time from the local system clock is used instead.
        </para>
        <para>
          The
          <literal>prefer_origin</literal>
          setting is used as the default
          because it provides a reasonable
          balance between preferring a
          time-stamp that is close to the
          point in time when the value was
          actually measured and avoiding
          the use of completely bogus time-stamps
          (or discarding samples)
          when a device server’s clock is not properly
          synchronized.
        </para>
      </section>

      <section xml:id="channel_access.configuration.enabling_channel">
        <title>Enabling channel option</title>
        <para>
          The
          <literal>enablingChannel</literal>
          option specifies the name of a
          channel that controls whether
          archiving is enabled.
          This option is useful when a channel
          should only be archived when
          certain conditions are met (e.g.
          the facility is in a certain state of
          operation).
          By default,
          the
          <literal>enablingChannel</literal>
          option is not set,
          meaning that a channel is always archived
          (unless it has explicitly
          been disabled in the configuration).
        </para>
        <para>
          The channel name specified as the value of the
          <literal>enablingChannel</literal>
          option can be any valid Channel
          Access channel.
          That channel
          does not have to be present in the Cassandra PV
          Archiver’s
          configuration.
          When the enabling channel is not connected,
          archiving is disabled.
          When the enabling channel is connected,
          archiving is enabled depending
          on the enabling channel’s value.
          When the enabling channel’s value is of an integer type, the
          target
          channel is enabled if the enabling channel’s value is
          non-zero.
          When the enabling channel’s value is of a
          floating-point type, the
          target channel is enabled when the
          enabling channel’s value is neither
          zero nor not-a-number.
          When
          the enabling channel’s value is of a string type, the target
          channel is enabled when the enabling channel’s value is
          neither the
          empty string, nor “0”, “false”, “no”, or “off”.
          Leading and trailing white-space is ignored for this
          comparison and
          the comparison is not case sensitive.
        </para>
        <para>
          If this option is not set or set to the empty string (the
          default),
          archiving is always enabled.
          If a channel has been
          disabled in the archiving configuration, this
          option does not
          have any effect and archiving always stays disabled,
          regardless of the enabling channel’s connection state and
          value.
        </para>
      </section>

      <section xml:id="channel_access.configuration.max_clock_skew">
        <title>Maximum clock skew option</title>
        <para>
          The
          <literal>maxClockSkew</literal>
          option specifies the maximum
          difference that is allowed between
          the time sent by the Channel Access
          server (together with the
          sample’s value) and the local system clock
          of the archiving
          server.
          The specified value must be a finite, non-negative
          floating point
          number that specifies the maximum clock skew in
          seconds. The default
          value is 30 seconds.
          The effects of this
          option depend on the
          <link linkend="channel_access.configuration.clock_source">
            <literal>clockSource</literal>
            option
          </link>
          .
        </para>
        <para>
          When the
          <literal>clockSource</literal>
          option is set to “local”, this
          option does not have any
          effects.
        </para>
        <para>
          When the
          <literal>clockSource</literal>
          option is set to
          “prefer_origin”, this option controls which
          clock source is selected.
          When this option is set to zero or
          the difference between the time
          specified by the Channel Access
          server and the time specified by the
          archiving server’s system
          clock is less than the limit specified by
          this option, the time
          provided by the Channel Access server is used as
          the sample’s
          time stamp.
          When this option is non-zero and the difference
          between the time
          specified by the Channel Access server and the
          time specified by the
          archiving server’s system clock is
          greater than the limit specified by
          this option, the time
          provided by the archiving server’s system clock
          is used as the
          sample’s time stamp.
        </para>
        <para>
          When the
          <literal>clockSource</literal>
          option is set to “origin”,
          this option controls when a sample
          is discarded.
          When this option is set to zero or the difference
          between the time
          specified by the Channel Access server and the
          time specified by the
          archiving server’s system clock is less
          than the limit specified by
          this option, the sample is archived
          and the time provided by the
          Channel Access server is used as
          the sample’s time stamp.
          When this option is non-zero and the
          difference between the time
          specified by the Channel Access
          server and the time specified by the
          archiving server’s system
          clock is greater than the limit specified by
          this option, the
          sample is discarded without being archived.
        </para>
        <para>
        </para>
      </section>

      <section xml:id="channel_access.configuration.max_update_period">
        <title>Maximum update period option</title>
        <para>
          The
          <literal>maxUpdatePeriod</literal>
          option specifies the longest
          period that may pass between
          writing two samples.
          The specified value must be a finite,
          non-negative floating point
          number that specifies the maximum
          period (specified in seconds)
          between writing two samples.
          The
          default value is zero, which means that a sample is only
          written
          when the Channel Access server sends an update.
          By using
          this option, one can ensure that a new sample repeating the
          value of the previous sample is written when no new sample is
          received
          from the Channel Access server within the specified
          period of time.
          Typically, it makes sense to combine this
          option with the
          <link
            linkend="channel_access.configuration.write_sample_when_disabled">
            <literal>writeSampleWhenDisabled</literal>
          </link>
          and
          <link
            linkend="channel_access.configuration.write_sample_when_disconnected">
            <literal>writeSampleWhenDisconnected</literal>
          </link>
          options.
        </para>
        <para>
          Due to processing delays, the actual period between writing
          the two
          samples might be slightly greater than the specified
          period.
          For obvious reasons, the time stamp used when writing a
          sample without
          having received an update from the Channel
          Access server is always
          generated using the archiving server’s
          system clock, regardless of the
          <link linkend="channel_access.configuration.clock_source">
            <literal>clockSource</literal>
            option
          </link>
          .
        </para>
        <para>
          Mixing samples that use the archiving server’s system clock
          for
          generating the time-stamp with samples that use the time
          stamp
          provided by the Channel Access server can have the effect
          that
          updates that are received from the Channel Access server
          are actually
          not archived because a previously written sample
          has a (slightly)
          greater time stamp and the newer sample is
          therefore discarded (the
          Cassandra PV Archiver server never
          writes samples that have a time
          stamp less than or equal to a
          previously archive sample).
          For this reason, it is recommended
          to set the
          <literal>clockSource</literal>
          option to
          <literal>local</literal>
          when setting this option to a non-zero value.
        </para>
      </section>

      <section xml:id="channel_access.configuration.meta_data_monitor_mask">
        <title>Meta-data monitor mask option</title>
        <para>
          The
          <literal>metaDataMonitorMask</literal>
          option specifies the
          monitor mask that is used for monitoring a
          channel for meta-data
          (engineering units, alarm and display
          limits, etc.) changes.
          The bit of the monitor mask is set when
          the corresponding token (one
          of “value”, “archive”, “alarm”,
          and “property”) is present.
          Tokens can be separated by commas,
          pipes, or spaces.
          Please refer to the
          <link
            xlink:href="http://www.aps.anl.gov/epics/base/R3-15/4-docs/CAref.html">Channel Access Reference Manual</link>
          for details about the meaning of this mask bits.
          The event mask
          used when monitoring a channel for value changes is
          specified
          separately through the
          <link linkend="channel_access.configuration.monitor_mask">
            <literal>monitorMask</literal>
            option
          </link>
          .
          The default value for this option is “property”, which should
          typically have the effect that an update is sent by the server
          when
          one of the meta-data properties changes.
        </para>
      </section>

      <section xml:id="channel_access.configuration.min_update_period">
        <title>Minimum update period option</title>
        <para>
          The
          <literal>minUpdatePeriod</literal>
          option specifies the shortest
          period that must pass between
          writing two samples.
          The specified value must be a finite,
          non-negative floating point
          number that specifies the minimum
          period (in seconds) between writing
          two samples.
          The default
          value is zero, which means that a sample is always written
          when the Channel Access server sends an update, regardless of
          the time
          that has passed since receiving the last update.
        </para>
        <para>
          By using this option, one can limit the rate at which
          samples are
          written.
          This is useful when a Channel Access server
          sends updates at a much
          higher rate than they should be
          archived.
          However, for very high update rates, samples might
          still be lost if
          the system cannot process them as quickly as
          they arrive.
        </para>
      </section>

      <section xml:id="channel_access.configuration.monitor_mask">
        <title>Monitor mask option</title>
        <para>
          The
          <literal>monitorMask</literal>
          option specifies the
          monitor mask that is used for monitoring a
          channel for value and alarm
          state changes.
          The bit of the
          monitor mask is set when the corresponding token (one
          of
          “value”, “archive”, “alarm”, and “property”) is present.
          Tokens can be separated by commas, pipes, or spaces.
          Please
          refer to the
          <link
            xlink:href="http://www.aps.anl.gov/epics/base/R3-15/4-docs/CAref.html">Channel Access Reference Manual</link>
          for details about the meaning of this mask bits.
          The event mask
          used when monitoring a channel for value changes is
          specified
          separately through the
          <link linkend="channel_access.configuration.monitor_mask">
            <literal>monitorMask</literal>
            option
          </link>
          .
          The default value for this option is “archive|alarm”.
        </para>
        <para>
          When not using the
          <link linkend="channel_access.configuration.min_update_period">
            <literal>minUpdatePeriod</literal>
            option
          </link>
          ,
          a sample is written for each update that is received from the
          Channel
          Access server.
          For this reason, the monitor mask has an
          effect on the rate at which
          samples are written.
          Most Channel
          Access servers send updates at a lower rate when setting
          the
          “archive” instead of the “value” bit, which is why this bit is
          used in the default value for this option.
          The “alarm” bit, on
          the other hand, triggers an update each time the
          channel’s
          alarm state changes.
        </para>
      </section>

      <section xml:id="channel_access.configuration.write_sample_when_disabled">
        <title>Write sample when disabled option</title>
        <para>
          The
          <literal>writeSampleWhenDisabled</literal>
          option allows for
          writing a sample when a channel is disabled.
          This option is enabled by setting it to “true”.
          By default, it
          is set to “false”, which disables this option.
          Typically, it
          makes sense to combine this option with the
          <link linkend="channel_access.configuration.max_update_period">
            <literal>maxUpdatePeriod</literal>
          </link>
          and
          <link
            linkend="channel_access.configuration.write_sample_when_disconnected">
            <literal>writeSampleWhenDisconnected</literal>
          </link>
          options.
        </para>
        <para>
          When this option is enabled, a special sample acting as a
          marker for
          the disabled state is written to the archive when a
          channel is
          disabled.
          A channel can be disabled in the archive
          configuration or through an
          <link linkend="channel_access.configuration.enabling_channel">enabling channel</link>
          .
          By writing such a marker sample, one can tell from the
          archived data
          whether a value simply did not change for an
          extended period of time
          or no samples where written because
          archiving was disabled.
        </para>
        <para>
          When writing a marker sample to indicate that archiving is
          disabled,
          the time from the archiving server’s system clock is
          used, regardless
          of the
          <link linkend="channel_access.configuration.clock_source">
            <literal>clockSource</literal>
            option
          </link>
          .
          Mixing samples that use the archiving server’s system clock
          for
          generating the time-stamp with samples that use the time
          stamp
          provided by the Channel Access server can have the effect
          that
          updates that are received from the Channel Access server
          are actually
          not archived because a previously written sample
          has a (slightly)
          greater time stamp and the newer sample is
          therefore discarded (the
          Cassandra PV Archiver server never
          writes samples that have a time
          stamp less than or equal to a
          previously archive sample).
          For this reason, it is recommended
          to set the
          <literal>clockSource</literal>
          option to
          <literal>local</literal>
          when enabling this option.
        </para>
      </section>

      <section
        xml:id="channel_access.configuration.write_sample_when_disconnected">
        <title>Write sample when disconnected option</title>
        <para>
          The
          <literal>writeSampleWhenDisconnected</literal>
          option allows for
          writing a sample when a channel is
          disconnected.
          This option is enabled by setting it to “true”.
          By default, it is set to “false”, which disables this option.
        </para>
        <para>
          When this option is enabled, a special sample acting as a
          marker for
          the disconnected state is written to the archive
          when a channel is
          disconnected.
          By writing such a marker sample,
          one can tell from the archived data
          whether a value simply did
          not change for an extended period of time
          or no samples where
          written because the channel was not connected.
          Typically, it
          makes sense to combine this option with the
          <link linkend="channel_access.configuration.max_update_period">
            <literal>maxUpdatePeriod</literal>
          </link>
          and
          <link
            linkend="channel_access.configuration.write_sample_when_disabled">
            <literal>writeSampleWhenDisabled</literal>
          </link>
          options.
        </para>
        <para>
          When writing a marker sample to indicate that the channel is
          disconnected, the time from the archiving server’s system
          clock is
          used, regardless of the
          <link linkend="channel_access.configuration.clock_source">
            <literal>clockSource</literal>
            option
          </link>
          .
          Mixing samples that use the archiving server’s system clock
          for
          generating the time-stamp with samples that use the time
          stamp
          provided by the Channel Access server can have the effect
          that
          updates that are received from the Channel Access server
          are actually
          not archived because a previously written sample
          has a (slightly)
          greater time stamp and the newer sample is
          therefore discarded (the
          Cassandra PV Archiver server never
          writes samples that have a time
          stamp less than or equal to a
          previously archive sample).
          For this reason, it is recommended
          to set the
          <literal>clockSource</literal>
          option to
          <literal>local</literal>
          when enabling this option.
        </para>
      </section>
    </section>

    <section xml:id="channel_access.decimated_samples">
      <title>Decimated samples</title>
      <para>
        The Channel Access control-system support implements the
        generation of
        decimated samples in a way that should fit for most
        applications.
        This section explains how sample decimation is
        handled in different
        situations, in particular regarding the
        different possible types of raw
        samples.
      </para>
      <para>
        For numeric, scalar samples, the Channel Access control-system
        support
        aggregates source samples in order to generate a
        decimated sample that
        represents the aggregated information of
        all its source samples.
        This process is described in
        <xref linkend="channel_access.decimated_samples.aggregation" />
        .
        When the source samples cannot be reasonably aggregated (for
        example
        string samples or arrays), the Channel Access
        control-system support
        falls back to a simple decimation
        algorithm.
        This decimation algorithm is described in
        <xref linkend="channel_access.decimated_samples.decimation" />
        .
      </para>

      <section xml:id="channel_access.decimated_samples.aggregation">
        <title>Aggregation</title>
        <para>
          Numeric, scalar source samples are aggregated when generating
          a
          decimated sample.
          Such source samples are of the types
          <literal>DBR_DOUBLE</literal>
          ,
          <literal>DBR_FLOAT</literal>
          ,
          <literal>DBR_INT</literal>
          ,
          <literal>DBR_LONG</literal>
          , and
          <literal>DBR_SHORT</literal>
          and only
          have a single element.
          If the period that is covered by
          a decimated sample contains a sample
          of type
          <literal>DBR_ENUM</literal>
          or
          <literal>DBR_STRING</literal>
          or a sample that has more than one element, the algorithm
          falls back
          to using the simple decimation algorithm that is
          described in
          <xref linkend="channel_access.decimated_samples.decimation" />
          .
        </para>
        <para>
          When the source samples are of different types that are all
          aggregatable, (e.g.
          <literal>DBR_DOUBLE</literal>
          and
          <literal>DBR_SHORT</literal>
          ), the samples of the type that covers the
          greatest fraction of
          the period is used.
          Samples of other types are not considered
          when building the aggregated
          sample.
          Source samples that
          indicate the channel being disabled or
          disconnected are not
          used when building the aggregated sample either.
        </para>
        <para>
          The generated aggregated sample contains the following
          information:
        </para>
        <itemizedlist>
          <listitem>
            <simpara>
              mean of the source samples’ values
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              standard deviation of the source samples’ values
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              least source sample value (minimum)
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              greatest source sample value (maximum)
            </simpara>
          </listitem>
          <listitem>
            <simpara>
              fraction of the total period that is covered by the
              source samples
              of that type
            </simpara>
          </listitem>
        </itemizedlist>
        <para>
          The mean and the standard deviation are calculated so that
          the
          validity period of each sample is used as its weight.
          For
          example, if the period for which a decimated sample is
          generated
          contains two samples and one of these two samples
          covers 90 percent
          of the period and the other one covers 10
          percent of the period, the
          weight of the first sample is 0.9
          and the weight of the second sample
          is 0.1.
          This way, the mean
          and the standard deviation give a more natural
          representation
          of the channel’s actual value during the whole period.
        </para>
        <para>
          The fraction of the total period that is covered by the
          source samples
          of that type is kept for two reasons:
          First, it
          is needed when
          aggregating already aggregated samples
          further
          (for decimation
          levels with an even greater decimation period)
          in order to
          correctly calculate the weight of each sample.
          Second, it gives
          an idea of how much one can “trust” a sample.
          An aggregated
          sample that only covers a small fraction of the
          period
          is
          typically less reliable than an aggregated sample that
          covers
          a
          large fraction.
        </para>
        <para>
          The meta-data of an aggregated sample (alarm limits,
          engineering
          units, etc.) is simply taken from the first source
          sample of the
          respective type.
          The alarm severity is taken from
          the source sample with the highest
          alarm severity.
          The alarm
          status is taken from that same sample.
          If there is more than
          one source sample with the highest alarm
          severity, the alarm
          status from the first of these samples is used.
        </para>
      </section>

      <section xml:id="channel_access.decimated_samples.decimation">
        <title>Decimation</title>
        <para>
          When source samples cannot reasonably be aggregated
          (because they
          are of a non-numeric type or have values with
          more than a single
          element), a very simple decimation strategy
          is chosen.
          This strategy simply uses the first source sample,
          replacing its
          time stamp with the time of the start of the
          interval for which the
          decimated sample is generated.
          Decimated
          samples that are generated in this way are decimated in the
          literal sense and simply represent snapshots of the channel at
          specific points in time.
        </para>
      </section>
    </section>

    <section xml:id="channel_access.cql_layout">
      <title>CQL table layout</title>
      <para>
        In the database, channels that use the Channel Access
        control-system
        support can be identified by having their
        control-system type set to
        “channel_access”.
        The Channel Access
        control-system support stores all samples in a
        single
        table with
        the name
        <literal>channel_access_samples</literal>
        .
        The columns of this table are described by
        <xref
          linkend="channel_access.cql_layout.tbl.table_channel_access_samples" />
        .
      </para>
      <table
        xml:id="channel_access.cql_layout.tbl.table_channel_access_samples">
        <title>Columns of table channels_access_samples</title>
        <tgroup align="left" cols="4">
          <colspec colwidth="1*" />
          <colspec colwidth="1*" />
          <colspec colwidth="2*" />
          <colspec colwidth="2*" />
          <thead>
            <row>
              <entry>Column name</entry>
              <entry>Column type</entry>
              <entry>Data type</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>channel_data_id</entry>
              <entry>Partition key</entry>
              <entry>uuid</entry>
              <entry>
                Channel data ID.
              </entry>
            </row>
            <row>
              <entry>decimation_level</entry>
              <entry>Partition Key</entry>
              <entry>int</entry>
              <entry>
                Decimation level (identified by the decimation
                period in
                seconds). Zero indicates raw samples.
              </entry>
            </row>
            <row>
              <entry>bucket_start_time</entry>
              <entry>Partition Key</entry>
              <entry>bigint</entry>
              <entry>
                Start time of the sample bucket (in nanoseconds since
                epoch,
                which is January 1
                <superscript>st</superscript>
                , 1970, 00:00:00
                UTC).
              </entry>
            </row>
            <row>
              <entry>sample_time</entry>
              <entry>Clustering Key</entry>
              <entry>bigint</entry>
              <entry>
                Time stamp of the sample (in nanoseconds since epoch,
                which is
                January 1
                <superscript>st</superscript>
                , 1970, 00:00:00 UTC).
              </entry>
            </row>
            <row>
              <entry>a_char</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_char&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_CHAR</literal>
                with more
                than one element.
              </entry>
            </row>
            <row>
              <entry>a_double</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_double&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_DOUBLE</literal>
                with
                more than one element.
              </entry>
            </row>
            <row>
              <entry>a_enum</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_enum&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_ENUM</literal>
                with more
                than one element.
              </entry>
            </row>
            <row>
              <entry>a_float</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_float&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_FLOAT</literal>
                with more
                than one element.
              </entry>
            </row>
            <row>
              <entry>a_long</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_long&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_LONG</literal>
                with more
                than one element.
              </entry>
            </row>
            <row>
              <entry>a_short</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_short&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_SHORT</literal>
                with more
                than one element.
              </entry>
            </row>
            <row>
              <entry>a_string</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_array_string&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_STRING</literal>
                with
                more than one element.
              </entry>
            </row>
            <row>
              <entry>current_bucket_size</entry>
              <entry>Static</entry>
              <entry>int</entry>
              <entry>
                Accumulated size (in bytes) of the samples that
                have been
                written to the sample bucket so far.
              </entry>
            </row>
            <row>
              <entry>disabled</entry>
              <entry>Regular</entry>
              <entry>boolean</entry>
              <entry>
                Marker for a sample indicating that the channel was
                disabled at
                that point in time.
              </entry>
            </row>
            <row>
              <entry>disconnected</entry>
              <entry>Regular</entry>
              <entry>boolean</entry>
              <entry>
                Marker for a sample indicating that the channel was
                disconnected
                at that point in time.
              </entry>
            </row>
            <row>
              <entry>gs_char</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_aggregated_scalar_char&gt; </entry>
              <entry>
                Data for an aggregated sample that has been built from
                samples
                of type
                <literal>DBR_CHAR</literal>
                , each having a single
                element.
              </entry>
            </row>
            <row>
              <entry>gs_double</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_aggregated_scalar_double&gt; </entry>
              <entry>
                Data for an aggregated sample that has been built from
                samples
                of type
                <literal>DBR_DOUBLE</literal>
                , each having a single
                element.
              </entry>
            </row>
            <row>
              <entry>gs_float</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_aggregated_scalar_float&gt; </entry>
              <entry>
                Data for an aggregated sample that has been built from
                samples
                of type
                <literal>DBR_FLOAT</literal>
                , each having a single
                element.
              </entry>
            </row>
            <row>
              <entry>gs_long</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_aggregated_scalar_long&gt; </entry>
              <entry>
                Data for an aggregated sample that has been built from
                samples
                of type
                <literal>DBR_LONG</literal>
                , each having a single
                element.
              </entry>
            </row>
            <row>
              <entry>gs_short</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_aggregated_scalar_short&gt; </entry>
              <entry>
                Data for an aggregated sample that has been built from
                samples
                of type
                <literal>DBR_SHORT</literal>
                , each having a single
                element.
              </entry>
            </row>
            <row>
              <entry>s_char</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_char&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_CHAR</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_double</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_double&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_DOUBLE</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_enum</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_enum&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_ENUM</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_float</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_float&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_FLOAT</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_long</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_long&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_LONG</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_short</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_short&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_SHORT</literal>
                with a
                single element.
              </entry>
            </row>
            <row>
              <entry>s_string</entry>
              <entry>Regular</entry>
              <entry>frozen&lt;channel_access_scalar_string&gt;</entry>
              <entry>
                Data for a sample of type
                <literal>DBR_STRING</literal>
                with a
                single element.
              </entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para>
        The
        <literal>channel_data_id</literal>
        ,
        <literal>decimation_level</literal>
        , and
        <literal>bucket_start_time</literal>
        form a composite partition key that
        identifies the sample bucket.
        These parameters are passed to the control-system support by the
        Cassandra PV Archiver server and are simply used “as-is”.
      </para>
      <para>
        The
        <literal>sample_time</literal>
        is used as the clustering key.
        This way, it is easily possible to
        select only those samples from a
        sample bucket that have a time
        stamp within a specific interval.
      </para>
      <para>
        The
        <literal>current_bucket_size</literal>
        is a static column because it
        obviously is the same for the whole
        sample bucket.
        This column is updated by the control-system
        support each time a sample
        is added to the sample bucket.
      </para>
      <para>
        All other columns are used for storing the sample’s data.
        For
        each sample, exactly one of these columns has a non-null value.
        The
        <literal>disabled</literal>
        and
        <literal>disconnected</literal>
        columns are simple
        <literal>boolean</literal>
        columns.
        If one of them is
        <literal>true</literal>
        , it means that the sample is
        a marker of the corresponding type.
        Each column that stores a regular (non-marker) sample uses a
        user-defined type (UDT) that is only used by that column.
      </para>
      <note>
        <para>
          The names of the data columns have intentionally been
          chosen to be
          very short.
          The reason for this is simple:
          Due to
          how regular columns are internally handled by Cassandra, the
          column name is serialized for each row.
          When there are many
          rows, a long column name can contribute to the
          total data size
          significantly.
          Most of this overhead is compensated by the
          compression that is
          applied to SSTables before storing them on
          disk.
          However, the sample bucket size that is limited to about
          100 MB is
          measured before applying the compression.
          For this
          reason, longer column names would significantly reduce the
          number of samples that could be stored in each sample bucket.
        </para>
        <para>
          User-defined types (UDTs) are used for the same reason:
          When the various fields that are needed to store a sample
          would be
          represented as separate columns, the overhead that is
          caused by the
          meta-data for each column would increase the
          total data size
          significantly.
          Frozen UDTs, on the other hand,
          are as efficient as frozen tuples,
          allowing for the
          space-efficient storage of sample data while having
          human-readable names for their fields.
        </para>
      </note>
      <para>
        The UDTs that are used by the Channel Access control-system
        support all
        share a similar structure.
        The fields that may be
        present in these UDTs are listed in
        <xref linkend="channel_access.cql_layout.tbl.udt_fields" />
        .
      </para>
      <table xml:id="channel_access.cql_layout.tbl.udt_fields">
        <title>Fields of the user-defined types</title>
        <tgroup align="left" cols="3">
          <colspec colwidth="1*" />
          <colspec colwidth="1*" />
          <colspec colwidth="2*" />
          <thead>
            <row>
              <entry>Field name</entry>
              <entry>Data type</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>value</entry>
              <entry>depends on UDT</entry>
              <entry>
                sample’s value.
              </entry>
            </row>
            <row>
              <entry>std</entry>
              <entry>double</entry>
              <entry>
                standard deviation for an aggregated sample.
              </entry>
            </row>
            <row>
              <entry>min</entry>
              <entry>double</entry>
              <entry>
                least original value for an aggregated sample.
              </entry>
            </row>
            <row>
              <entry>max</entry>
              <entry>double</entry>
              <entry>
                greatest original value for an aggregated sample.
              </entry>
            </row>
            <row>
              <entry>covered_period_fraction</entry>
              <entry>double</entry>
              <entry>
                fraction of the period that is actually covered by the
                data in
                the aggregated sample.
                A value of
                <literal>1.0</literal>
                means that the data that was
                used to calculate the
                aggregated sample actually covers the full
                period that is
                supposed to be represented by the aggregated
                sample.
                A
                value of
                <literal>0.5</literal>
                means that the data that was
                used to calculate the
                aggregated sample actually only covers
                half of the period
                that is supposed to be covered by the
                aggregated sample.
              </entry>
            </row>
            <row>
              <entry>alarm_severity</entry>
              <entry>smallint</entry>
              <entry>
                alarm severity (
                <literal>0</literal>
                means
                <literal>NO_ALARM</literal>
                ,
                <literal>1</literal>
                means
                <literal>MINOR</literal>
                ,
                <literal>2</literal>
                means
                <literal>MAJOR</literal>
                ,
                <literal>3</literal>
                means
                <literal>INVALID</literal>
                ).
              </entry>
            </row>
            <row>
              <entry>alarm_status</entry>
              <entry>smallint</entry>
              <entry>
                alarm status (the number is the status code that is
                used by the
                Channel Access protocol to signal the
                corresponding alarm
                status).
              </entry>
            </row>
            <row>
              <entry>precision</entry>
              <entry>smallint</entry>
              <entry>
                display precision for floating point numbers.
              </entry>
            </row>
            <row>
              <entry>units</entry>
              <entry>text</entry>
              <entry>
                engineering units.
              </entry>
            </row>
            <row>
              <entry>labels</entry>
              <entry>frozen&lt;list&lt;text&gt;&gt;</entry>
              <entry>
                labels for enum states.
              </entry>
            </row>
            <row>
              <entry>lower_warning_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                lower warning limit.
              </entry>
            </row>
            <row>
              <entry>upper_warning_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                upper warning limit.
              </entry>
            </row>
            <row>
              <entry>lower_alarm_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                lower alarm limit.
              </entry>
            </row>
            <row>
              <entry>upper_alarm_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                upper alarm limit.
              </entry>
            </row>
            <row>
              <entry>lower_display_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                lower display limit.
              </entry>
            </row>
            <row>
              <entry>upper_display_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                upper display limit.
              </entry>
            </row>
            <row>
              <entry>lower_control_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                lower control limit.
              </entry>
            </row>
            <row>
              <entry>upper_control_limit</entry>
              <entry>depends on UDT</entry>
              <entry>
                upper control limit.
              </entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para>
        Not all of these fields are present in each UDT.
        The
        <literal>value</literal>
        ,
        <literal>alarm_severity</literal>
        , and
        <literal>alarm_status</literal>
        fields are the only ones that are
        present in all UDTs.
        The
        <literal>std</literal>
        ,
        <literal>min</literal>
        ,
        <literal>max</literal>
        , and
        <literal>covered_period_fraction</literal>
        fields are only present in the
        <literal>channel_access_aggregated_*</literal>
        UDTs.
        The
        <literal>precision</literal>
        field is only present in UDTs
        representing samples of a
        floating-point type.
        The
        <literal>units</literal>
        ,
        <literal>lower_warning_limit</literal>
        ,
        <literal>upper_warning_limit</literal>
        ,
        <literal>lower_alarm_limit</literal>
        ,
        <literal>upper_alarm_limit</literal>
        ,
        <literal>lower_display_limit</literal>
        ,
        <literal>upper_display_limit</literal>
        ,
        <literal>lower_control_limit</literal>
        , and
        <literal>upper_control_limit</literal>
        fields are only present in UDTs
        that represent samples of a
        numeric type.
        The
        <literal>labels</literal>
        field is only present in the
        <literal>channel_access_array_enum</literal>
        and
        <literal>channel_access_scalar_enum</literal>
        UDTs.
      </para>
      <para>
        The type of the
        <literal>value</literal>
        field depends on the type of
        the sample that is represented by
        the UDT.
        The same applies to the
        <literal>lower_warning_limit</literal>
        ,
        <literal>upper_warning_limit</literal>
        ,
        <literal>lower_alarm_limit</literal>
        ,
        <literal>upper_alarm_limit</literal>
        ,
        <literal>lower_display_limit</literal>
        ,
        <literal>upper_display_limit</literal>
        ,
        <literal>lower_control_limit</literal>
        , and
        <literal>upper_control_limit</literal>
        fields.
        The types used for those fields are listed in
        <xref linkend="channel_access.cql_layout.tbl.udt_field_types" />
        .
      </para>
      <table xml:id="channel_access.cql_layout.tbl.udt_field_types">
        <title>Type of UDT fields</title>
        <tgroup align="left" cols="3">
          <thead>
            <row>
              <entry>User-defined type</entry>
              <entry>Value field type</entry>
              <entry>Limit fields type</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>channel_access_aggregated_scalar_char</entry>
              <entry>double</entry>
              <entry>tinyint</entry>
            </row>
            <row>
              <entry>channel_access_aggregated_scalar_double</entry>
              <entry>double</entry>
              <entry>double</entry>
            </row>
            <row>
              <entry>channel_access_aggregated_scalar_float</entry>
              <entry>double</entry>
              <entry>float</entry>
            </row>
            <row>
              <entry>channel_access_aggregated_scalar_long</entry>
              <entry>double</entry>
              <entry>int</entry>
            </row>
            <row>
              <entry>channel_access_aggregated_scalar_short</entry>
              <entry>double</entry>
              <entry>smallint</entry>
            </row>
            <row>
              <entry>channel_access_array_char</entry>
              <entry>blob</entry>
              <entry>tinyint</entry>
            </row>
            <row>
              <entry>channel_access_array_double</entry>
              <entry>blob</entry>
              <entry>double</entry>
            </row>
            <row>
              <entry>channel_access_array_enum</entry>
              <entry>blob</entry>
              <entry>n/a</entry>
            </row>
            <row>
              <entry>channel_access_array_float</entry>
              <entry>blob</entry>
              <entry>float</entry>
            </row>
            <row>
              <entry>channel_access_array_long</entry>
              <entry>blob</entry>
              <entry>int</entry>
            </row>
            <row>
              <entry>channel_access_array_short</entry>
              <entry>blob</entry>
              <entry>smallint</entry>
            </row>
            <row>
              <entry>channel_access_array_string</entry>
              <entry>blob</entry>
              <entry>n/a</entry>
            </row>
            <row>
              <entry>channel_access_scalar_char</entry>
              <entry>tinyint</entry>
              <entry>tinyint</entry>
            </row>
            <row>
              <entry>channel_access_scalar_double</entry>
              <entry>double</entry>
              <entry>double</entry>
            </row>
            <row>
              <entry>channel_access_scalar_enum</entry>
              <entry>smallint</entry>
              <entry>n/a</entry>
            </row>
            <row>
              <entry>channel_access_scalar_float</entry>
              <entry>float</entry>
              <entry>float</entry>
            </row>
            <row>
              <entry>channel_access_scalar_long</entry>
              <entry>int</entry>
              <entry>int</entry>
            </row>
            <row>
              <entry>channel_access_scalar_short</entry>
              <entry>smallint</entry>
              <entry>smallint</entry>
            </row>
            <row>
              <entry>channel_access_scalar_string</entry>
              <entry>text</entry>
              <entry>n/a</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <para>
        For aggregated samples, the
        <literal>value</literal>
        field is always of
        type
        <literal>double</literal>
        because it stores the mean of all source
        samples.
        The array types
        store the value elements in a
        <literal>blob</literal>
        .
        The reason for this is that Cassandra’s
        <literal>list</literal>
        type
        comes with an overhead that is significant when representing
        a large
        number of elements as it is commonly encountered for
        Channel Access
        channels that have array values.
      </para>
      <para>
        Storing these arrays inside a
        <literal>blob</literal>
        is very efficient
        because the size occupied by each element is
        not more than the element’s
        actual size (e.g. two bytes for a
        each element of a
        <literal>DBR_SHORT</literal>
        sample).
        The numbers inside the
        <literal>blob</literal>
        are stored in big endian
        format, so that when using Java, they
        can easily be converted back to
        numbers by interpreting the
        <classname>ByteBuffer</classname>
        representing the
        <literal>blob</literal>
        as a buffer of numbers (e.g. an
        <classname>IntBuffer</classname>
        for samples of type
        <literal>DBR_LONG</literal>
        ).
      </para>
      <para>
        For array samples of type
        <literal>DBR_STRING</literal>
        , the blob stores
        40 bytes for each element.
        These 40 bytes
        represent the raw value as it has been received from the
        Channel
        Access server.
      </para>
      <para>
        The complete list of Java element and buffer types that
        correspond to
        the data stored in the
        <literal>value</literal>
        fields of the array UDTs
        is given by
        <xref linkend="channel_access.cql_layout.tbl.udt_value_blob_java_types" />
        .
      </para>
      <table xml:id="channel_access.cql_layout.tbl.udt_value_blob_java_types">
        <title>Java types corresponding to blobs storing sample values
        </title>
        <tgroup align="left" cols="3">
          <thead>
            <row>
              <entry>User-defined type</entry>
              <entry>Java element type</entry>
              <entry>Java buffer type</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>channel_access_array_char</entry>
              <entry>byte</entry>
              <entry>ByteBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_double</entry>
              <entry>double</entry>
              <entry>DoubleBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_enum</entry>
              <entry>short</entry>
              <entry>ShortBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_float</entry>
              <entry>float</entry>
              <entry>FloatBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_long</entry>
              <entry>int</entry>
              <entry>IntBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_short</entry>
              <entry>short</entry>
              <entry>ShortBuffer</entry>
            </row>
            <row>
              <entry>channel_access_array_string</entry>
              <entry>byte[40]</entry>
              <entry>ByteBuffer</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
  </appendix>

</book>
